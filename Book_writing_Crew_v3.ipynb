{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMKI6S7zk2kPqoLL38D2SUo",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/bbanzai88/Book_Writing_Crew/blob/main/Book_writing_Crew_v3.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "y8VvYqlWZnx7"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "This code doesnt use crewAI or crewai  flow and seems to produce better  results i.e. it has some character development and the number of chapters produced agrees with what was expected. This version includes:\n",
        "\n",
        "stripping <think>â€¦</think> everywhere from the output\n",
        "\n",
        "stronger outline de-dupe\n",
        "\n",
        "chapter repetition detection + automatic revision\n",
        "\n",
        "an editor that scores â€œinterestingnessâ€ + punch-up pass\n",
        "\n",
        "cleaner prompts that forbid meta commentary\n",
        "\n",
        "mixed models: DeepSeek-R1 for planning/eval, Llama 3.1 for prose"
      ],
      "metadata": {
        "id": "U-2hTvsQdTOm"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "CRt1XC_sP1EC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "UVxRA07fP1BN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "0onezjd1P09I"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
        "# 0) Colab Setup: install & launch Ollama\n",
        "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
        "!pip install --quiet langchain-ollama python-docx tqdm\n",
        "\n",
        "import os, threading, subprocess, time, requests\n",
        "from google.colab import files\n",
        "\n",
        "# Unset any OpenAI/LiteLLM envs that could hijack LangChain\n",
        "for v in [\n",
        "    \"OPENAI_API_KEY\",\n",
        "    \"LITELLM_PROVIDER\", \"LITELLM_MODEL\", \"LITELLM_BASE_URL\",\n",
        "    \"LITELL M_PROVIDER\", \"LITELL M_MODEL\", \"LITELL M_BASE_URL\"  # catch stray typos\n",
        "]:\n",
        "    os.environ.pop(v, None)\n",
        "\n",
        "os.environ[\"OLLAMA_HOST\"]    = \"127.0.0.1:11434\"\n",
        "os.environ[\"OLLAMA_ORIGINS\"] = \"*\"\n",
        "\n",
        "# Install & start Ollama\n",
        "!curl -fsSL https://ollama.com/install.sh -o install.sh\n",
        "!bash install.sh >/dev/null 2>&1 || true\n",
        "\n",
        "def _serve_ollama():\n",
        "    subprocess.Popen([\"ollama\",\"serve\"], stderr=subprocess.DEVNULL, stdout=subprocess.DEVNULL)\n",
        "\n",
        "threading.Thread(target=_serve_ollama, daemon=True).start()\n",
        "time.sleep(8)\n",
        "print(\"âœ… Ollama status:\", requests.get(\"http://127.0.0.1:11434\").status_code)\n",
        "\n",
        "# Pull models: planner/evaluator (DeepSeek-R1) and writer (Llama 3.1)\n",
        "!ollama pull deepseek-r1:1.5b\n",
        "!ollama pull llama3.1:8b\n",
        "\n",
        "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
        "# 1) Imports & Inputs\n",
        "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
        "import json, re\n",
        "from typing import List, Any, Dict\n",
        "from concurrent.futures import ThreadPoolExecutor, as_completed\n",
        "from collections import Counter\n",
        "from tqdm import tqdm\n",
        "import docx\n",
        "\n",
        "from langchain_ollama import OllamaLLM\n",
        "from langchain_core.prompts import PromptTemplate  # modern import\n",
        "\n",
        "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
        "# User parameters\n",
        "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
        "NUM_CH       = 70  # set 20â€“30 for faster iteration\n",
        "SEED_IDEA    = (\"Dr. Lena Park â€” a brilliant but introverted data scientist at Datum, \"\n",
        "                \"a social-media analytics startup. She notices impossible engagement \"\n",
        "                \"patterns in a rising star; her investigation unravels a conspiracy \"\n",
        "                \"of AI-driven â€œinfluencersâ€ masquerading as humansâ€”and she must decide \"\n",
        "                \"whether to expose the truth or risk blowing up the platform.\")\n",
        "BOOK_TITLE   = \"Artificial Influencers 2\"\n",
        "MODE         = \"fiction\"  # or \"philosophy\"\n",
        "\n",
        "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
        "# 2) LLM & Prompts (using the | operator, not LLMChain)\n",
        "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
        "planner_llm = OllamaLLM(\n",
        "    model=\"deepseek-r1:1.5b\",\n",
        "    base_url=\"http://127.0.0.1:11434\",\n",
        "    temperature=0.5,  # a bit lower to help structure\n",
        ")\n",
        "writer_llm  = OllamaLLM(\n",
        "    model=\"llama3.1:8b\",\n",
        "    base_url=\"http://127.0.0.1:11434\",\n",
        "    temperature=0.8,\n",
        ")\n",
        "\n",
        "# NDJSON prompts (MUCH easier to parse than JSON arrays)\n",
        "outline_prompt = PromptTemplate(\n",
        "    input_variables=[\"topic\",\"count\"],\n",
        "    template=(\n",
        "\"You are a creative fiction author. Generate exactly {count} UNIQUE chapter seeds \"\n",
        "\"for the book below. OUTPUT FORMAT: **NDJSON**, one compact JSON object per line, \"\n",
        "\"no leading numbering, no extra text, no trailing commas, no code fences.\\n\\n\"\n",
        "\"Each line MUST be like:\\n\"\n",
        "'{{\"title\":\"...\",\"description\":\"...\"}}\\n\\n'\n",
        "\"Book idea:\\n{topic}\\n\"\n",
        "    )\n",
        ")\n",
        "\n",
        "character_prompt = PromptTemplate(\n",
        "    input_variables=[\"outline\",\"num_chars\"],\n",
        "    template=(\n",
        "\"Given this chapter outline (JSON list):\\n{outline}\\n\\n\"\n",
        "\"Create exactly {num_chars} main characters.\\n\"\n",
        "\"OUTPUT FORMAT: **NDJSON**, one compact JSON object per line (no array, no extra text):\\n\"\n",
        "'{{\"name\":\"...\",\"role\":\"...\",\"development_arc\":\"...\"}}\\n'\n",
        "    )\n",
        ")\n",
        "\n",
        "chapter_prompt = PromptTemplate(\n",
        "    input_variables=[\"title\",\"description\",\"idea\"],\n",
        "    template=(\n",
        "\"\"\"Write a ~2200â€“3200 word chapter titled \"{title}\".\n",
        "Seed idea: {idea}\n",
        "Chapter description: \"{description}\"\n",
        "\n",
        "Constraints:\n",
        "- NO meta commentary, NO analysis of your process, NO decision making.\n",
        "- Assume the reader remembers prior chapters; do not re-explain backstory.\n",
        "- Maintain continuity, but introduce at least one fresh obstacle, one vivid sensory beat, and one believable surprise.\n",
        "- Use concrete, precise details; avoid clichÃ©s.\n",
        "- End with a small but real unresolved tension.\n",
        "Return TEXT ONLY.\n",
        "\"\"\"\n",
        "    )\n",
        ")\n",
        "\n",
        "REVISION_PROMPT = PromptTemplate(\n",
        "    input_variables=[\"chapter\",\"title\",\"description\",\"ledger\"],\n",
        "    template=(\n",
        "\"\"\"Revise the chapter to reduce repetition with earlier chapters while improving novelty and tension.\n",
        "Keep the same characters and continuity, but change scene dynamics, setting details, and micro-beats.\n",
        "\n",
        "Rules:\n",
        "- Do NOT re-explain backstory already known.\n",
        "- Add at least one fresh obstacle, one specific sensory detail, and one surprising but plausible turn.\n",
        "- Preserve voice and POV.\n",
        "Return TEXT ONLY.\n",
        "\n",
        "Title: {title}\n",
        "Description: {description}\n",
        "\n",
        "Do-not-repeat ledger (phrases/scenes to avoid): {ledger}\n",
        "\n",
        "Chapter draft:\n",
        "{chapter}\n",
        "\"\"\"\n",
        "    )\n",
        ")\n",
        "\n",
        "EVAL_PROMPT = PromptTemplate(\n",
        "    input_variables=[\"chapter\"],\n",
        "    template=(\n",
        "\"\"\"You are a tough fiction editor. Rate the chapter (1â€“10) on:\n",
        "- pacing\n",
        "- tension\n",
        "- voice\n",
        "- imagery\n",
        "- dialogue\n",
        "- novelty\n",
        "\n",
        "Return STRICT JSON only:\n",
        "{\"scores\":{\"pacing\":x,\"tension\":x,\"voice\":x,\"imagery\":x,\"dialogue\":x,\"novelty\":x},\"one_sentence_note\":\"...\",\"three_micro_edits\":[\"...\",\"...\",\"...\"]}\n",
        "\n",
        "Chapter:\n",
        "{chapter}\n",
        "\"\"\"\n",
        "    )\n",
        ")\n",
        "\n",
        "PUNCHUP_PROMPT = PromptTemplate(\n",
        "    input_variables=[\"chapter\",\"edits\"],\n",
        "    template=(\n",
        "\"\"\"Apply these micro-edits to strengthen the chapter without changing the plot:\n",
        "- {edits}\n",
        "\n",
        "Rules:\n",
        "- Keep POV, continuity, and length roughly the same (Â±10%).\n",
        "- Add concrete sensory details.\n",
        "- Tighten weak sentences; remove clichÃ©s.\n",
        "Return TEXT ONLY.\n",
        "\n",
        "Chapter:\n",
        "{chapter}\n",
        "\"\"\"\n",
        "    )\n",
        ")\n",
        "\n",
        "# build chains with the pipe operator (no deprecation warnings)\n",
        "outline_chain   = outline_prompt   | planner_llm\n",
        "character_chain = character_prompt | planner_llm\n",
        "chapter_chain   = chapter_prompt   | writer_llm\n",
        "revision_chain  = REVISION_PROMPT  | writer_llm\n",
        "eval_chain      = EVAL_PROMPT      | planner_llm\n",
        "punchup_chain   = PUNCHUP_PROMPT   | writer_llm\n",
        "\n",
        "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
        "# 3) Utilities: strip <think>â€¦</think>, parse NDJSON, similarity guards\n",
        "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
        "THINK_RE = re.compile(r\"<think>.*?</think>\\s*\", flags=re.S|re.I)\n",
        "FENCE_RE = re.compile(r\"```(?:json)?|```\", flags=re.I)\n",
        "\n",
        "def strip_think(x: Any) -> str:\n",
        "    s = x[\"text\"] if isinstance(x, dict) and \"text\" in x else str(x)\n",
        "    s = THINK_RE.sub(\"\", s)\n",
        "    s = FENCE_RE.sub(\"\", s)\n",
        "    return s.strip()\n",
        "\n",
        "def parse_ndjson(text: str, expected: int = None) -> List[dict]:\n",
        "    out = []\n",
        "    for ln in text.splitlines():\n",
        "        ln = ln.strip()\n",
        "        if not ln: continue\n",
        "        # ignore accidental bullets/numbering\n",
        "        if ln[:2] in (\"- \", \"* \"): ln = ln[2:].strip()\n",
        "        if ln and ln[0].isdigit() and ln.lstrip().split(\" \",1)[0].rstrip(\".\").isdigit():\n",
        "            # \"1. {...}\" â†’ \"{...}\"\n",
        "            ln = re.sub(r\"^\\d+\\.\\s*\", \"\", ln)\n",
        "        try:\n",
        "            obj = json.loads(ln)\n",
        "            if isinstance(obj, dict):\n",
        "                out.append(obj)\n",
        "        except json.JSONDecodeError:\n",
        "            # attempt tiny fixes: replace smart quotes, stray trailing commas\n",
        "            fix = ln.replace(\"â€œ\",\"\\\"\").replace(\"â€\",\"\\\"\").replace(\"â€™\",\"'\")\n",
        "            fix = re.sub(r\",\\s*}\", \"}\", fix)\n",
        "            fix = re.sub(r\",\\s*]\", \"]\", fix)\n",
        "            try:\n",
        "                obj = json.loads(fix)\n",
        "                if isinstance(obj, dict):\n",
        "                    out.append(obj)\n",
        "            except Exception:\n",
        "                continue\n",
        "    if expected is not None and len(out) != expected:\n",
        "        # keep best-effort, caller may retry\n",
        "        pass\n",
        "    return out\n",
        "\n",
        "def jaccard(a: str, b: str) -> float:\n",
        "    A = set(re.findall(r\"[a-z0-9']+\", a.lower()))\n",
        "    B = set(re.findall(r\"[a-z0-9']+\", b.lower()))\n",
        "    if not A or not B: return 0.0\n",
        "    return len(A & B) / len(A | B)\n",
        "\n",
        "def too_similar(ch1: Dict[str,str], ch2: Dict[str,str]) -> bool:\n",
        "    t_sim = jaccard(ch1[\"title\"], ch2[\"title\"])\n",
        "    d_sim = jaccard(ch1[\"description\"], ch2[\"description\"])\n",
        "    return (t_sim > 0.65) or (t_sim > 0.45 and d_sim > 0.55)\n",
        "\n",
        "def bigram_overlap(a: str, b: str) -> float:\n",
        "    def bigrams(s):\n",
        "        toks = re.findall(r\"[a-z0-9']+\", s.lower())\n",
        "        return set(zip(toks, toks[1:])) if len(toks) > 1 else set()\n",
        "    A, B = bigrams(a), bigrams(b)\n",
        "    denom = len(A | B) if (A or B) else 1\n",
        "    return len(A & B) / denom\n",
        "\n",
        "def top_trigrams(text: str, k: int = 30) -> List[str]:\n",
        "    toks = re.findall(r\"[a-z0-9']+\", text.lower())\n",
        "    tris = Counter(zip(toks, toks[1:], toks[2:]))\n",
        "    return [\" \".join(t) for t,_ in tris.most_common(k)]\n",
        "\n",
        "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
        "# 4) Outline generation with NDJSON + retry + strict dedupe\n",
        "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
        "print(f\"â†’ Generating {NUM_CH}-chapter outline in chunks of ~10â€¦\")\n",
        "outline, seen_titles = [], set()\n",
        "chunk = 10\n",
        "attempts = 0\n",
        "MAX_ATTEMPTS = 40\n",
        "\n",
        "while len(outline) < NUM_CH and attempts < MAX_ATTEMPTS:\n",
        "    ask = min(chunk, NUM_CH - len(outline))\n",
        "    raw = outline_chain.invoke({\"topic\": SEED_IDEA, \"count\": ask})\n",
        "    attempts += 1\n",
        "    lines = parse_ndjson(strip_think(raw), expected=ask)\n",
        "    if not lines:\n",
        "        print(\"âš ï¸ Outline chunk parse failed (empty); retryingâ€¦\")\n",
        "        continue\n",
        "    added = 0\n",
        "    for ch in lines:\n",
        "        cand = {\n",
        "            \"title\": (ch.get(\"title\") or \"\").strip(),\n",
        "            \"description\": (ch.get(\"description\") or \"\").strip()\n",
        "        }\n",
        "        if not cand[\"title\"] or not cand[\"description\"]:\n",
        "            continue\n",
        "        if cand[\"title\"] in seen_titles:\n",
        "            continue\n",
        "        if any(too_similar(cand, existing) for existing in outline):\n",
        "            continue\n",
        "        outline.append(cand)\n",
        "        seen_titles.add(cand[\"title\"])\n",
        "        added += 1\n",
        "        if len(outline) >= NUM_CH:\n",
        "            break\n",
        "    if added == 0:\n",
        "        # tighten retry loop if nothing useful came back\n",
        "        print(\"â„¹ï¸ No new unique chapters from this chunk; retryingâ€¦\")\n",
        "\n",
        "print(f\"âœ” Final outline: {len(outline)} chapters\\n\")\n",
        "if len(outline) < NUM_CH:\n",
        "    print(\"âš ï¸ Could not reach target count; proceeding with what we have.\")\n",
        "\n",
        "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
        "# 5) Character Bible (NDJSON + retry)\n",
        "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
        "NUM_CHAR = max(3, min(10, NUM_CH//8))\n",
        "print(f\"â†’ Generating {NUM_CHAR} charactersâ€¦\")\n",
        "characters = []\n",
        "for _ in range(6):  # a few retries if parsing fails\n",
        "    raw_chars = character_chain.invoke({\n",
        "        \"outline\": json.dumps(outline, ensure_ascii=False),\n",
        "        \"num_chars\": NUM_CHAR\n",
        "    })\n",
        "    characters = parse_ndjson(strip_think(raw_chars), expected=NUM_CHAR)\n",
        "    if len(characters) == NUM_CHAR:\n",
        "        break\n",
        "print(f\"âœ” Got {len(characters)} characters\\n\")\n",
        "\n",
        "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
        "# 6) Chapter Generation (+ repetition revision + eval + punch-up)\n",
        "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
        "print(\"â†’ Generating chapters in parallelâ€¦\")\n",
        "chap_texts = [None]*len(outline)\n",
        "editor_notes = [None]*len(outline)\n",
        "\n",
        "MAX_WORKERS = 3  # adjust if your session is slower/faster\n",
        "\n",
        "def write_one(idx):\n",
        "    meta = outline[idx]\n",
        "    res = chapter_chain.invoke({\n",
        "        \"title\": meta[\"title\"],\n",
        "        \"description\": meta[\"description\"],\n",
        "        \"idea\": SEED_IDEA\n",
        "    })\n",
        "    chapter_txt = strip_think(res)\n",
        "\n",
        "    # Repetition check against earlier completed chapters\n",
        "    ledger = []\n",
        "    for j in range(idx):\n",
        "        prev = chap_texts[j]\n",
        "        if not prev: continue\n",
        "        if bigram_overlap(chapter_txt, prev) > 0.22:\n",
        "            ledger.extend(top_trigrams(prev, k=10))\n",
        "    ledger = list(dict.fromkeys(ledger))[:60]  # unique + cap\n",
        "\n",
        "    if ledger:\n",
        "        revised = revision_chain.invoke({\n",
        "            \"chapter\": chapter_txt,\n",
        "            \"title\": meta[\"title\"],\n",
        "            \"description\": meta[\"description\"],\n",
        "            \"ledger\": \"; \".join(ledger)\n",
        "        })\n",
        "        chapter_txt = strip_think(revised)\n",
        "\n",
        "    # Evaluate interestingness\n",
        "    report_raw = eval_chain.invoke({\"chapter\": chapter_txt})\n",
        "    report_txt = strip_think(report_raw)\n",
        "    data = None\n",
        "    try:\n",
        "        # extract last JSON-ish block\n",
        "        m = re.search(r\"\\{[\\s\\S]*\\}\\s*$\", report_txt)\n",
        "        if m:\n",
        "            data = json.loads(m.group(0))\n",
        "    except Exception:\n",
        "        data = None\n",
        "\n",
        "    # Punch-up if needed\n",
        "    if data and \"scores\" in data:\n",
        "        scores = data[\"scores\"]\n",
        "        try:\n",
        "            avg_score = sum(float(scores[k]) for k in scores)/len(scores)\n",
        "        except Exception:\n",
        "            avg_score = 10.0\n",
        "        if avg_score < 7.5:\n",
        "            edits = \" | \".join(data.get(\"three_micro_edits\", [])) or \"Tighten weak lines; add fresh sensory detail; remove clichÃ©s.\"\n",
        "            punched = punchup_chain.invoke({\"chapter\": chapter_txt, \"edits\": edits})\n",
        "            chapter_txt = strip_think(punched)\n",
        "\n",
        "    return chapter_txt, data\n",
        "\n",
        "from concurrent.futures import ThreadPoolExecutor, as_completed\n",
        "with ThreadPoolExecutor(max_workers=MAX_WORKERS) as ex:\n",
        "    futures = { ex.submit(write_one, i): i for i in range(len(outline)) }\n",
        "    for fut in tqdm(as_completed(futures), total=len(futures), desc=\"Chapters\"):\n",
        "        idx = futures[fut]\n",
        "        try:\n",
        "            ch_txt, notes = fut.result()\n",
        "        except Exception as e:\n",
        "            ch_txt, notes = f\"[Generation failed: {e}]\", None\n",
        "        chap_texts[idx] = ch_txt\n",
        "        editor_notes[idx] = notes\n",
        "\n",
        "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
        "# 7) Save to Word + Download (includes Editorâ€™s Notes appendix)\n",
        "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
        "doc = docx.Document()\n",
        "doc.add_heading(BOOK_TITLE, 0)\n",
        "doc.add_paragraph(f\"Seed idea: {SEED_IDEA}\")\n",
        "\n",
        "# Character Development Section\n",
        "if characters:\n",
        "    doc.add_page_break()\n",
        "    doc.add_heading(\"Character Development\", level=1)\n",
        "    for c in characters:\n",
        "        name = c.get(\"name\",\"(Unnamed)\")\n",
        "        role = c.get(\"role\",\"\")\n",
        "        arc  = c.get(\"development_arc\",\"\")\n",
        "        doc.add_heading(name, level=2)\n",
        "        if role: doc.add_paragraph(f\"Role: {role}\")\n",
        "        if arc:  doc.add_paragraph(arc)\n",
        "\n",
        "# Chapters\n",
        "for i, (meta, text) in enumerate(zip(outline, chap_texts), start=1):\n",
        "    doc.add_page_break()\n",
        "    doc.add_heading(f\"Chapter {i}: {meta['title']}\", level=1)\n",
        "    doc.add_paragraph(meta['description'], style=\"Intense Quote\")\n",
        "    doc.add_paragraph((text or \"\").strip())\n",
        "\n",
        "# Editorâ€™s Notes (Auto-Eval)\n",
        "doc.add_page_break()\n",
        "doc.add_heading(\"Editorâ€™s Notes (Auto-Eval)\", level=1)\n",
        "for i, (meta, notes) in enumerate(zip(outline, editor_notes), start=1):\n",
        "    doc.add_heading(f\"Chapter {i}: {meta['title']}\", level=2)\n",
        "    if not notes or \"scores\" not in notes:\n",
        "        doc.add_paragraph(\"No evaluation available.\")\n",
        "        continue\n",
        "    scores = notes[\"scores\"]\n",
        "    one_liner = notes.get(\"one_sentence_note\",\"\")\n",
        "    edits = notes.get(\"three_micro_edits\", [])\n",
        "    try:\n",
        "        avg_score = sum(float(scores[k]) for k in scores)/len(scores)\n",
        "    except Exception:\n",
        "        avg_score = None\n",
        "    doc.add_paragraph(\"Scores: \" + \", \".join(f\"{k}: {scores[k]}\" for k in scores))\n",
        "    if avg_score is not None:\n",
        "        doc.add_paragraph(f\"Average: {avg_score:.2f}\")\n",
        "    if one_liner:\n",
        "        doc.add_paragraph(f\"Note: {one_liner}\")\n",
        "    if edits:\n",
        "        for e in edits:\n",
        "            doc.add_paragraph(f\"â€¢ {e}\")\n",
        "\n",
        "fn = BOOK_TITLE.replace(\" \", \"_\") + \".docx\"\n",
        "doc.save(fn)\n",
        "print(f\"ğŸ“˜ Saved {fn}\")\n",
        "files.download(fn)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 225
        },
        "id": "sFr1wckAP0yq",
        "outputId": "e3a9ee51-14cb-4f37-8ab1-c1dd1042a92f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "âœ… Ollama status: 200\n",
            "\u001b[?2026h\u001b[?25l\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1G\u001b[?25h\u001b[?2026l\n",
            "\u001b[?2026h\u001b[?25l\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1G\u001b[?25h\u001b[?2026l\n",
            "â†’ Generating 70-chapter outline in chunks of ~10â€¦\n",
            "âœ” Final outline: 70 chapters\n",
            "\n",
            "â†’ Generating 8 charactersâ€¦\n",
            "âœ” Got 8 characters\n",
            "\n",
            "â†’ Generating chapters in parallelâ€¦\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Chapters: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 70/70 [18:07:15<00:00, 931.93s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ğŸ“˜ Saved Artificial_Influencers_2.docx\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_f1a77f9a-6681-40ab-bcc7-930dbf712a3f\", \"Artificial_Influencers_2.docx\", 45392)"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "jy6E_0ctlHLT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
        "# 0) Colab Setup: install & launch Ollama\n",
        "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
        "!pip install --quiet langchain-ollama python-docx tqdm\n",
        "\n",
        "import os, threading, subprocess, time, requests\n",
        "from google.colab import files\n",
        "\n",
        "# Unset any OpenAI/LiteLLM envs that could hijack LangChain\n",
        "for v in [\n",
        "    \"OPENAI_API_KEY\",\n",
        "    \"LITELLM_PROVIDER\", \"LITELLM_MODEL\", \"LITELLM_BASE_URL\",\n",
        "    \"LITELL M_PROVIDER\", \"LITELL M_MODEL\", \"LITELL M_BASE_URL\"  # catch stray typos\n",
        "]:\n",
        "    os.environ.pop(v, None)\n",
        "\n",
        "os.environ[\"OLLAMA_HOST\"]    = \"127.0.0.1:11434\"\n",
        "os.environ[\"OLLAMA_ORIGINS\"] = \"*\"\n",
        "\n",
        "# Install & start Ollama\n",
        "!curl -fsSL https://ollama.com/install.sh -o install.sh\n",
        "!bash install.sh >/dev/null 2>&1 || true\n",
        "\n",
        "def _serve_ollama():\n",
        "    subprocess.Popen([\"ollama\",\"serve\"], stderr=subprocess.DEVNULL, stdout=subprocess.DEVNULL)\n",
        "\n",
        "threading.Thread(target=_serve_ollama, daemon=True).start()\n",
        "time.sleep(8)\n",
        "print(\"âœ… Ollama status:\", requests.get(\"http://127.0.0.1:11434\").status_code)\n",
        "\n",
        "# Pull models: planner/evaluator (DeepSeek-R1) and writer (Llama 3.1)\n",
        "!ollama pull deepseek-r1:1.5b\n",
        "!ollama pull llama3.1:8b\n",
        "\n",
        "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
        "# 1) Imports & Inputs\n",
        "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
        "import json, re\n",
        "from typing import List, Any, Dict\n",
        "from concurrent.futures import ThreadPoolExecutor, as_completed\n",
        "from collections import Counter\n",
        "from tqdm import tqdm\n",
        "import docx\n",
        "\n",
        "from langchain_ollama import OllamaLLM\n",
        "from langchain_core.prompts import PromptTemplate  # modern import\n",
        "\n",
        "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
        "# User parameters\n",
        "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
        "NUM_CH       = 20  # set 70 when you're happy with results\n",
        "SEED_IDEA    = (\"Dr. Lena Park â€” a brilliant but introverted data scientist at Datum, \"\n",
        "                \"a social-media analytics startup. She notices impossible engagement \"\n",
        "                \"patterns in a rising star; her investigation unravels a conspiracy \"\n",
        "                \"of AI-driven â€œinfluencersâ€ masquerading as humansâ€”and she must decide \"\n",
        "                \"whether to expose the truth or risk blowing up the platform.\")\n",
        "BOOK_TITLE   = \"Artificial Influencers 2\"\n",
        "MODE         = \"fiction\"  # or \"philosophy\"\n",
        "\n",
        "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
        "# 2) LLM & Prompts (using the | operator, not LLMChain)\n",
        "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
        "planner_llm = OllamaLLM(\n",
        "    model=\"deepseek-r1:1.5b\",\n",
        "    base_url=\"http://127.0.0.1:11434\",\n",
        "    temperature=0.3,  # lower â‡’ stricter structure for NDJSON\n",
        ")\n",
        "writer_llm  = OllamaLLM(\n",
        "    model=\"llama3.1:8b\",\n",
        "    base_url=\"http://127.0.0.1:11434\",\n",
        "    temperature=0.8,\n",
        ")\n",
        "\n",
        "# NDJSON prompts (MUCH easier to parse than JSON arrays)\n",
        "outline_prompt = PromptTemplate(\n",
        "    input_variables=[\"topic\",\"count\"],\n",
        "    template=(\n",
        "\"You are a creative fiction author. Generate exactly {count} UNIQUE chapter seeds \"\n",
        "\"for the book below. OUTPUT FORMAT: **NDJSON**, one compact JSON object per line, \"\n",
        "\"no leading numbering, no extra text, no trailing commas, no code fences.\\n\\n\"\n",
        "\"Each line MUST be like:\\n\"\n",
        "'{{\\\"title\\\":\\\"...\\\",\\\"description\\\":\\\"...\\\"}}\\\\n'\n",
        "\"\\nBook idea:\\n{topic}\\n\"\n",
        "    )\n",
        ")\n",
        "\n",
        "character_prompt = PromptTemplate(\n",
        "    input_variables=[\"outline\",\"num_chars\"],\n",
        "    template=(\n",
        "\"Given this chapter outline (JSON list):\\n{outline}\\n\\n\"\n",
        "\"Create exactly {num_chars} main characters.\\n\"\n",
        "\"OUTPUT FORMAT: **NDJSON**, one compact JSON object per line (no array, no extra text):\\n\"\n",
        "'{{\\\"name\\\":\\\"...\\\",\\\"role\\\":\\\"...\\\",\\\"development_arc\\\":\\\"...\\\"}}'\n",
        "    )\n",
        ")\n",
        "\n",
        "chapter_prompt = PromptTemplate(\n",
        "    input_variables=[\"title\",\"description\",\"idea\"],\n",
        "    template=(\n",
        "\"\"\"Write a ~2200â€“3200 word chapter titled \"{title}\".\n",
        "Seed idea: {idea}\n",
        "Chapter description: \"{description}\"\n",
        "\n",
        "Constraints:\n",
        "- NO meta commentary, NO analysis of your process, NO decision making.\n",
        "- Assume the reader remembers prior chapters; do not re-explain backstory.\n",
        "- Maintain continuity, but introduce at least one fresh obstacle, one vivid sensory beat, and one believable surprise.\n",
        "- Use concrete, precise details; avoid clichÃ©s.\n",
        "- End with a small but real unresolved tension.\n",
        "Return TEXT ONLY.\n",
        "\"\"\"\n",
        "    )\n",
        ")\n",
        "\n",
        "REVISION_PROMPT = PromptTemplate(\n",
        "    input_variables=[\"chapter\",\"title\",\"description\",\"ledger\"],\n",
        "    template=(\n",
        "\"\"\"Revise the chapter to reduce repetition with earlier chapters while improving novelty and tension.\n",
        "Keep the same characters and continuity, but change scene dynamics, setting details, and micro-beats.\n",
        "\n",
        "Rules:\n",
        "- Do NOT re-explain backstory already known.\n",
        "- Add at least one fresh obstacle, one specific sensory detail, and one surprising but plausible turn.\n",
        "- Preserve voice and POV.\n",
        "Return TEXT ONLY.\n",
        "\n",
        "Title: {title}\n",
        "Description: {description}\n",
        "\n",
        "Do-not-repeat ledger (phrases/scenes to avoid): {ledger}\n",
        "\n",
        "Chapter draft:\n",
        "{chapter}\n",
        "\"\"\"\n",
        "    )\n",
        ")\n",
        "\n",
        "# NOTE: braces escaped below ({{ â€¦ }}) so LangChain doesn't treat them as variables\n",
        "EVAL_PROMPT = PromptTemplate(\n",
        "    input_variables=[\"chapter\"],\n",
        "    template=(\n",
        "\"\"\"You are a tough fiction editor. Rate the chapter (1â€“10) on:\n",
        "- pacing\n",
        "- tension\n",
        "- voice\n",
        "- imagery\n",
        "- dialogue\n",
        "- novelty\n",
        "\n",
        "Return STRICT JSON only:\n",
        "{{\"scores\":{{\"pacing\":x,\"tension\":x,\"voice\":x,\"imagery\":x,\"dialogue\":x,\"novelty\":x}},\"one_sentence_note\":\"...\",\"three_micro_edits\":[\"...\",\"...\",\"...\"]}}\n",
        "\n",
        "Chapter:\n",
        "{chapter}\n",
        "\"\"\"\n",
        "    )\n",
        ")\n",
        "\n",
        "PUNCHUP_PROMPT = PromptTemplate(\n",
        "    input_variables=[\"chapter\",\"edits\"],\n",
        "    template=(\n",
        "\"\"\"Apply these micro-edits to strengthen the chapter without changing the plot:\n",
        "- {edits}\n",
        "\n",
        "Rules:\n",
        "- Keep POV, continuity, and length roughly the same (Â±10%).\n",
        "- Add concrete sensory details.\n",
        "- Tighten weak sentences; remove clichÃ©s.\n",
        "Return TEXT ONLY.\n",
        "\n",
        "Chapter:\n",
        "{chapter}\n",
        "\"\"\"\n",
        "    )\n",
        ")\n",
        "\n",
        "# build chains with the pipe operator (no deprecation warnings)\n",
        "outline_chain   = outline_prompt   | planner_llm\n",
        "character_chain = character_prompt | planner_llm\n",
        "chapter_chain   = chapter_prompt   | writer_llm\n",
        "revision_chain  = REVISION_PROMPT  | writer_llm\n",
        "eval_chain      = EVAL_PROMPT      | planner_llm\n",
        "punchup_chain   = PUNCHUP_PROMPT   | writer_llm\n",
        "\n",
        "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
        "# 3) Utilities: strip <think>â€¦</think>, parse NDJSON, similarity guards\n",
        "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
        "THINK_RE = re.compile(r\"<think>.*?</think>\\s*\", flags=re.S|re.I)\n",
        "FENCE_RE = re.compile(r\"```(?:json)?|```\", flags=re.I)\n",
        "\n",
        "def strip_think(x: Any) -> str:\n",
        "    s = x[\"text\"] if isinstance(x, dict) and \"text\" in x else str(x)\n",
        "    s = THINK_RE.sub(\"\", s)\n",
        "    s = FENCE_RE.sub(\"\", s)\n",
        "    return s.strip()\n",
        "\n",
        "def parse_ndjson(text: str, expected: int = None) -> List[dict]:\n",
        "    out = []\n",
        "    for ln in text.splitlines():\n",
        "        ln = ln.strip()\n",
        "        if not ln:\n",
        "            continue\n",
        "        # ignore accidental bullets/numbering\n",
        "        if ln[:2] in (\"- \", \"* \"):\n",
        "            ln = ln[2:].strip()\n",
        "        if ln and ln[0].isdigit() and ln.lstrip().split(\" \",1)[0].rstrip(\".\").isdigit():\n",
        "            ln = re.sub(r\"^\\d+\\.\\s*\", \"\", ln)  # \"1. { ... }\" â†’ \"{ ... }\"\n",
        "        try:\n",
        "            obj = json.loads(ln)\n",
        "            if isinstance(obj, dict):\n",
        "                out.append(obj)\n",
        "        except json.JSONDecodeError:\n",
        "            # tiny auto-fix: smart quotes / trailing commas\n",
        "            fix = ln.replace(\"â€œ\",\"\\\"\").replace(\"â€\",\"\\\"\").replace(\"â€™\",\"'\")\n",
        "            fix = re.sub(r\",\\s*}\", \"}\", fix)\n",
        "            fix = re.sub(r\",\\s*]\", \"]\", fix)\n",
        "            try:\n",
        "                obj = json.loads(fix)\n",
        "                if isinstance(obj, dict):\n",
        "                    out.append(obj)\n",
        "            except Exception:\n",
        "                continue\n",
        "    # we allow best-effort even if count != expected\n",
        "    return out\n",
        "\n",
        "def jaccard(a: str, b: str) -> float:\n",
        "    A = set(re.findall(r\"[a-z0-9']+\", a.lower()))\n",
        "    B = set(re.findall(r\"[a-z0-9']+\", b.lower()))\n",
        "    if not A or not B: return 0.0\n",
        "    return len(A & B) / len(A | B)\n",
        "\n",
        "def too_similar(ch1: Dict[str,str], ch2: Dict[str,str]) -> bool:\n",
        "    t_sim = jaccard(ch1[\"title\"], ch2[\"title\"])\n",
        "    d_sim = jaccard(ch1[\"description\"], ch2[\"description\"])\n",
        "    return (t_sim > 0.65) or (t_sim > 0.45 and d_sim > 0.55)\n",
        "\n",
        "def bigram_overlap(a: str, b: str) -> float:\n",
        "    def bigrams(s):\n",
        "        toks = re.findall(r\"[a-z0-9']+\", s.lower())\n",
        "        return set(zip(toks, toks[1:])) if len(toks) > 1 else set()\n",
        "    A, B = bigrams(a), bigrams(b)\n",
        "    denom = len(A | B) if (A or B) else 1\n",
        "    return len(A & B) / denom\n",
        "\n",
        "def top_trigrams(text: str, k: int = 30) -> List[str]:\n",
        "    toks = re.findall(r\"[a-z0-9']+\", text.lower())\n",
        "    tris = Counter(zip(toks, toks[1:], toks[2:]))\n",
        "    return [\" \".join(t) for t,_ in tris.most_common(k)]\n",
        "\n",
        "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
        "# 4) Outline generation with NDJSON + retry + strict dedupe\n",
        "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
        "print(f\"â†’ Generating {NUM_CH}-chapter outline in chunks of ~10â€¦\")\n",
        "outline, seen_titles = [], set()\n",
        "chunk = 10\n",
        "attempts = 0\n",
        "MAX_ATTEMPTS = 40\n",
        "\n",
        "while len(outline) < NUM_CH and attempts < MAX_ATTEMPTS:\n",
        "    ask = min(chunk, NUM_CH - len(outline))\n",
        "    raw = outline_chain.invoke({\"topic\": SEED_IDEA, \"count\": ask})\n",
        "    attempts += 1\n",
        "    lines = parse_ndjson(strip_think(raw), expected=ask)\n",
        "    if not lines:\n",
        "        print(\"âš ï¸ Outline chunk parse failed (empty); retryingâ€¦\")\n",
        "        continue\n",
        "    added = 0\n",
        "    for ch in lines:\n",
        "        cand = {\n",
        "            \"title\": (ch.get(\"title\") or \"\").strip(),\n",
        "            \"description\": (ch.get(\"description\") or \"\").strip()\n",
        "        }\n",
        "        if not cand[\"title\"] or not cand[\"description\"]:\n",
        "            continue\n",
        "        if cand[\"title\"] in seen_titles:\n",
        "            continue\n",
        "        if any(too_similar(cand, existing) for existing in outline):\n",
        "            continue\n",
        "        outline.append(cand)\n",
        "        seen_titles.add(cand[\"title\"])\n",
        "        added += 1\n",
        "        if len(outline) >= NUM_CH:\n",
        "            break\n",
        "    if added == 0:\n",
        "        print(\"â„¹ï¸ No new unique chapters from this chunk; retryingâ€¦\")\n",
        "\n",
        "print(f\"âœ” Final outline: {len(outline)} chapters\\n\")\n",
        "if len(outline) < NUM_CH:\n",
        "    print(\"âš ï¸ Could not reach target count; proceeding with what we have.\")\n",
        "\n",
        "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
        "# 5) Character Bible (NDJSON + retry)\n",
        "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
        "NUM_CHAR = max(3, min(10, NUM_CH//8))\n",
        "print(f\"â†’ Generating {NUM_CHAR} charactersâ€¦\")\n",
        "characters = []\n",
        "for _ in range(6):  # a few retries if parsing fails\n",
        "    raw_chars = character_chain.invoke({\n",
        "        \"outline\": json.dumps(outline, ensure_ascii=False),\n",
        "        \"num_chars\": NUM_CHAR\n",
        "    })\n",
        "    characters = parse_ndjson(strip_think(raw_chars), expected=NUM_CHAR)\n",
        "    if len(characters) == NUM_CHAR:\n",
        "        break\n",
        "print(f\"âœ” Got {len(characters)} characters\\n\")\n",
        "\n",
        "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
        "# 6) Chapter Generation (+ repetition revision + eval + punch-up) with guards\n",
        "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
        "print(\"â†’ Generating chapters in parallelâ€¦\")\n",
        "chap_texts = [None]*len(outline)\n",
        "editor_notes = [None]*len(outline)\n",
        "\n",
        "MAX_WORKERS = 3  # adjust if your session is slower/faster\n",
        "\n",
        "def write_one(idx):\n",
        "    meta = outline[idx]\n",
        "    # First draft\n",
        "    res = chapter_chain.invoke({\n",
        "        \"title\": meta[\"title\"],\n",
        "        \"description\": meta[\"description\"],\n",
        "        \"idea\": SEED_IDEA\n",
        "    })\n",
        "    chapter_txt = strip_think(res)\n",
        "\n",
        "    # Repetition check against earlier completed chapters\n",
        "    ledger = []\n",
        "    for j in range(idx):\n",
        "        prev = chap_texts[j]\n",
        "        if not prev: continue\n",
        "        if bigram_overlap(chapter_txt, prev) > 0.22:\n",
        "            ledger.extend(top_trigrams(prev, k=10))\n",
        "    ledger = list(dict.fromkeys(ledger))[:60]  # unique + cap\n",
        "\n",
        "    if ledger:\n",
        "        revised = revision_chain.invoke({\n",
        "            \"chapter\": chapter_txt,\n",
        "            \"title\": meta[\"title\"],\n",
        "            \"description\": meta[\"description\"],\n",
        "            \"ledger\": \"; \".join(ledger)\n",
        "        })\n",
        "        chapter_txt = strip_think(revised)\n",
        "\n",
        "    # Evaluate interestingness (GUARDED)\n",
        "    data = None\n",
        "    try:\n",
        "        report_raw = eval_chain.invoke({\"chapter\": chapter_txt})\n",
        "        report_txt = strip_think(report_raw)\n",
        "        m = re.search(r\"\\{[\\s\\S]*\\}\\s*$\", report_txt)\n",
        "        if m:\n",
        "            data = json.loads(m.group(0))\n",
        "        if data and \"scores\" in data:\n",
        "            scores = data[\"scores\"]\n",
        "            avg_score = sum(float(scores[k]) for k in scores)/len(scores)\n",
        "            if avg_score < 7.5:\n",
        "                edits = \" | \".join(data.get(\"three_micro_edits\", [])) or \\\n",
        "                        \"Tighten weak lines; add fresh sensory detail; remove clichÃ©s.\"\n",
        "                punched = punchup_chain.invoke({\"chapter\": chapter_txt, \"edits\": edits})\n",
        "                chapter_txt = strip_think(punched)\n",
        "    except Exception:\n",
        "        data = None  # keep chapter as-is if eval/punch-up fails\n",
        "\n",
        "    return chapter_txt, data\n",
        "\n",
        "from concurrent.futures import ThreadPoolExecutor, as_completed\n",
        "with ThreadPoolExecutor(max_workers=MAX_WORKERS) as ex:\n",
        "    futures = { ex.submit(write_one, i): i for i in range(len(outline)) }\n",
        "    for fut in tqdm(as_completed(futures), total=len(futures), desc=\"Chapters\"):\n",
        "        idx = futures[fut]\n",
        "        try:\n",
        "            ch_txt, notes = fut.result()\n",
        "        except Exception as e:\n",
        "            ch_txt, notes = f\"[Generation failed: {e}]\", None\n",
        "        chap_texts[idx] = ch_txt\n",
        "        editor_notes[idx] = notes\n",
        "\n",
        "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
        "# 7) Save to Word + Download (includes Editorâ€™s Notes appendix)\n",
        "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
        "doc = docx.Document()\n",
        "doc.add_heading(BOOK_TITLE, 0)\n",
        "doc.add_paragraph(f\"Seed idea: {SEED_IDEA}\")\n",
        "\n",
        "# Character Development Section\n",
        "if characters:\n",
        "    doc.add_page_break()\n",
        "    doc.add_heading(\"Character Development\", level=1)\n",
        "    for c in characters:\n",
        "        name = c.get(\"name\",\"(Unnamed)\")\n",
        "        role = c.get(\"role\",\"\")\n",
        "        arc  = c.get(\"development_arc\",\"\")\n",
        "        doc.add_heading(name, level=2)\n",
        "        if role: doc.add_paragraph(f\"Role: {role}\")\n",
        "        if arc:  doc.add_paragraph(arc)\n",
        "\n",
        "# Chapters\n",
        "for i, (meta, text) in enumerate(zip(outline, chap_texts), start=1):\n",
        "    doc.add_page_break()\n",
        "    doc.add_heading(f\"Chapter {i}: {meta['title']}\", level=1)\n",
        "    doc.add_paragraph(meta['description'], style=\"Intense Quote\")\n",
        "    doc.add_paragraph((text or \"\").strip())\n",
        "\n",
        "# Editorâ€™s Notes (Auto-Eval)\n",
        "doc.add_page_break()\n",
        "doc.add_heading(\"Editorâ€™s Notes (Auto-Eval)\", level=1)\n",
        "for i, (meta, notes) in enumerate(zip(outline, editor_notes), start=1):\n",
        "    doc.add_heading(f\"Chapter {i}: {meta['title']}\", level=2)\n",
        "    if not notes or \"scores\" not in notes:\n",
        "        doc.add_paragraph(\"No evaluation available.\")\n",
        "        continue\n",
        "    scores = notes[\"scores\"]\n",
        "    one_liner = notes.get(\"one_sentence_note\",\"\")\n",
        "    edits = notes.get(\"three_micro_edits\", [])\n",
        "    try:\n",
        "        avg_score = sum(float(scores[k]) for k in scores)/len(scores)\n",
        "    except Exception:\n",
        "        avg_score = None\n",
        "    doc.add_paragraph(\"Scores: \" + \", \".join(f\"{k}: {scores[k]}\" for k in scores))\n",
        "    if avg_score is not None:\n",
        "        doc.add_paragraph(f\"Average: {avg_score:.2f}\")\n",
        "    if one_liner:\n",
        "        doc.add_paragraph(f\"Note: {one_liner}\")\n",
        "    if edits:\n",
        "        for e in edits:\n",
        "            doc.add_paragraph(f\"â€¢ {e}\")\n",
        "\n",
        "fn = BOOK_TITLE.replace(\" \", \"_\") + \".docx\"\n",
        "doc.save(fn)\n",
        "print(f\"ğŸ“˜ Saved {fn}\")\n",
        "files.download(fn)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wZtOSXq8lG-f",
        "outputId": "be6855cf-d9f2-4d71-cd62-9d6c474a83de"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m0.0/253.0 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[91mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[91mâ•¸\u001b[0m\u001b[90mâ”\u001b[0m \u001b[32m245.8/253.0 kB\u001b[0m \u001b[31m8.1 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m253.0/253.0 kB\u001b[0m \u001b[31m5.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hâœ… Ollama status: 200\n",
            "\u001b[?2026h\u001b[?25l\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\n",
            "\u001b[?2026h\u001b[?25l\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\n",
            "â†’ Generating 20-chapter outline in chunks of ~10â€¦\n",
            "âš ï¸ Outline chunk parse failed (empty); retryingâ€¦\n",
            "âš ï¸ Outline chunk parse failed (empty); retryingâ€¦\n",
            "âš ï¸ Outline chunk parse failed (empty); retryingâ€¦\n",
            "âœ” Final outline: 20 chapters\n",
            "\n",
            "â†’ Generating 3 charactersâ€¦\n",
            "âœ” Got 3 characters\n",
            "\n",
            "â†’ Generating chapters in parallelâ€¦\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Chapters: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 20/20 [11:44:45<00:00, 2114.26s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ğŸ“˜ Saved Artificial_Influencers_2.docx\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_b4f68202-297b-4dc7-9459-b96cce1a86ab\", \"Artificial_Influencers_2.docx\", 75934)"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "cuz_pU0eC0Lg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "X0ZgrXeDC0BM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#This verson has knobs to make it better maybe\n",
        "\n",
        "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
        "# 0) Colab Setup: install & launch Ollama (planner/evaluator + writer)\n",
        "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
        "!pip install --quiet langchain-ollama python-docx tqdm\n",
        "\n",
        "import os, threading, subprocess, time, requests, json, re\n",
        "from typing import List, Any, Dict\n",
        "from concurrent.futures import ThreadPoolExecutor, as_completed\n",
        "from collections import Counter\n",
        "from tqdm import tqdm\n",
        "import docx\n",
        "from google.colab import files\n",
        "\n",
        "# Unset any OpenAI/LiteLLM envs that could hijack LangChain\n",
        "for v in [\n",
        "    \"OPENAI_API_KEY\",\n",
        "    \"LITELLM_PROVIDER\", \"LITELLM_MODEL\", \"LITELLM_BASE_URL\",\n",
        "    \"LITELL M_PROVIDER\", \"LITELL M_MODEL\", \"LITELL M_BASE_URL\"  # catch stray typos\n",
        "]:\n",
        "    os.environ.pop(v, None)\n",
        "\n",
        "os.environ[\"OLLAMA_HOST\"]    = \"127.0.0.1:11434\"\n",
        "os.environ[\"OLLAMA_ORIGINS\"] = \"*\"\n",
        "\n",
        "# Install & start Ollama\n",
        "!curl -fsSL https://ollama.com/install.sh -o install.sh\n",
        "!bash install.sh >/dev/null 2>&1 || true\n",
        "\n",
        "def _serve_ollama():\n",
        "    subprocess.Popen([\"ollama\",\"serve\"], stderr=subprocess.DEVNULL, stdout=subprocess.DEVNULL)\n",
        "\n",
        "threading.Thread(target=_serve_ollama, daemon=True).start()\n",
        "time.sleep(8)\n",
        "print(\"âœ… Ollama status:\", requests.get(\"http://127.0.0.1:11434\").status_code)\n",
        "\n",
        "# Pull models: planner/evaluator (DeepSeek-R1) and writer (Llama 3.1)\n",
        "!ollama pull deepseek-r1:1.5b\n",
        "!ollama pull llama3.1:8b\n",
        "\n",
        "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
        "# 1) Imports (LangChain) & User Inputs\n",
        "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
        "from langchain_ollama import OllamaLLM\n",
        "from langchain_core.prompts import PromptTemplate  # modern import\n",
        "\n",
        "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
        "# User parameters\n",
        "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
        "NUM_CH       = 20  # set 70 when you're happy with results\n",
        "SEED_IDEA    = (\"This idea is for a technothriller: Dr. Lena Park â€” a brilliant but introverted data scientist at Datum, \"\n",
        "                \"a social-media analytics startup. She notices impossible engagement \"\n",
        "                \"patterns in a rising star; her investigation unravels a conspiracy \"\n",
        "                \"of AI-driven â€œinfluencersâ€ masquerading as humansâ€”and she must decide \"\n",
        "                \"whether to expose the truth or risk blowing up the platform.\")\n",
        "BOOK_TITLE   = \"Artificial Influencers 2\"\n",
        "MODE         = \"fiction\"  # or \"philosophy\"\n",
        "\n",
        "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
        "# 2) LLMs & Core Prompts (using the | operator, not LLMChain)\n",
        "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
        "planner_llm = OllamaLLM(\n",
        "    model=\"deepseek-r1:1.5b\",\n",
        "    base_url=\"http://127.0.0.1:11434\",\n",
        "    temperature=0.3,  # lower â‡’ stricter structure for NDJSON/JSON\n",
        ")\n",
        "writer_llm  = OllamaLLM(\n",
        "    model=\"llama3.1:8b\",\n",
        "    base_url=\"http://127.0.0.1:11434\",\n",
        "    temperature=0.8,\n",
        ")\n",
        "\n",
        "# NDJSON prompts (MUCH easier to parse than JSON arrays)\n",
        "outline_prompt = PromptTemplate(\n",
        "    input_variables=[\"topic\",\"count\"],\n",
        "    template=(\n",
        "\"You are a creative fiction author. Generate exactly {count} UNIQUE chapter seeds \"\n",
        "\"for the book below. OUTPUT FORMAT: **NDJSON**, one compact JSON object per line, \"\n",
        "\"no leading numbering, no extra text, no trailing commas, no code fences.\\n\\n\"\n",
        "\"Each line MUST be like:\\n\"\n",
        "'{{\\\"title\\\":\\\"...\\\",\\\"description\\\":\\\"...\\\"}}\\\\n'\n",
        "\"\\nBook idea:\\n{topic}\\n\"\n",
        "    )\n",
        ")\n",
        "\n",
        "character_prompt = PromptTemplate(\n",
        "    input_variables=[\"outline\",\"num_chars\"],\n",
        "    template=(\n",
        "\"Given this chapter outline (JSON list):\\n{outline}\\n\\n\"\n",
        "\"Create exactly {num_chars} main characters.\\n\"\n",
        "\"OUTPUT FORMAT: **NDJSON**, one compact JSON object per line (no array, no extra text):\\n\"\n",
        "'{{\\\"name\\\":\\\"...\\\",\\\"role\\\":\\\"...\\\",\\\"development_arc\\\":\\\"...\\\"}}'\n",
        "    )\n",
        ")\n",
        "\n",
        "chapter_prompt = PromptTemplate(\n",
        "    input_variables=[\"title\",\"description\",\"idea\"],\n",
        "    template=(\n",
        "\"\"\"Write a ~2200â€“3200 word chapter titled \"{title}\".\n",
        "Seed idea: {idea}\n",
        "Chapter description: \"{description}\"\n",
        "\n",
        "Constraints:\n",
        "- NO meta commentary, NO analysis of your process, NO decision making.\n",
        "- Assume the reader remembers prior chapters; do not re-explain backstory.\n",
        "- Maintain continuity, but introduce at least one fresh obstacle, one vivid sensory beat, and one believable surprise.\n",
        "- Use concrete, precise details; avoid clichÃ©s.\n",
        "- End with a small but real unresolved tension.\n",
        "Return TEXT ONLY.\n",
        "\"\"\"\n",
        "    )\n",
        ")\n",
        "\n",
        "REVISION_PROMPT = PromptTemplate(\n",
        "    input_variables=[\"chapter\",\"title\",\"description\",\"ledger\"],\n",
        "    template=(\n",
        "\"\"\"Revise the chapter to reduce repetition with earlier chapters while improving novelty and tension.\n",
        "Keep the same characters and continuity, but change scene dynamics, setting details, and micro-beats.\n",
        "\n",
        "Rules:\n",
        "- Do NOT re-explain backstory already known.\n",
        "- Add at least one fresh obstacle, one specific sensory detail, and one surprising but plausible turn.\n",
        "- Preserve voice and POV.\n",
        "Return TEXT ONLY.\n",
        "\n",
        "Title: {title}\n",
        "Description: {description}\n",
        "\n",
        "Do-not-repeat ledger (phrases/scenes to avoid): {ledger}\n",
        "\n",
        "Chapter draft:\n",
        "{chapter}\n",
        "\"\"\"\n",
        "    )\n",
        ")\n",
        "\n",
        "# NOTE: braces escaped below ({{ â€¦ }}) so LangChain doesn't treat them as variables\n",
        "EVAL_PROMPT = PromptTemplate(\n",
        "    input_variables=[\"chapter\"],\n",
        "    template=(\n",
        "\"\"\"You are a tough fiction editor. Rate the chapter (1â€“10) on:\n",
        "- pacing\n",
        "- tension\n",
        "- voice\n",
        "- imagery\n",
        "- dialogue\n",
        "- novelty\n",
        "\n",
        "Return STRICT JSON only:\n",
        "{{\"scores\":{{\"pacing\":x,\"tension\":x,\"voice\":x,\"imagery\":x,\"dialogue\":x,\"novelty\":x}},\"one_sentence_note\":\"...\",\"three_micro_edits\":[\"...\",\"...\",\"...\"]}}\n",
        "\n",
        "Chapter:\n",
        "{chapter}\n",
        "\"\"\"\n",
        "    )\n",
        ")\n",
        "\n",
        "PUNCHUP_PROMPT = PromptTemplate(\n",
        "    input_variables=[\"chapter\",\"edits\"],\n",
        "    template=(\n",
        "\"\"\"Apply these micro-edits to strengthen the chapter without changing the plot:\n",
        "- {edits}\n",
        "\n",
        "Rules:\n",
        "- Keep POV, continuity, and length roughly the same (Â±10%).\n",
        "- Add concrete sensory details.\n",
        "- Tighten weak sentences; remove clichÃ©s.\n",
        "Return TEXT ONLY.\n",
        "\n",
        "Chapter:\n",
        "{chapter}\n",
        "\"\"\"\n",
        "    )\n",
        ")\n",
        "\n",
        "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
        "# 2.a THEME/MOTIF bible, BEATS planner, dialogue tuner, anti-clichÃ©, marketing\n",
        "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
        "THEME_PROMPT = PromptTemplate(\n",
        "    input_variables=[\"topic\",\"outline\"],\n",
        "    template=(\n",
        "\"\"\"You are a development editor. From the seed idea and outline, extract:\n",
        "- 3â€“5 core THEMES (short phrases)\n",
        "- 6â€“12 recurring MOTIFS or props (e.g., \"glitch-art\", \"rain-soaked streets\")\n",
        "- 3â€“6 PROMISES to the reader (e.g., \"ethical tension\", \"reveal of hidden mastermind\")\n",
        "- A one-sentence LOGLINE pitched to a general audience\n",
        "- Genre expectations to signal with setting & imagery (GENRE_SIGNALS, 5â€“8 phrases)\n",
        "\n",
        "Return STRICT JSON:\n",
        "{{\n",
        "  \"themes\": [\"...\"],\n",
        "  \"motifs\": [\"...\"],\n",
        "  \"promises\": [\"...\"],\n",
        "  \"logline\": \"...\",\n",
        "  \"genre_signals\": [\"...\"]\n",
        "}}\n",
        "\n",
        "Seed idea: {topic}\n",
        "Outline: {outline}\n",
        "\"\"\"\n",
        "    )\n",
        ")\n",
        "\n",
        "BEATS_PROMPT = PromptTemplate(\n",
        "    input_variables=[\"title\",\"description\",\"theme_bible\",\"motif_ledger\"],\n",
        "    template=(\n",
        "\"\"\"Plan a tight beat sheet for the chapter with approx. 8â€“12 beats following a tension curve.\n",
        "Enforce: strong opening hook line, mid-chapter reversal, and a cliffhanger/stinger.\n",
        "\n",
        "Constraints:\n",
        "- Integrate 1â€“2 MOTIFS from motif_ledger (callbacks) and 1 FRESH setting detail aligned to genre_signals.\n",
        "- Target dialogue ratio: 30â€“45% of lines contain dialogue.\n",
        "- Specify a SENSORY PALETTE (2â€“3 senses to emphasize).\n",
        "- Map an EMOTION ARC over beats (e.g., curiosity â†’ dread â†’ resolve).\n",
        "\n",
        "Return STRICT JSON:\n",
        "{{\n",
        "  \"beats\": [\n",
        "    {{\"name\":\"Hook\",\"goal\":\"...\",\"conflict\":\"...\",\"setting\":\"...\",\"emotion\":\"...\"}},\n",
        "    ...\n",
        "  ],\n",
        "  \"dialogue_target_pct\": 0.38,\n",
        "  \"sensory_palette\": [\"sound\",\"smell\"],\n",
        "  \"foreshadow\":\"...\",\n",
        "  \"callback_motif\":\"...\"\n",
        "}}\n",
        "\n",
        "Title: {title}\n",
        "Description: {description}\n",
        "THEME_BIBLE: {theme_bible}\n",
        "MOTIF_LEDGER: {motif_ledger}\n",
        "\"\"\"\n",
        "    )\n",
        ")\n",
        "\n",
        "CHAPTER_WITH_BEATS_PROMPT = PromptTemplate(\n",
        "    input_variables=[\"title\",\"description\",\"idea\",\"plan\",\"themes\",\"sensory_palette\",\"dialogue_target\"],\n",
        "    template=(\n",
        "\"\"\"Write a ~2200â€“3200 word chapter titled \"{title}\".\n",
        "\n",
        "Seed idea: {idea}\n",
        "Mini-brief: {description}\n",
        "Plan (beats): {plan}\n",
        "\n",
        "Must do:\n",
        "- OPEN with a punchy 1â€“2 sentence HOOK that raises a concrete question.\n",
        "- Emphasize SENSORY PALETTE: {sensory_palette}\n",
        "- Aim for DIALOGUE DENSITY â‰ˆ {dialogue_target:.2f} (about 30â€“45% lines include dialogue).\n",
        "- Integrate 1 motif or prop from the plan naturally.\n",
        "- Midpoint reversal that reframes stakes.\n",
        "- END with a plausible CLIFFHANGER/STINGER (no meta).\n",
        "\n",
        "Style:\n",
        "- Concrete details, crisp verbs; avoid clichÃ©s.\n",
        "- Maintain POV and continuity; no backstory dumps.\n",
        "\n",
        "Themes to subtly reinforce: {themes}\n",
        "Return TEXT ONLY.\n",
        "\"\"\"\n",
        "    )\n",
        ")\n",
        "\n",
        "DIALOGUE_TUNER_PROMPT = PromptTemplate(\n",
        "    input_variables=[\"chapter\",\"target\"],\n",
        "    template=(\n",
        "\"\"\"Revise the chapter to adjust dialogue density to â‰ˆ {target:.2f} (Â±0.08).\n",
        "Keep plot and beats intact. Do not shorten by more than 10% or lengthen by more than 10%.\n",
        "Return TEXT ONLY.\n",
        "\n",
        "Chapter:\n",
        "{chapter}\n",
        "\"\"\"\n",
        "    )\n",
        ")\n",
        "\n",
        "DECLICHE_PROMPT = PromptTemplate(\n",
        "    input_variables=[\"chapter\"],\n",
        "    template=(\n",
        "\"\"\"Rewrite at sentence-level to remove clichÃ©s, generic metaphors, and filler.\n",
        "Replace with specific, concrete imagery fitting a near-future techno-thriller vibe.\n",
        "Preserve plot, POV, beats, and length (Â±5%). Return TEXT ONLY.\n",
        "\n",
        "Chapter:\n",
        "{chapter}\n",
        "\"\"\"\n",
        "    )\n",
        ")\n",
        "\n",
        "MOTIF_MINER_PROMPT = PromptTemplate(\n",
        "    input_variables=[\"chapter\"],\n",
        "    template=(\n",
        "\"\"\"Extract 1â€“3 recurring motifs/props/images present in this chapter (short noun phrases).\n",
        "Return STRICT JSON: {{\"motifs\":[\"...\"]}}\n",
        "\n",
        "Chapter:\n",
        "{chapter}\n",
        "\"\"\"\n",
        "    )\n",
        ")\n",
        "\n",
        "BLURB_PROMPT = PromptTemplate(\n",
        "    input_variables=[\"title\",\"logline\",\"themes\",\"promises\"],\n",
        "    template=(\n",
        "\"\"\"Write:\n",
        "1) A high-impact back-cover BLURB (120â€“160 words) using the logline and themes.\n",
        "2) A 1-sentence hook for retailer product pages.\n",
        "3) 3 short BookTok/Bookstagram snippets (â‰¤140 chars each).\n",
        "\n",
        "Return STRICT JSON:\n",
        "{{\n",
        "  \"blurb\":\"...\",\n",
        "  \"product_hook\":\"...\",\n",
        "  \"snippets\": [\"...\",\"...\",\"...\"]\n",
        "}}\n",
        "\n",
        "Title: {title}\n",
        "Logline: {logline}\n",
        "Themes: {themes}\n",
        "Promises: {promises}\n",
        "\"\"\"\n",
        "    )\n",
        ")\n",
        "\n",
        "# Build chains with the pipe operator\n",
        "outline_chain     = outline_prompt               | planner_llm\n",
        "character_chain   = character_prompt             | planner_llm\n",
        "chapter_chain     = chapter_prompt               | writer_llm\n",
        "revision_chain    = REVISION_PROMPT              | writer_llm\n",
        "eval_chain        = EVAL_PROMPT                  | planner_llm\n",
        "punchup_chain     = PUNCHUP_PROMPT               | writer_llm\n",
        "\n",
        "theme_chain       = THEME_PROMPT                 | planner_llm\n",
        "beats_chain       = BEATS_PROMPT                 | planner_llm\n",
        "chapter_beats_llm = CHAPTER_WITH_BEATS_PROMPT    | writer_llm\n",
        "dialogue_tuner    = DIALOGUE_TUNER_PROMPT        | writer_llm\n",
        "decliche_chain    = DECLICHE_PROMPT              | writer_llm\n",
        "motif_miner       = MOTIF_MINER_PROMPT           | planner_llm\n",
        "blurb_chain       = BLURB_PROMPT                 | planner_llm\n",
        "\n",
        "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
        "# 3) Utilities: strip <think>â€¦</think>, parse NDJSON/JSON, similarity guards\n",
        "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
        "THINK_RE = re.compile(r\"<think>.*?</think>\\s*\", flags=re.S|re.I)\n",
        "FENCE_RE = re.compile(r\"```(?:json)?|```\", flags=re.I)\n",
        "\n",
        "def strip_think(x: Any) -> str:\n",
        "    s = x[\"text\"] if isinstance(x, dict) and \"text\" in x else str(x)\n",
        "    s = THINK_RE.sub(\"\", s)\n",
        "    s = FENCE_RE.sub(\"\", s)\n",
        "    return s.strip()\n",
        "\n",
        "def parse_ndjson(text: str, expected: int = None) -> List[dict]:\n",
        "    out = []\n",
        "    for ln in text.splitlines():\n",
        "        ln = ln.strip()\n",
        "        if not ln:\n",
        "            continue\n",
        "        # ignore accidental bullets/numbering\n",
        "        if ln[:2] in (\"- \", \"* \"):\n",
        "            ln = ln[2:].strip()\n",
        "        if ln and ln[0].isdigit() and ln.lstrip().split(\" \",1)[0].rstrip(\".\").isdigit():\n",
        "            ln = re.sub(r\"^\\d+\\.\\s*\", \"\", ln)  # \"1. { ... }\" â†’ \"{ ... }\"\n",
        "        try:\n",
        "            obj = json.loads(ln)\n",
        "            if isinstance(obj, dict):\n",
        "                out.append(obj)\n",
        "        except json.JSONDecodeError:\n",
        "            # tiny auto-fix: smart quotes / trailing commas\n",
        "            fix = ln.replace(\"â€œ\",\"\\\"\").replace(\"â€\",\"\\\"\").replace(\"â€™\",\"'\")\n",
        "            fix = re.sub(r\",\\s*}\", \"}\", fix)\n",
        "            fix = re.sub(r\",\\s*]\", \"]\", fix)\n",
        "            try:\n",
        "                obj = json.loads(fix)\n",
        "                if isinstance(obj, dict):\n",
        "                    out.append(obj)\n",
        "            except Exception:\n",
        "                continue\n",
        "    return out\n",
        "\n",
        "def jaccard(a: str, b: str) -> float:\n",
        "    A = set(re.findall(r\"[a-z0-9']+\", a.lower()))\n",
        "    B = set(re.findall(r\"[a-z0-9']+\", b.lower()))\n",
        "    if not A or not B: return 0.0\n",
        "    return len(A & B) / len(A | B)\n",
        "\n",
        "def too_similar(ch1: Dict[str,str], ch2: Dict[str,str]) -> bool:\n",
        "    t_sim = jaccard(ch1[\"title\"], ch2[\"title\"])\n",
        "    d_sim = jaccard(ch1[\"description\"], ch2[\"description\"])\n",
        "    return (t_sim > 0.65) or (t_sim > 0.45 and d_sim > 0.55)\n",
        "\n",
        "def bigram_overlap(a: str, b: str) -> float:\n",
        "    def bigrams(s):\n",
        "        toks = re.findall(r\"[a-z0-9']+\", s.lower())\n",
        "        return set(zip(toks, toks[1:])) if len(toks) > 1 else set()\n",
        "    A, B = bigrams(a), bigrams(b)\n",
        "    denom = len(A | B) if (A or B) else 1\n",
        "    return len(A & B) / denom\n",
        "\n",
        "def top_trigrams(text: str, k: int = 30) -> List[str]:\n",
        "    toks = re.findall(r\"[a-z0-9']+\", text.lower())\n",
        "    tris = Counter(zip(toks, toks[1:], toks[2:]))\n",
        "    return [\" \".join(t) for t,_ in tris.most_common(k)]\n",
        "\n",
        "# 3.a Dialogue ratio & strict JSON helper\n",
        "def approx_dialogue_ratio(text: str) -> float:\n",
        "    # crude but robust: count lines with quotes or leading em-dash dialogue\n",
        "    lines = [ln.strip() for ln in text.splitlines() if ln.strip()]\n",
        "    if not lines: return 0.0\n",
        "    dial = sum(1 for ln in lines if re.search(r'[\"â€œâ€]|^â€”', ln))\n",
        "    return dial / max(1, len(lines))\n",
        "\n",
        "def parse_strict_json(s: str) -> dict:\n",
        "    s = strip_think(s)\n",
        "    m = re.search(r\"\\{[\\s\\S]*\\}\\s*$\", s)\n",
        "    if not m: return {}\n",
        "    try:\n",
        "        return json.loads(m.group(0))\n",
        "    except Exception:\n",
        "        # lenient fixes\n",
        "        fix = m.group(0).replace(\"â€œ\",\"\\\"\").replace(\"â€\",\"\\\"\").replace(\"â€™\",\"'\")\n",
        "        fix = re.sub(r\",\\s*}\", \"}\", fix)\n",
        "        fix = re.sub(r\",\\s*]\", \"]\", fix)\n",
        "        try: return json.loads(fix)\n",
        "        except Exception: return {}\n",
        "\n",
        "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
        "# 4) Outline generation with NDJSON + retry + strict dedupe\n",
        "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
        "print(f\"â†’ Generating {NUM_CH}-chapter outline in chunks of ~10â€¦\")\n",
        "outline, seen_titles = [], set()\n",
        "chunk = 10\n",
        "attempts = 0\n",
        "MAX_ATTEMPTS = 40\n",
        "\n",
        "while len(outline) < NUM_CH and attempts < MAX_ATTEMPTS:\n",
        "    ask = min(chunk, NUM_CH - len(outline))\n",
        "    raw = outline_chain.invoke({\"topic\": SEED_IDEA, \"count\": ask})\n",
        "    attempts += 1\n",
        "    lines = parse_ndjson(strip_think(raw), expected=ask)\n",
        "    if not lines:\n",
        "        print(\"âš ï¸ Outline chunk parse failed (empty); retryingâ€¦\")\n",
        "        continue\n",
        "    added = 0\n",
        "    for ch in lines:\n",
        "        cand = {\n",
        "            \"title\": (ch.get(\"title\") or \"\").strip(),\n",
        "            \"description\": (ch.get(\"description\") or \"\").strip()\n",
        "        }\n",
        "        if not cand[\"title\"] or not cand[\"description\"]:\n",
        "            continue\n",
        "        if cand[\"title\"] in seen_titles:\n",
        "            continue\n",
        "        if any(too_similar(cand, existing) for existing in outline):\n",
        "            continue\n",
        "        outline.append(cand)\n",
        "        seen_titles.add(cand[\"title\"])\n",
        "        added += 1\n",
        "        if len(outline) >= NUM_CH:\n",
        "            break\n",
        "    if added == 0:\n",
        "        print(\"â„¹ï¸ No new unique chapters from this chunk; retryingâ€¦\")\n",
        "\n",
        "print(f\"âœ” Final outline: {len(outline)} chapters\\n\")\n",
        "if len(outline) < NUM_CH:\n",
        "    print(\"âš ï¸ Could not reach target count; proceeding with what we have.\")\n",
        "\n",
        "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
        "# 5) Character Bible (NDJSON + retry) + Theme/Motif Bible\n",
        "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
        "NUM_CHAR = max(3, min(10, NUM_CH//8))\n",
        "print(f\"â†’ Generating {NUM_CHAR} charactersâ€¦\")\n",
        "characters = []\n",
        "for _ in range(6):  # a few retries if parsing fails\n",
        "    raw_chars = character_chain.invoke({\n",
        "        \"outline\": json.dumps(outline, ensure_ascii=False),\n",
        "        \"num_chars\": NUM_CHAR\n",
        "    })\n",
        "    characters = parse_ndjson(strip_think(raw_chars), expected=NUM_CHAR)\n",
        "    if len(characters) == NUM_CHAR:\n",
        "        break\n",
        "print(f\"âœ” Got {len(characters)} characters\\n\")\n",
        "\n",
        "# 5.a Theme/Motif bible from outline\n",
        "print(\"â†’ Building theme/motif bibleâ€¦\")\n",
        "theme_raw = theme_chain.invoke({\n",
        "    \"topic\": SEED_IDEA,\n",
        "    \"outline\": json.dumps(outline, ensure_ascii=False)\n",
        "})\n",
        "THEME_BIBLE = parse_strict_json(theme_raw) or {\n",
        "    \"themes\": [],\n",
        "    \"motifs\": [],\n",
        "    \"promises\": [],\n",
        "    \"logline\": \"\",\n",
        "    \"genre_signals\": []\n",
        "}\n",
        "MOTIF_LEDGER = list(THEME_BIBLE.get(\"motifs\", []))  # seed with global motifs\n",
        "print(\"âœ” Theme bible ready.\\n\")\n",
        "\n",
        "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
        "# 6) Chapter Generation (+ beats + dialogue tuner + anti-clichÃ©) with guards\n",
        "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
        "print(\"â†’ Generating chapters in parallelâ€¦\")\n",
        "chap_texts = [None]*len(outline)\n",
        "editor_notes = [None]*len(outline)\n",
        "\n",
        "MAX_WORKERS = 3  # adjust if your session is slower/faster\n",
        "BIGRAM_THRESHOLD = 0.22  # repetition strictness\n",
        "\n",
        "def write_one(idx):\n",
        "    meta = outline[idx]\n",
        "\n",
        "    # 1) Plan beats with callbacks to existing motif ledger\n",
        "    plan_raw = beats_chain.invoke({\n",
        "        \"title\": meta[\"title\"],\n",
        "        \"description\": meta[\"description\"],\n",
        "        \"theme_bible\": json.dumps(THEME_BIBLE, ensure_ascii=False),\n",
        "        \"motif_ledger\": json.dumps(MOTIF_LEDGER[-12:], ensure_ascii=False)  # recent motifs\n",
        "    })\n",
        "    plan = parse_strict_json(plan_raw)\n",
        "    dialogue_target = float(plan.get(\"dialogue_target_pct\", 0.36))\n",
        "    sensory_palette = plan.get(\"sensory_palette\", [\"sight\",\"sound\"])\n",
        "    plan_json = json.dumps(plan.get(\"beats\", []), ensure_ascii=False)\n",
        "\n",
        "    # 2) Draft with hooks, sensory palette, dialogue target\n",
        "    res = chapter_beats_llm.invoke({\n",
        "        \"title\": meta[\"title\"],\n",
        "        \"description\": meta[\"description\"],\n",
        "        \"idea\": SEED_IDEA,\n",
        "        \"plan\": plan_json,\n",
        "        \"themes\": \", \".join(THEME_BIBLE.get(\"themes\", [])),\n",
        "        \"sensory_palette\": \", \".join(sensory_palette),\n",
        "        \"dialogue_target\": dialogue_target\n",
        "    })\n",
        "    chapter_txt = strip_think(res)\n",
        "\n",
        "    # 3) Repetition guard vs earlier chapters\n",
        "    ledger = []\n",
        "    for j in range(idx):\n",
        "        prev = chap_texts[j]\n",
        "        if not prev: continue\n",
        "        if bigram_overlap(chapter_txt, prev) > BIGRAM_THRESHOLD:\n",
        "            ledger.extend(top_trigrams(prev, k=10))\n",
        "    ledger = list(dict.fromkeys(ledger))[:60]\n",
        "    if ledger:\n",
        "        revised = revision_chain.invoke({\n",
        "            \"chapter\": chapter_txt,\n",
        "            \"title\": meta[\"title\"],\n",
        "            \"description\": meta[\"description\"],\n",
        "            \"ledger\": \"; \".join(ledger)\n",
        "        })\n",
        "        chapter_txt = strip_think(revised)\n",
        "\n",
        "    # 4) Dialogue density tuner (Â±8%)\n",
        "    dr = approx_dialogue_ratio(chapter_txt)\n",
        "    if abs(dr - dialogue_target) > 0.08:\n",
        "        tuned = dialogue_tuner.invoke({\"chapter\": chapter_txt, \"target\": dialogue_target})\n",
        "        chapter_txt = strip_think(tuned)\n",
        "\n",
        "    # 5) Anti-clichÃ© polish (tight, specific imagery)\n",
        "    polished = decliche_chain.invoke({\"chapter\": chapter_txt})\n",
        "    chapter_txt = strip_think(polished)\n",
        "\n",
        "    # 6) Auto-evaluation + optional punch-up\n",
        "    data = None\n",
        "    try:\n",
        "        report_raw = eval_chain.invoke({\"chapter\": chapter_txt})\n",
        "        report_txt = strip_think(report_raw)\n",
        "        m = re.search(r\"\\{[\\s\\S]*\\}\\s*$\", report_txt)\n",
        "        if m:\n",
        "            data = json.loads(m.group(0))\n",
        "        if data and \"scores\" in data:\n",
        "            scores = data[\"scores\"]\n",
        "            avg_score = sum(float(scores[k]) for k in scores)/len(scores)\n",
        "            if avg_score < 7.5:\n",
        "                edits = \" | \".join(data.get(\"three_micro_edits\", [])) or \\\n",
        "                        \"Sharpen hooks; escalate mid-point reversal; add concrete sensory beats.\"\n",
        "                punched = punchup_chain.invoke({\"chapter\": chapter_txt, \"edits\": edits})\n",
        "                chapter_txt = strip_think(punched)\n",
        "    except Exception:\n",
        "        data = None\n",
        "\n",
        "    # 7) Mine motifs from this chapter â†’ update global ledger (for callbacks)\n",
        "    try:\n",
        "        mined_raw = motif_miner.invoke({\"chapter\": chapter_txt})\n",
        "        mined = parse_strict_json(mined_raw)\n",
        "        for m in (mined.get(\"motifs\") or []):\n",
        "            if m not in MOTIF_LEDGER:\n",
        "                MOTIF_LEDGER.append(m)\n",
        "    except Exception:\n",
        "        pass\n",
        "\n",
        "    return chapter_txt, data\n",
        "\n",
        "with ThreadPoolExecutor(max_workers=MAX_WORKERS) as ex:\n",
        "    futures = { ex.submit(write_one, i): i for i in range(len(outline)) }\n",
        "    for fut in tqdm(as_completed(futures), total=len(futures), desc=\"Chapters\"):\n",
        "        idx = futures[fut]\n",
        "        try:\n",
        "            ch_txt, notes = fut.result()\n",
        "        except Exception as e:\n",
        "            ch_txt, notes = f\"[Generation failed: {e}]\", None\n",
        "        chap_texts[idx] = ch_txt\n",
        "        editor_notes[idx] = notes\n",
        "\n",
        "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
        "# 7) Save to Word + Back-cover copy + Download (includes Editorâ€™s Notes)\n",
        "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
        "doc = docx.Document()\n",
        "doc.add_heading(BOOK_TITLE, 0)\n",
        "doc.add_paragraph(f\"Seed idea: {SEED_IDEA}\")\n",
        "\n",
        "# Character Development Section\n",
        "if characters:\n",
        "    doc.add_page_break()\n",
        "    doc.add_heading(\"Character Development\", level=1)\n",
        "    for c in characters:\n",
        "        name = c.get(\"name\",\"(Unnamed)\")\n",
        "        role = c.get(\"role\",\"\")\n",
        "        arc  = c.get(\"development_arc\",\"\")\n",
        "        doc.add_heading(name, level=2)\n",
        "        if role: doc.add_paragraph(f\"Role: {role}\")\n",
        "        if arc:  doc.add_paragraph(arc)\n",
        "\n",
        "# Chapters\n",
        "for i, (meta, text) in enumerate(zip(outline, chap_texts), start=1):\n",
        "    doc.add_page_break()\n",
        "    doc.add_heading(f\"Chapter {i}: {meta['title']}\", level=1)\n",
        "    doc.add_paragraph(meta['description'], style=\"Intense Quote\")\n",
        "    doc.add_paragraph((text or \"\").strip())\n",
        "\n",
        "# Editorâ€™s Notes (Auto-Eval)\n",
        "doc.add_page_break()\n",
        "doc.add_heading(\"Editorâ€™s Notes (Auto-Eval)\", level=1)\n",
        "for i, (meta, notes) in enumerate(zip(outline, editor_notes), start=1):\n",
        "    doc.add_heading(f\"Chapter {i}: {meta['title']}\", level=2)\n",
        "    if not notes or \"scores\" not in notes:\n",
        "        doc.add_paragraph(\"No evaluation available.\")\n",
        "        continue\n",
        "    scores = notes[\"scores\"]\n",
        "    one_liner = notes.get(\"one_sentence_note\",\"\")\n",
        "    edits = notes.get(\"three_micro_edits\", [])\n",
        "    try:\n",
        "        avg_score = sum(float(scores[k]) for k in scores)/len(scores)\n",
        "    except Exception:\n",
        "        avg_score = None\n",
        "    doc.add_paragraph(\"Scores: \" + \", \".join(f\"{k}: {scores[k]}\" for k in scores))\n",
        "    if avg_score is not None:\n",
        "        doc.add_paragraph(f\"Average: {avg_score:.2f}\")\n",
        "    if one_liner:\n",
        "        doc.add_paragraph(f\"Note: {one_liner}\")\n",
        "    if edits:\n",
        "        for e in edits:\n",
        "            doc.add_paragraph(f\"â€¢ {e}\")\n",
        "\n",
        "# 7.a Back-cover blurb + retailer hook + social snippets\n",
        "blurb_data = {}\n",
        "try:\n",
        "    blurb_raw = blurb_chain.invoke({\n",
        "        \"title\": BOOK_TITLE,\n",
        "        \"logline\": THEME_BIBLE.get(\"logline\",\"\"),\n",
        "        \"themes\": \", \".join(THEME_BIBLE.get(\"themes\", [])),\n",
        "        \"promises\": \", \".join(THEME_BIBLE.get(\"promises\", []))\n",
        "    })\n",
        "    blurb_data = parse_strict_json(blurb_raw) or {}\n",
        "except Exception:\n",
        "    blurb_data = {}\n",
        "\n",
        "doc.add_page_break()\n",
        "doc.add_heading(\"Back-Cover Copy & Retailer Hook\", level=1)\n",
        "if blurb_data.get(\"blurb\"):\n",
        "    doc.add_paragraph(blurb_data[\"blurb\"])\n",
        "if blurb_data.get(\"product_hook\"):\n",
        "    doc.add_paragraph(f\"\\nRetailer Hook: {blurb_data['product_hook']}\")\n",
        "if blurb_data.get(\"snippets\"):\n",
        "    doc.add_heading(\"Short Social Snippets\", level=2)\n",
        "    for s in blurb_data[\"snippets\"]:\n",
        "        doc.add_paragraph(f\"â€¢ {s}\")\n",
        "\n",
        "# Save & download\n",
        "fn = BOOK_TITLE.replace(\" \", \"_\") + \".docx\"\n",
        "doc.save(fn)\n",
        "print(f\"ğŸ“˜ Saved {fn}\")\n",
        "files.download(fn)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 512
        },
        "id": "gpKyThbfCz0V",
        "outputId": "27e5700c-61ad-4985-9794-a089d644d1d5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m0.0/253.0 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m253.0/253.0 kB\u001b[0m \u001b[31m11.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hâœ… Ollama status: 200\n",
            "\u001b[?2026h\u001b[?25l\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\n",
            "\u001b[?2026h\u001b[?25l\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\n",
            "â†’ Generating 20-chapter outline in chunks of ~10â€¦\n",
            "âš ï¸ Outline chunk parse failed (empty); retryingâ€¦\n",
            "âš ï¸ Outline chunk parse failed (empty); retryingâ€¦\n",
            "âš ï¸ Outline chunk parse failed (empty); retryingâ€¦\n",
            "âš ï¸ Outline chunk parse failed (empty); retryingâ€¦\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-2416734228.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    436\u001b[0m \u001b[0;32mwhile\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutline\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0mNUM_CH\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mattempts\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0mMAX_ATTEMPTS\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    437\u001b[0m     \u001b[0mask\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mchunk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mNUM_CH\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutline\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 438\u001b[0;31m     \u001b[0mraw\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moutline_chain\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minvoke\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m\"topic\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mSEED_IDEA\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"count\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mask\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    439\u001b[0m     \u001b[0mattempts\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    440\u001b[0m     \u001b[0mlines\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparse_ndjson\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstrip_think\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mraw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexpected\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mask\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/langchain_core/runnables/base.py\u001b[0m in \u001b[0;36minvoke\u001b[0;34m(self, input, config, **kwargs)\u001b[0m\n\u001b[1;32m   3047\u001b[0m                         \u001b[0minput_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minvoke\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3048\u001b[0m                     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3049\u001b[0;31m                         \u001b[0minput_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minvoke\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3050\u001b[0m         \u001b[0;31m# finish the root run\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3051\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mBaseException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/langchain_core/language_models/llms.py\u001b[0m in \u001b[0;36minvoke\u001b[0;34m(self, input, config, stop, **kwargs)\u001b[0m\n\u001b[1;32m    387\u001b[0m         \u001b[0mconfig\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mensure_config\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    388\u001b[0m         return (\n\u001b[0;32m--> 389\u001b[0;31m             self.generate_prompt(\n\u001b[0m\u001b[1;32m    390\u001b[0m                 \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_convert_input\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    391\u001b[0m                 \u001b[0mstop\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstop\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/langchain_core/language_models/llms.py\u001b[0m in \u001b[0;36mgenerate_prompt\u001b[0;34m(self, prompts, stop, callbacks, **kwargs)\u001b[0m\n\u001b[1;32m    764\u001b[0m     ) -> LLMResult:\n\u001b[1;32m    765\u001b[0m         \u001b[0mprompt_strings\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_string\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mp\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mprompts\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 766\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgenerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprompt_strings\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstop\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    767\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    768\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0moverride\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/langchain_core/language_models/llms.py\u001b[0m in \u001b[0;36mgenerate\u001b[0;34m(self, prompts, stop, callbacks, tags, metadata, run_name, run_id, **kwargs)\u001b[0m\n\u001b[1;32m    969\u001b[0m                 )\n\u001b[1;32m    970\u001b[0m             ]\n\u001b[0;32m--> 971\u001b[0;31m             return self._generate_helper(\n\u001b[0m\u001b[1;32m    972\u001b[0m                 \u001b[0mprompts\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    973\u001b[0m                 \u001b[0mstop\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/langchain_core/language_models/llms.py\u001b[0m in \u001b[0;36m_generate_helper\u001b[0;34m(self, prompts, stop, run_managers, new_arg_supported, **kwargs)\u001b[0m\n\u001b[1;32m    790\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    791\u001b[0m             output = (\n\u001b[0;32m--> 792\u001b[0;31m                 self._generate(\n\u001b[0m\u001b[1;32m    793\u001b[0m                     \u001b[0mprompts\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    794\u001b[0m                     \u001b[0mstop\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstop\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/langchain_ollama/llms.py\u001b[0m in \u001b[0;36m_generate\u001b[0;34m(self, prompts, stop, run_manager, **kwargs)\u001b[0m\n\u001b[1;32m    360\u001b[0m         \u001b[0mgenerations\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    361\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mprompt\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mprompts\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 362\u001b[0;31m             final_chunk = self._stream_with_aggregation(\n\u001b[0m\u001b[1;32m    363\u001b[0m                 \u001b[0mprompt\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    364\u001b[0m                 \u001b[0mstop\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstop\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/langchain_ollama/llms.py\u001b[0m in \u001b[0;36m_stream_with_aggregation\u001b[0;34m(self, prompt, stop, run_manager, verbose, **kwargs)\u001b[0m\n\u001b[1;32m    319\u001b[0m         \u001b[0mfinal_chunk\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    320\u001b[0m         \u001b[0mthinking_content\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 321\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0mstream_resp\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_create_generate_stream\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprompt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    322\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstream_resp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    323\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mstream_resp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"thinking\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/langchain_ollama/llms.py\u001b[0m in \u001b[0;36m_create_generate_stream\u001b[0;34m(self, prompt, stop, **kwargs)\u001b[0m\n\u001b[1;32m    263\u001b[0m     ) -> Iterator[Union[Mapping[str, Any], str]]:\n\u001b[1;32m    264\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_client\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 265\u001b[0;31m             yield from self._client.generate(\n\u001b[0m\u001b[1;32m    266\u001b[0m                 \u001b[0;34m**\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_generate_params\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprompt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstop\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    267\u001b[0m             )\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/ollama/_client.py\u001b[0m in \u001b[0;36minner\u001b[0;34m()\u001b[0m\n\u001b[1;32m    170\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mResponseError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresponse\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresponse\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstatus_code\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    171\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 172\u001b[0;31m           \u001b[0;32mfor\u001b[0m \u001b[0mline\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miter_lines\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    173\u001b[0m             \u001b[0mpart\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mjson\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloads\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mline\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    174\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0merr\u001b[0m \u001b[0;34m:=\u001b[0m \u001b[0mpart\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'error'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/httpx/_models.py\u001b[0m in \u001b[0;36miter_lines\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    927\u001b[0m         \u001b[0mdecoder\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mLineDecoder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    928\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mrequest_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_request\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 929\u001b[0;31m             \u001b[0;32mfor\u001b[0m \u001b[0mtext\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miter_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    930\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0mline\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdecoder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    931\u001b[0m                     \u001b[0;32myield\u001b[0m \u001b[0mline\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/httpx/_models.py\u001b[0m in \u001b[0;36miter_text\u001b[0;34m(self, chunk_size)\u001b[0m\n\u001b[1;32m    914\u001b[0m         \u001b[0mchunker\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextChunker\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mchunk_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mchunk_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    915\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mrequest_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_request\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 916\u001b[0;31m             \u001b[0;32mfor\u001b[0m \u001b[0mbyte_content\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miter_bytes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    917\u001b[0m                 \u001b[0mtext_content\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdecoder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbyte_content\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    918\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0mchunk\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mchunker\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext_content\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/httpx/_models.py\u001b[0m in \u001b[0;36miter_bytes\u001b[0;34m(self, chunk_size)\u001b[0m\n\u001b[1;32m    895\u001b[0m             \u001b[0mchunker\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mByteChunker\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mchunk_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mchunk_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    896\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mrequest_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_request\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 897\u001b[0;31m                 \u001b[0;32mfor\u001b[0m \u001b[0mraw_bytes\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miter_raw\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    898\u001b[0m                     \u001b[0mdecoded\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdecoder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mraw_bytes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    899\u001b[0m                     \u001b[0;32mfor\u001b[0m \u001b[0mchunk\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mchunker\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdecoded\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/httpx/_models.py\u001b[0m in \u001b[0;36miter_raw\u001b[0;34m(self, chunk_size)\u001b[0m\n\u001b[1;32m    949\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    950\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mrequest_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_request\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 951\u001b[0;31m             \u001b[0;32mfor\u001b[0m \u001b[0mraw_stream_bytes\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstream\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    952\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_bytes_downloaded\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mraw_stream_bytes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    953\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0mchunk\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mchunker\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mraw_stream_bytes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/httpx/_client.py\u001b[0m in \u001b[0;36m__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    151\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__iter__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mtyping\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIterator\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mbytes\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 153\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0mchunk\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stream\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    154\u001b[0m             \u001b[0;32myield\u001b[0m \u001b[0mchunk\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    155\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/httpx/_transports/default.py\u001b[0m in \u001b[0;36m__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    125\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__iter__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mtyping\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIterator\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mbytes\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    126\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mmap_httpcore_exceptions\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 127\u001b[0;31m             \u001b[0;32mfor\u001b[0m \u001b[0mpart\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_httpcore_stream\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    128\u001b[0m                 \u001b[0;32myield\u001b[0m \u001b[0mpart\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    129\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/httpcore/_sync/connection_pool.py\u001b[0m in \u001b[0;36m__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    405\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mBaseException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mexc\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    406\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 407\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mexc\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    408\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    409\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/httpcore/_sync/connection_pool.py\u001b[0m in \u001b[0;36m__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    401\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__iter__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mtyping\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIterator\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mbytes\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    402\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 403\u001b[0;31m             \u001b[0;32mfor\u001b[0m \u001b[0mpart\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stream\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    404\u001b[0m                 \u001b[0;32myield\u001b[0m \u001b[0mpart\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    405\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mBaseException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mexc\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/httpcore/_sync/http11.py\u001b[0m in \u001b[0;36m__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    340\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mShieldCancellation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    341\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 342\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mexc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    343\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    344\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/httpcore/_sync/http11.py\u001b[0m in \u001b[0;36m__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    332\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    333\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mTrace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"receive_response_body\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogger\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_request\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 334\u001b[0;31m                 \u001b[0;32mfor\u001b[0m \u001b[0mchunk\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_connection\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_receive_response_body\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    335\u001b[0m                     \u001b[0;32myield\u001b[0m \u001b[0mchunk\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    336\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mBaseException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mexc\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/httpcore/_sync/http11.py\u001b[0m in \u001b[0;36m_receive_response_body\u001b[0;34m(self, request)\u001b[0m\n\u001b[1;32m    201\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    202\u001b[0m         \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 203\u001b[0;31m             \u001b[0mevent\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_receive_event\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    204\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mevent\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mh11\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mData\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    205\u001b[0m                 \u001b[0;32myield\u001b[0m \u001b[0mbytes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mevent\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/httpcore/_sync/http11.py\u001b[0m in \u001b[0;36m_receive_event\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    215\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    216\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mevent\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mh11\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mNEED_DATA\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 217\u001b[0;31m                 data = self._network_stream.read(\n\u001b[0m\u001b[1;32m    218\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mREAD_NUM_BYTES\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    219\u001b[0m                 )\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/httpcore/_backends/sync.py\u001b[0m in \u001b[0;36mread\u001b[0;34m(self, max_bytes, timeout)\u001b[0m\n\u001b[1;32m    126\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mmap_exceptions\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexc_map\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    127\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sock\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msettimeout\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 128\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sock\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmax_bytes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    129\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    130\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mwrite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbuffer\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mbytes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mfloat\u001b[0m \u001b[0;34m|\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "7gvkXftzuqBr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "LbA1mNS6up98"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "JZtf-SFYup61"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "eKj3hFa9upxl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
        "# 0) Colab Setup: install & launch Ollama (with speed toggles & checkpointing)\n",
        "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
        "!pip install --quiet langchain-ollama python-docx tqdm\n",
        "\n",
        "import os, threading, subprocess, time, requests, json, re, shutil, pathlib, math\n",
        "from typing import List, Any, Dict\n",
        "from concurrent.futures import ThreadPoolExecutor, as_completed\n",
        "from collections import Counter\n",
        "from tqdm import tqdm\n",
        "import docx\n",
        "from google.colab import files\n",
        "\n",
        "# Avoid LangChain provider hijacks\n",
        "for v in [\n",
        "    \"OPENAI_API_KEY\",\n",
        "    \"LITELLM_PROVIDER\", \"LITELLM_MODEL\", \"LITELLM_BASE_URL\",\n",
        "    \"LITELL M_PROVIDER\", \"LITELL M_MODEL\", \"LITELL M_BASE_URL\"  # catch stray typos\n",
        "]:\n",
        "    os.environ.pop(v, None)\n",
        "\n",
        "# â€”â€” Speed/robustness knobs â€”â€”\n",
        "FAST_MODE = True                 # Flip to False when you're happy with outputs\n",
        "CHECKPOINT_DIR = \"book_ckpt\"     # Saves each chapter as it completes\n",
        "os.makedirs(CHECKPOINT_DIR, exist_ok=True)\n",
        "\n",
        "# Make Ollama conservative about parallelism in Colab\n",
        "os.environ[\"OLLAMA_MAX_LOADED_MODELS\"] = \"1\"\n",
        "os.environ[\"OLLAMA_NUM_PARALLEL\"] = \"1\"\n",
        "\n",
        "# Launch Ollama daemon\n",
        "os.environ[\"OLLAMA_HOST\"]    = \"127.0.0.1:11434\"\n",
        "os.environ[\"OLLAMA_ORIGINS\"] = \"*\"\n",
        "\n",
        "!curl -fsSL https://ollama.com/install.sh -o install.sh\n",
        "!bash install.sh >/dev/null 2>&1 || true\n",
        "\n",
        "def _serve_ollama():\n",
        "    subprocess.Popen([\"ollama\",\"serve\"], stderr=subprocess.DEVNULL, stdout=subprocess.DEVNULL)\n",
        "\n",
        "threading.Thread(target=_serve_ollama, daemon=True).start()\n",
        "time.sleep(8)\n",
        "print(\"âœ… Ollama health:\", requests.get(\"http://127.0.0.1:11434\").status_code)\n",
        "\n",
        "# GPU detection to size workers\n",
        "def _has_gpu():\n",
        "    try:\n",
        "        return shutil.which(\"nvidia-smi\") and (subprocess.run([\"nvidia-smi\"], capture_output=True).returncode==0)\n",
        "    except Exception:\n",
        "        return False\n",
        "HAS_GPU = bool(_has_gpu())\n",
        "print(\"ğŸ–¥ï¸ GPU:\", \"available\" if HAS_GPU else \"not detected\")\n",
        "\n",
        "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
        "# 1) User parameters (auto size by target pages â†’ chapters)\n",
        "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
        "BOOK_TITLE   = \"Artificial Influencers 2\"\n",
        "MODE         = \"fiction\"  # or \"nonfiction\"\n",
        "\n",
        "# Either set an explicit target page count, or leave None to auto-center the profile\n",
        "TARGET_PAGES = 320 if MODE == \"fiction\" else 280\n",
        "\n",
        "GENRE_PROFILE = {\n",
        "    \"fiction\":   {\"pages_min\": 280, \"pages_max\": 360, \"chapter_words_typical\": (2400, 3600)},\n",
        "    \"nonfiction\":{\"pages_min\": 220, \"pages_max\": 320, \"chapter_words_typical\": (3000, 4500)}\n",
        "}[MODE]\n",
        "\n",
        "if TARGET_PAGES is None:\n",
        "    TARGET_PAGES = (GENRE_PROFILE[\"pages_min\"] + GENRE_PROFILE[\"pages_max\"]) // 2\n",
        "\n",
        "# Words-per-page assumption (trade paperback-ish)\n",
        "WORDS_PER_PAGE = 275\n",
        "TARGET_WORDS   = int(TARGET_PAGES * WORDS_PER_PAGE)\n",
        "\n",
        "# Choose a target chapter length (midpoint of typical band), and derive initial chapter count:\n",
        "CH_MIN, CH_MAX = GENRE_PROFILE[\"chapter_words_typical\"]\n",
        "CH_TARGET_WORDS = int((CH_MIN + CH_MAX) / 2)\n",
        "NUM_CH = max(12, min(80, (TARGET_WORDS + CH_TARGET_WORDS - 1) // CH_TARGET_WORDS))\n",
        "\n",
        "# Your story seed:\n",
        "SEED_IDEA = (\n",
        "    \"idea for technothriller: Dr. Lena Park â€” a brilliant but introverted data scientist at Datum, \"\n",
        "    \"a social-media analytics startup. She notices impossible engagement \"\n",
        "    \"patterns in a rising star; her investigation unravels a conspiracy \"\n",
        "    \"of AI-driven 'influencers' masquerading as humansâ€”and she must decide \"\n",
        "    \"whether to expose the truth or risk blowing up the platform.\"\n",
        ")\n",
        "\n",
        "print(f\"ğŸ¯ Target pages: {TARGET_PAGES}  â†’ target words â‰ˆ {TARGET_WORDS:,}\")\n",
        "print(f\"ğŸ“ Chapter target: ~{CH_TARGET_WORDS:,} words â†’ initial chapters: {NUM_CH}\")\n",
        "\n",
        "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
        "# 2) LLMs & Prompts (with speed-aware models/options)\n",
        "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
        "from langchain_ollama import OllamaLLM\n",
        "from langchain_core.prompts import PromptTemplate  # modern import\n",
        "\n",
        "PLANNER_MODEL = \"deepseek-r1:1.5b\"\n",
        "WRITER_MODEL  = \"llama3.2:3b-instruct\" if FAST_MODE else \"llama3.1:8b\"\n",
        "PLANNER_NUM_PREDICT = 384 if FAST_MODE else 640\n",
        "WRITER_NUM_PREDICT  = 1800 if FAST_MODE else 3000\n",
        "MAX_WORKERS = 1 if (FAST_MODE or not HAS_GPU) else 3   # be conservative on CPU\n",
        "\n",
        "# Pull only what's needed for this run\n",
        "subprocess.run([\"ollama\",\"pull\", PLANNER_MODEL], check=False)\n",
        "subprocess.run([\"ollama\",\"pull\", WRITER_MODEL],  check=False)\n",
        "\n",
        "planner_llm = OllamaLLM(\n",
        "    model=PLANNER_MODEL,\n",
        "    base_url=\"http://127.0.0.1:11434\",\n",
        "    temperature=0.25,\n",
        "    num_predict=PLANNER_NUM_PREDICT,\n",
        ")\n",
        "\n",
        "writer_llm  = OllamaLLM(\n",
        "    model=WRITER_MODEL,\n",
        "    base_url=\"http://127.0.0.1:11434\",\n",
        "    temperature=0.8,\n",
        "    num_ctx=4096,\n",
        "    num_predict=WRITER_NUM_PREDICT,\n",
        ")\n",
        "\n",
        "# NDJSON prompts (easier to parse than JSON arrays)\n",
        "outline_prompt = PromptTemplate(\n",
        "    input_variables=[\"topic\",\"count\"],\n",
        "    template=(\n",
        "\"You are a creative fiction author. Generate exactly {count} UNIQUE chapter seeds \"\n",
        "\"for the book below. OUTPUT FORMAT: **NDJSON**, one compact JSON object per line, \"\n",
        "\"no leading numbering, no extra text, no trailing commas, no code fences.\\n\\n\"\n",
        "\"Each line MUST be like:\\n\"\n",
        "'{{\\\"title\\\":\\\"...\\\",\\\"description\\\":\\\"...\\\"}}\\\\n'\n",
        "\"\\nBook idea:\\n{topic}\\n\"\n",
        "    )\n",
        ")\n",
        "\n",
        "character_prompt = PromptTemplate(\n",
        "    input_variables=[\"outline\",\"num_chars\"],\n",
        "    template=(\n",
        "\"Given this chapter outline (JSON list):\\n{outline}\\n\\n\"\n",
        "\"Create exactly {num_chars} main characters.\\n\"\n",
        "\"OUTPUT FORMAT: **NDJSON**, one compact JSON object per line (no array, no extra text):\\n\"\n",
        "'{{\\\"name\\\":\\\"...\\\",\\\"role\\\":\\\"...\\\",\\\"development_arc\\\":\\\"...\\\"}}'\n",
        "    )\n",
        ")\n",
        "\n",
        "chapter_prompt = PromptTemplate(\n",
        "    input_variables=[\"title\",\"description\",\"idea\"],\n",
        "    template=(\n",
        "\"\"\"Write a ~2200â€“3200 word chapter titled \"{title}\".\n",
        "Seed idea: {idea}\n",
        "Chapter description: \"{description}\"\n",
        "\n",
        "Constraints:\n",
        "- NO meta commentary, NO analysis of your process, NO decision making.\n",
        "- Assume the reader remembers prior chapters; do not re-explain backstory.\n",
        "- Maintain continuity, but introduce at least one fresh obstacle, one vivid sensory beat, and one believable surprise.\n",
        "- Use concrete, precise details; avoid clichÃ©s.\n",
        "- End with a small but real unresolved tension.\n",
        "Return TEXT ONLY.\n",
        "\"\"\"\n",
        "    )\n",
        ")\n",
        "\n",
        "REVISION_PROMPT = PromptTemplate(\n",
        "    input_variables=[\"chapter\",\"title\",\"description\",\"ledger\"],\n",
        "    template=(\n",
        "\"\"\"Revise the chapter to reduce repetition with earlier chapters while improving novelty and tension.\n",
        "Keep the same characters and continuity, but change scene dynamics, setting details, and micro-beats.\n",
        "\n",
        "Rules:\n",
        "- Do NOT re-explain backstory already known.\n",
        "- Add at least one fresh obstacle, one specific sensory detail, and one surprising but plausible turn.\n",
        "- Preserve voice and POV.\n",
        "Return TEXT ONLY.\n",
        "\n",
        "Title: {title}\n",
        "Description: {description}\n",
        "\n",
        "Do-not-repeat ledger (phrases/scenes to avoid): {ledger}\n",
        "\n",
        "Chapter draft:\n",
        "{chapter}\n",
        "\"\"\"\n",
        "    )\n",
        ")\n",
        "\n",
        "# NOTE: braces escaped below ({{ â€¦ }})\n",
        "EVAL_PROMPT = PromptTemplate(\n",
        "    input_variables=[\"chapter\"],\n",
        "    template=(\n",
        "\"\"\"You are a tough fiction editor. Rate the chapter (1â€“10) on:\n",
        "- pacing\n",
        "- tension\n",
        "- voice\n",
        "- imagery\n",
        "- dialogue\n",
        "- novelty\n",
        "\n",
        "Return STRICT JSON only:\n",
        "{{\"scores\":{{\"pacing\":x,\"tension\":x,\"voice\":x,\"imagery\":x,\"dialogue\":x,\"novelty\":x}},\"one_sentence_note\":\"...\",\"three_micro_edits\":[\"...\",\"...\",\"...\"]}}\n",
        "\n",
        "Chapter:\n",
        "{chapter}\n",
        "\"\"\"\n",
        "    )\n",
        ")\n",
        "\n",
        "PUNCHUP_PROMPT = PromptTemplate(\n",
        "    input_variables=[\"chapter\",\"edits\"],\n",
        "    template=(\n",
        "\"\"\"Apply these micro-edits to strengthen the chapter without changing the plot:\n",
        "- {edits}\n",
        "\n",
        "Rules:\n",
        "- Keep POV, continuity, and length roughly the same (Â±10%).\n",
        "- Add concrete sensory details.\n",
        "- Tighten weak sentences; remove clichÃ©s.\n",
        "Return TEXT ONLY.\n",
        "\n",
        "Chapter:\n",
        "{chapter}\n",
        "\"\"\"\n",
        "    )\n",
        ")\n",
        "\n",
        "# 2.a Theme/Motif bible, beats planner, dialogue tuner, anti-clichÃ©, marketing\n",
        "THEME_PROMPT = PromptTemplate(\n",
        "    input_variables=[\"topic\",\"outline\"],\n",
        "    template=(\n",
        "\"\"\"You are a development editor. From the seed idea and outline, extract:\n",
        "- 3â€“5 core THEMES (short phrases)\n",
        "- 6â€“12 recurring MOTIFS or props (e.g., \"glitch-art\", \"rain-soaked streets\")\n",
        "- 3â€“6 PROMISES to the reader (e.g., \"ethical tension\", \"reveal of hidden mastermind\")\n",
        "- A one-sentence LOGLINE pitched to a general audience\n",
        "- Genre expectations to signal with setting & imagery (GENRE_SIGNALS, 5â€“8 phrases)\n",
        "\n",
        "Return STRICT JSON:\n",
        "{{\n",
        "  \"themes\": [\"...\"],\n",
        "  \"motifs\": [\"...\"],\n",
        "  \"promises\": [\"...\"],\n",
        "  \"logline\": \"...\",\n",
        "  \"genre_signals\": [\"...\"]\n",
        "}}\n",
        "\n",
        "Seed idea: {topic}\n",
        "Outline: {outline}\n",
        "\"\"\"\n",
        "    )\n",
        ")\n",
        "\n",
        "BEATS_PROMPT = PromptTemplate(\n",
        "    input_variables=[\"title\",\"description\",\"theme_bible\",\"motif_ledger\"],\n",
        "    template=(\n",
        "\"\"\"Plan a tight beat sheet for the chapter with approx. 8â€“12 beats following a tension curve.\n",
        "Enforce: strong opening hook line, mid-chapter reversal, and a cliffhanger/stinger.\n",
        "\n",
        "Constraints:\n",
        "- Integrate 1â€“2 MOTIFS from motif_ledger (callbacks) and 1 FRESH setting detail aligned to genre_signals.\n",
        "- Target dialogue ratio: 30â€“45% of lines contain dialogue.\n",
        "- Specify a SENSORY PALETTE (2â€“3 senses to emphasize).\n",
        "- Map an EMOTION ARC over beats (e.g., curiosity â†’ dread â†’ resolve).\n",
        "\n",
        "Return STRICT JSON:\n",
        "{{\n",
        "  \"beats\": [\n",
        "    {{\"name\":\"Hook\",\"goal\":\"...\",\"conflict\":\"...\",\"setting\":\"...\",\"emotion\":\"...\"}},\n",
        "    ...\n",
        "  ],\n",
        "  \"dialogue_target_pct\": 0.38,\n",
        "  \"sensory_palette\": [\"sound\",\"smell\"],\n",
        "  \"foreshadow\":\"...\",\n",
        "  \"callback_motif\":\"...\"\n",
        "}}\n",
        "\n",
        "Title: {title}\n",
        "Description: {description}\n",
        "THEME_BIBLE: {theme_bible}\n",
        "MOTIF_LEDGER: {motif_ledger}\n",
        "\"\"\"\n",
        "    )\n",
        ")\n",
        "\n",
        "CHAPTER_WITH_BEATS_PROMPT = PromptTemplate(\n",
        "    input_variables=[\"title\",\"description\",\"idea\",\"plan\",\"themes\",\"sensory_palette\",\"dialogue_target\"],\n",
        "    template=(\n",
        "\"\"\"Write a ~2200â€“3200 word chapter titled \"{title}\".\n",
        "\n",
        "Seed idea: {idea}\n",
        "Mini-brief: {description}\n",
        "Plan (beats): {plan}\n",
        "\n",
        "Must do:\n",
        "- OPEN with a punchy 1â€“2 sentence HOOK that raises a concrete question.\n",
        "- Emphasize SENSORY PALETTE: {sensory_palette}\n",
        "- Aim for DIALOGUE DENSITY â‰ˆ {dialogue_target:.2f} (about 30â€“45% lines include dialogue).\n",
        "- Integrate 1 motif or prop from the plan naturally.\n",
        "- Midpoint reversal that reframes stakes.\n",
        "- END with a plausible CLIFFHANGER/STINGER (no meta).\n",
        "\n",
        "Style:\n",
        "- Concrete details, crisp verbs; avoid clichÃ©s.\n",
        "- Maintain POV and continuity; no backstory dumps.\n",
        "\n",
        "Themes to subtly reinforce: {themes}\n",
        "Return TEXT ONLY.\n",
        "\"\"\"\n",
        "    )\n",
        ")\n",
        "\n",
        "DIALOGUE_TUNER_PROMPT = PromptTemplate(\n",
        "    input_variables=[\"chapter\",\"target\"],\n",
        "    template=(\n",
        "\"\"\"Revise the chapter to adjust dialogue density to â‰ˆ {target:.2f} (Â±0.08).\n",
        "Keep plot and beats intact. Do not shorten by more than 10% or lengthen by more than 10%.\n",
        "Return TEXT ONLY.\n",
        "\n",
        "Chapter:\n",
        "{chapter}\n",
        "\"\"\"\n",
        "    )\n",
        ")\n",
        "\n",
        "DECLICHE_PROMPT = PromptTemplate(\n",
        "    input_variables=[\"chapter\"],\n",
        "    template=(\n",
        "\"\"\"Rewrite at sentence-level to remove clichÃ©s, generic metaphors, and filler.\n",
        "Replace with specific, concrete imagery fitting a near-future techno-thriller vibe.\n",
        "Preserve plot, POV, beats, and length (Â±5%). Return TEXT ONLY.\n",
        "\n",
        "Chapter:\n",
        "{chapter}\n",
        "\"\"\"\n",
        "    )\n",
        ")\n",
        "\n",
        "MOTIF_MINER_PROMPT = PromptTemplate(\n",
        "    input_variables=[\"chapter\"],\n",
        "    template=(\n",
        "\"\"\"Extract 1â€“3 recurring motifs/props/images present in this chapter (short noun phrases).\n",
        "Return STRICT JSON: {{\"motifs\":[\"...\"]}}\n",
        "\n",
        "Chapter:\n",
        "{chapter}\n",
        "\"\"\"\n",
        "    )\n",
        ")\n",
        "\n",
        "BLURB_PROMPT = PromptTemplate(\n",
        "    input_variables=[\"title\",\"logline\",\"themes\",\"promises\"],\n",
        "    template=(\n",
        "\"\"\"Write:\n",
        "1) A high-impact back-cover BLURB (120â€“160 words) using the logline and themes.\n",
        "2) A 1-sentence hook for retailer product pages.\n",
        "3) 3 short BookTok/Bookstagram snippets (â‰¤140 chars each).\n",
        "\n",
        "Return STRICT JSON:\n",
        "{{\n",
        "  \"blurb\":\"...\",\n",
        "  \"product_hook\":\"...\",\n",
        "  \"snippets\": [\"...\",\"...\",\"...\"]\n",
        "}}\n",
        "\n",
        "Title: {title}\n",
        "Logline: {logline}\n",
        "Themes: {themes}\n",
        "Promises: {promises}\n",
        "\"\"\"\n",
        "    )\n",
        ")\n",
        "\n",
        "# Build chains with the pipe operator\n",
        "outline_chain     = outline_prompt               | planner_llm\n",
        "character_chain   = character_prompt             | planner_llm\n",
        "chapter_chain     = chapter_prompt               | writer_llm\n",
        "revision_chain    = REVISION_PROMPT              | writer_llm\n",
        "eval_chain        = EVAL_PROMPT                  | planner_llm\n",
        "punchup_chain     = PUNCHUP_PROMPT               | writer_llm\n",
        "\n",
        "theme_chain       = THEME_PROMPT                 | planner_llm\n",
        "beats_chain       = BEATS_PROMPT                 | planner_llm\n",
        "chapter_beats_llm = CHAPTER_WITH_BEATS_PROMPT    | writer_llm\n",
        "dialogue_tuner    = DIALOGUE_TUNER_PROMPT        | writer_llm\n",
        "decliche_chain    = DECLICHE_PROMPT              | writer_llm\n",
        "motif_miner       = MOTIF_MINER_PROMPT           | planner_llm\n",
        "blurb_chain       = BLURB_PROMPT                 | planner_llm\n",
        "\n",
        "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
        "# 3) Utilities: strip <think>, parse NDJSON/JSON, similarity, IO helpers\n",
        "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
        "THINK_RE = re.compile(r\"<think>.*?</think>\\s*\", flags=re.S|re.I)\n",
        "FENCE_RE = re.compile(r\"```(?:json)?|```\", flags=re.I)\n",
        "\n",
        "def strip_think(x: Any) -> str:\n",
        "    s = x[\"text\"] if isinstance(x, dict) and \"text\" in x else str(x)\n",
        "    s = THINK_RE.sub(\"\", s)\n",
        "    s = FENCE_RE.sub(\"\", s)\n",
        "    return s.strip()\n",
        "\n",
        "def parse_ndjson(text: str, expected: int = None) -> List[dict]:\n",
        "    out = []\n",
        "    for ln in text.splitlines():\n",
        "        ln = ln.strip()\n",
        "        if not ln:\n",
        "            continue\n",
        "        if ln[:2] in (\"- \", \"* \"): ln = ln[2:].strip()  # ignore bullets\n",
        "        if ln and ln[0].isdigit() and ln.lstrip().split(\" \",1)[0].rstrip(\".\").isdigit():\n",
        "            ln = re.sub(r\"^\\d+\\.\\s*\", \"\", ln)\n",
        "        try:\n",
        "            obj = json.loads(ln)\n",
        "            if isinstance(obj, dict): out.append(obj)\n",
        "        except json.JSONDecodeError:\n",
        "            fix = ln.replace(\"â€œ\",\"\\\"\").replace(\"â€\",\"\\\"\").replace(\"â€™\",\"'\")\n",
        "            fix = re.sub(r\",\\s*}\", \"}\", fix); fix = re.sub(r\",\\s*]\", \"]\", fix)\n",
        "            try:\n",
        "                obj = json.loads(fix)\n",
        "                if isinstance(obj, dict): out.append(obj)\n",
        "            except Exception:\n",
        "                continue\n",
        "    return out\n",
        "\n",
        "def parse_strict_json(s: str) -> dict:\n",
        "    s = strip_think(s)\n",
        "    m = re.search(r\"\\{[\\s\\S]*\\}\\s*$\", s)\n",
        "    if not m: return {}\n",
        "    try:\n",
        "        return json.loads(m.group(0))\n",
        "    except Exception:\n",
        "        fix = m.group(0).replace(\"â€œ\",\"\\\"\").replace(\"â€\",\"\\\"\").replace(\"â€™\",\"'\")\n",
        "        fix = re.sub(r\",\\s*}\", \"}\", fix); fix = re.sub(r\",\\s*]\", \"]\", fix)\n",
        "        try: return json.loads(fix)\n",
        "        except Exception: return {}\n",
        "\n",
        "def jaccard(a: str, b: str) -> float:\n",
        "    A = set(re.findall(r\"[a-z0-9']+\", a.lower()))\n",
        "    B = set(re.findall(r\"[a-z0-9']+\", b.lower()))\n",
        "    if not A or not B: return 0.0\n",
        "    return len(A & B) / len(A | B)\n",
        "\n",
        "def too_similar(ch1: Dict[str,str], ch2: Dict[str,str]) -> bool:\n",
        "    t_sim = jaccard(ch1[\"title\"], ch2[\"title\"])\n",
        "    d_sim = jaccard(ch1[\"description\"], ch2[\"description\"])\n",
        "    return (t_sim > 0.65) or (t_sim > 0.45 and d_sim > 0.55)\n",
        "\n",
        "def bigram_overlap(a: str, b: str) -> float:\n",
        "    def bigrams(s):\n",
        "        toks = re.findall(r\"[a-z0-9']+\", s.lower())\n",
        "        return set(zip(toks, toks[1:])) if len(toks) > 1 else set()\n",
        "    A, B = bigrams(a), bigrams(b)\n",
        "    denom = len(A | B) if (A or B) else 1\n",
        "    return len(A & B) / denom\n",
        "\n",
        "def top_trigrams(text: str, k: int = 30) -> List[str]:\n",
        "    toks = re.findall(r\"[a-z0-9']+\", text.lower())\n",
        "    tris = Counter(zip(toks, toks[1:], toks[2:]))\n",
        "    return [\" \".join(t) for t,_ in tris.most_common(k)]\n",
        "\n",
        "def approx_dialogue_ratio(text: str) -> float:\n",
        "    lines = [ln.strip() for ln in text.splitlines() if ln.strip()]\n",
        "    if not lines: return 0.0\n",
        "    dial = sum(1 for ln in lines if re.search(r'[\"â€œâ€]|^â€”', ln))\n",
        "    return dial / max(1, len(lines))\n",
        "\n",
        "def word_count(text: str) -> int:\n",
        "    return len(re.findall(r\"[A-Za-z0-9']+\", text or \"\"))\n",
        "\n",
        "# Checkpoint helpers\n",
        "def _slug(s):\n",
        "    return re.sub(r\"[^a-z0-9]+\", \"-\", s.lower()).strip(\"-\")[:60]\n",
        "\n",
        "def _ck_paths(i, title):\n",
        "    base = f\"{i:03d}-{_slug(title)}\"\n",
        "    p = pathlib.Path(CHECKPOINT_DIR)\n",
        "    return p / (base + \".txt\"), p / (base + \".json\")\n",
        "\n",
        "def save_ckpt(i, title, text, notes):\n",
        "    p_txt, p_meta = _ck_paths(i, title)\n",
        "    p_txt.write_text(text or \"\", encoding=\"utf-8\")\n",
        "    meta = {\"chapter_index\": i, \"title\": title, \"notes\": notes}\n",
        "    p_meta.write_text(json.dumps(meta, ensure_ascii=False, indent=2), encoding=\"utf-8\")\n",
        "\n",
        "def load_ckpt_if_any(i, title):\n",
        "    p_txt, p_meta = _ck_paths(i, title)\n",
        "    if p_txt.exists():\n",
        "        text = p_txt.read_text(encoding=\"utf-8\")\n",
        "        notes = None\n",
        "        if p_meta.exists():\n",
        "            try: notes = json.loads(p_meta.read_text(encoding=\"utf-8\"))\n",
        "            except Exception: notes = None\n",
        "        return text, notes\n",
        "    return None, None\n",
        "\n",
        "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
        "# 4) Outline generation with NDJSON + retry + strict dedupe\n",
        "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
        "print(f\"â†’ Generating {NUM_CH}-chapter outline in chunks of ~10â€¦\")\n",
        "outline, seen_titles = [], set()\n",
        "chunk = 10\n",
        "attempts = 0\n",
        "MAX_ATTEMPTS = 40\n",
        "\n",
        "while len(outline) < NUM_CH and attempts < MAX_ATTEMPTS:\n",
        "    ask = min(chunk, NUM_CH - len(outline))\n",
        "    raw = outline_chain.invoke({\"topic\": SEED_IDEA, \"count\": ask})\n",
        "    attempts += 1\n",
        "    lines = parse_ndjson(strip_think(raw), expected=ask)\n",
        "    if not lines:\n",
        "        print(\"âš ï¸ Outline chunk parse failed (empty); retryingâ€¦\")\n",
        "        continue\n",
        "    added = 0\n",
        "    for ch in lines:\n",
        "        cand = {\n",
        "            \"title\": (ch.get(\"title\") or \"\").strip(),\n",
        "            \"description\": (ch.get(\"description\") or \"\").strip()\n",
        "        }\n",
        "        if not cand[\"title\"] or not cand[\"description\"]:\n",
        "            continue\n",
        "        if cand[\"title\"] in seen_titles:\n",
        "            continue\n",
        "        if any(too_similar(cand, existing) for existing in outline):\n",
        "            continue\n",
        "        outline.append(cand)\n",
        "        seen_titles.add(cand[\"title\"])\n",
        "        added += 1\n",
        "        if len(outline) >= NUM_CH:\n",
        "            break\n",
        "    if added == 0:\n",
        "        print(\"â„¹ï¸ No new unique chapters from this chunk; retryingâ€¦\")\n",
        "\n",
        "print(f\"âœ” Final outline: {len(outline)} chapters\\n\")\n",
        "if len(outline) < NUM_CH:\n",
        "    print(\"âš ï¸ Could not reach target count; proceeding with what we have.\")\n",
        "\n",
        "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
        "# 5) Character Bible + Theme/Motif Bible\n",
        "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
        "NUM_CHAR = max(3, min(10, len(outline)//8))\n",
        "print(f\"â†’ Generating {NUM_CHAR} charactersâ€¦\")\n",
        "characters = []\n",
        "for _ in range(6):  # a few retries if parsing fails\n",
        "    raw_chars = character_chain.invoke({\n",
        "        \"outline\": json.dumps(outline, ensure_ascii=False),\n",
        "        \"num_chars\": NUM_CHAR\n",
        "    })\n",
        "    characters = parse_ndjson(strip_think(raw_chars), expected=NUM_CHAR)\n",
        "    if len(characters) == NUM_CHAR:\n",
        "        break\n",
        "print(f\"âœ” Got {len(characters)} characters\\n\")\n",
        "\n",
        "print(\"â†’ Building theme/motif bibleâ€¦\")\n",
        "theme_raw = theme_chain.invoke({\n",
        "    \"topic\": SEED_IDEA,\n",
        "    \"outline\": json.dumps(outline, ensure_ascii=False)\n",
        "})\n",
        "THEME_BIBLE = parse_strict_json(theme_raw) or {\n",
        "    \"themes\": [],\n",
        "    \"motifs\": [],\n",
        "    \"promises\": [],\n",
        "    \"logline\": \"\",\n",
        "    \"genre_signals\": []\n",
        "}\n",
        "MOTIF_LEDGER = list(THEME_BIBLE.get(\"motifs\", []))  # seed with global motifs\n",
        "print(\"âœ” Theme bible ready.\\n\")\n",
        "\n",
        "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
        "# 6) Chapter Generation with beats + checkpointing + early re-calibration\n",
        "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
        "print(\"â†’ Generating chaptersâ€¦\")\n",
        "chap_texts = [None]*len(outline)\n",
        "editor_notes = [None]*len(outline)\n",
        "BIGRAM_THRESHOLD = 0.22  # repetition strictness\n",
        "\n",
        "def write_one(idx):\n",
        "    meta = outline[idx]\n",
        "    title = meta[\"title\"]\n",
        "\n",
        "    # Resume if checkpoint exists\n",
        "    cached_txt, cached_notes = load_ckpt_if_any(idx, title)\n",
        "    if cached_txt:\n",
        "        return cached_txt, cached_notes\n",
        "\n",
        "    # 1) Plan beats with callbacks to existing motif ledger\n",
        "    plan_raw = beats_chain.invoke({\n",
        "        \"title\": meta[\"title\"],\n",
        "        \"description\": meta[\"description\"],\n",
        "        \"theme_bible\": json.dumps(THEME_BIBLE, ensure_ascii=False),\n",
        "        \"motif_ledger\": json.dumps(MOTIF_LEDGER[-12:], ensure_ascii=False)  # recent motifs\n",
        "    })\n",
        "    plan = parse_strict_json(plan_raw)\n",
        "    dialogue_target = float(plan.get(\"dialogue_target_pct\", 0.36))\n",
        "    sensory_palette = plan.get(\"sensory_palette\", [\"sight\",\"sound\"])\n",
        "    plan_json = json.dumps(plan.get(\"beats\", []), ensure_ascii=False)\n",
        "\n",
        "    # 2) Draft with hooks, sensory palette, dialogue target\n",
        "    res = chapter_beats_llm.invoke({\n",
        "        \"title\": meta[\"title\"],\n",
        "        \"description\": meta[\"description\"],\n",
        "        \"idea\": SEED_IDEA,\n",
        "        \"plan\": plan_json,\n",
        "        \"themes\": \", \".join(THEME_BIBLE.get(\"themes\", [])),\n",
        "        \"sensory_palette\": \", \".join(sensory_palette),\n",
        "        \"dialogue_target\": dialogue_target\n",
        "    })\n",
        "    chapter_txt = strip_think(res)\n",
        "\n",
        "    # 3) Repetition guard vs earlier chapters\n",
        "    ledger = []\n",
        "    for j in range(idx):\n",
        "        prev = chap_texts[j]\n",
        "        if not prev: continue\n",
        "        if bigram_overlap(chapter_txt, prev) > BIGRAM_THRESHOLD:\n",
        "            ledger.extend(top_trigrams(prev, k=10))\n",
        "    ledger = list(dict.fromkeys(ledger))[:60]\n",
        "    if ledger:\n",
        "        revised = revision_chain.invoke({\n",
        "            \"chapter\": chapter_txt,\n",
        "            \"title\": meta[\"title\"],\n",
        "            \"description\": meta[\"description\"],\n",
        "            \"ledger\": \"; \".join(ledger)\n",
        "        })\n",
        "        chapter_txt = strip_think(revised)\n",
        "\n",
        "    # 4/5) Auto-evaluation â†’ only run heavy passes if needed\n",
        "    data = None\n",
        "    try:\n",
        "        report_raw = eval_chain.invoke({\"chapter\": chapter_txt})\n",
        "        report_txt = strip_think(report_raw)\n",
        "        m = re.search(r\"\\{[\\s\\S]*\\}\\s*$\", report_txt)\n",
        "        if m:\n",
        "            data = json.loads(m.group(0))\n",
        "        if data and \"scores\" in data:\n",
        "            scores = data[\"scores\"]\n",
        "            avg_score = sum(float(scores[k]) for k in scores)/len(scores)\n",
        "\n",
        "            # Dialogue tuner if notably off target\n",
        "            dr = approx_dialogue_ratio(chapter_txt)\n",
        "            if abs(dr - dialogue_target) > 0.10:\n",
        "                tuned = dialogue_tuner.invoke({\"chapter\": chapter_txt, \"target\": dialogue_target})\n",
        "                chapter_txt = strip_think(tuned)\n",
        "\n",
        "            # DeclichÃ© only when quality is mid or FAST_MODE off\n",
        "            if (avg_score < 7.6) or (not FAST_MODE):\n",
        "                polished = decliche_chain.invoke({\"chapter\": chapter_txt})\n",
        "                chapter_txt = strip_think(polished)\n",
        "\n",
        "            # Punch-up if still low\n",
        "            if avg_score < 7.4:\n",
        "                edits = \" | \".join(data.get(\"three_micro_edits\", [])) or \\\n",
        "                        \"Sharpen hooks; escalate midpoint; add concrete sensory beats.\"\n",
        "                punched = punchup_chain.invoke({\"chapter\": chapter_txt, \"edits\": edits})\n",
        "                chapter_txt = strip_think(punched)\n",
        "    except Exception:\n",
        "        data = None\n",
        "\n",
        "    # 6) Mine motifs from this chapter â†’ update global ledger\n",
        "    try:\n",
        "        mined_raw = motif_miner.invoke({\"chapter\": chapter_txt})\n",
        "        mined = parse_strict_json(mined_raw)\n",
        "        for m in (mined.get(\"motifs\") or []):\n",
        "            if m not in MOTIF_LEDGER:\n",
        "                MOTIF_LEDGER.append(m)\n",
        "    except Exception:\n",
        "        pass\n",
        "\n",
        "    # Save checkpoint\n",
        "    save_ckpt(idx, title, chapter_txt, data)\n",
        "    return chapter_txt, data\n",
        "\n",
        "# â€”â€” Early calibration: write first few chapters serially, resize outline\n",
        "PREGEN = min(3, len(outline))\n",
        "for i in range(PREGEN):\n",
        "    ch_txt, notes = write_one(i)\n",
        "    chap_texts[i] = ch_txt\n",
        "    editor_notes[i] = notes\n",
        "\n",
        "# Measure actual words/chapter and re-size remaining outline to hit target pages\n",
        "actual_avg = max(500, sum(word_count(chap_texts[i]) for i in range(PREGEN)) // PREGEN)\n",
        "recalc_num_ch = max(12, min(80, (TARGET_WORDS + actual_avg - 1) // actual_avg))\n",
        "\n",
        "if recalc_num_ch != len(outline):\n",
        "    delta = recalc_num_ch - len(outline)\n",
        "    if delta > 0:\n",
        "        ask_more = delta\n",
        "        raw_extra = outline_chain.invoke({\"topic\": SEED_IDEA, \"count\": ask_more})\n",
        "        extra = parse_ndjson(strip_think(raw_extra), expected=ask_more)\n",
        "        seen_titles = set([c[\"title\"] for c in outline])\n",
        "        for ch in extra:\n",
        "            cand = {\"title\": (ch.get(\"title\") or \"\").strip(),\n",
        "                    \"description\": (ch.get(\"description\") or \"\").strip()}\n",
        "            if not cand[\"title\"] or not cand[\"description\"]:\n",
        "                continue\n",
        "            if cand[\"title\"] in seen_titles:\n",
        "                continue\n",
        "            if any(too_similar(cand, e) for e in outline):\n",
        "                continue\n",
        "            outline.append(cand); seen_titles.add(cand[\"title\"])\n",
        "            chap_texts.append(None); editor_notes.append(None)\n",
        "            if len(outline) >= recalc_num_ch: break\n",
        "        print(f\"ğŸ” Resized outline: +{max(0, delta)} â†’ total {len(outline)} chapters\")\n",
        "    elif delta < 0:\n",
        "        keep = max(PREGEN, recalc_num_ch)\n",
        "        outline = outline[:keep]\n",
        "        chap_texts = chap_texts[:keep]\n",
        "        editor_notes = editor_notes[:keep]\n",
        "        print(f\"âœ‚ï¸  Trimmed outline to {len(outline)} chapters\")\n",
        "\n",
        "# Generate remaining chapters in parallel/respectful workers\n",
        "remaining_idxs = [i for i, t in enumerate(chap_texts) if t is None]\n",
        "with ThreadPoolExecutor(max_workers=MAX_WORKERS) as ex:\n",
        "    futures = { ex.submit(write_one, i): i for i in remaining_idxs }\n",
        "    for fut in tqdm(as_completed(futures), total=len(futures), desc=\"Chapters\"):\n",
        "        idx = futures[fut]\n",
        "        try:\n",
        "            ch_txt, notes = fut.result()\n",
        "        except Exception as e:\n",
        "            ch_txt, notes = f\"[Generation failed: {e}]\", None\n",
        "        chap_texts[idx] = ch_txt\n",
        "        editor_notes[idx] = notes\n",
        "\n",
        "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
        "# 7) Pre-save totals â†’ Save to Word + Back-cover copy + Download\n",
        "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
        "total_words = sum(word_count(t or \"\") for t in chap_texts)\n",
        "est_pages  = total_words / WORDS_PER_PAGE\n",
        "suggested_ch = max(12, min(80, round(total_words / CH_TARGET_WORDS)))\n",
        "print(f\"ğŸ§® Total words: {total_words:,}  â†’ est. pages â‰ˆ {est_pages:.0f}\")\n",
        "print(f\"ğŸ”§ If you rerun, suggested chapters for this style â‰ˆ {suggested_ch}\")\n",
        "\n",
        "doc = docx.Document()\n",
        "doc.add_heading(BOOK_TITLE, 0)\n",
        "doc.add_paragraph(f\"Seed idea: {SEED_IDEA}\")\n",
        "doc.add_paragraph(f\"Estimated pages: ~{est_pages:.0f}\")\n",
        "\n",
        "# Character Development Section\n",
        "if characters:\n",
        "    doc.add_page_break()\n",
        "    doc.add_heading(\"Character Development\", level=1)\n",
        "    for c in characters:\n",
        "        name = c.get(\"name\",\"(Unnamed)\")\n",
        "        role = c.get(\"role\",\"\")\n",
        "        arc  = c.get(\"development_arc\",\"\")\n",
        "        doc.add_heading(name, level=2)\n",
        "        if role: doc.add_paragraph(f\"Role: {role}\")\n",
        "        if arc:  doc.add_paragraph(arc)\n",
        "\n",
        "# Chapters\n",
        "for i, (meta, text) in enumerate(zip(outline, chap_texts), start=1):\n",
        "    doc.add_page_break()\n",
        "    doc.add_heading(f\"Chapter {i}: {meta['title']}\", level=1)\n",
        "    doc.add_paragraph(meta['description'], style=\"Intense Quote\")\n",
        "    doc.add_paragraph((text or \"\").strip())\n",
        "\n",
        "# Editorâ€™s Notes (Auto-Eval)\n",
        "doc.add_page_break()\n",
        "doc.add_heading(\"Editorâ€™s Notes (Auto-Eval)\", level=1)\n",
        "for i, (meta, notes) in enumerate(zip(outline, editor_notes), start=1):\n",
        "    doc.add_heading(f\"Chapter {i}: {meta['title']}\", level=2)\n",
        "    if not notes or \"scores\" not in (notes or {}):\n",
        "        doc.add_paragraph(\"No evaluation available.\")\n",
        "        continue\n",
        "    scores = notes[\"scores\"]\n",
        "    one_liner = notes.get(\"one_sentence_note\",\"\")\n",
        "    edits = notes.get(\"three_micro_edits\", [])\n",
        "    try:\n",
        "        avg_score = sum(float(scores[k]) for k in scores)/len(scores)\n",
        "    except Exception:\n",
        "        avg_score = None\n",
        "    doc.add_paragraph(\"Scores: \" + \", \".join(f\"{k}: {scores[k]}\" for k in scores))\n",
        "    if avg_score is not None:\n",
        "        doc.add_paragraph(f\"Average: {avg_score:.2f}\")\n",
        "    if one_liner:\n",
        "        doc.add_paragraph(f\"Note: {one_liner}\")\n",
        "    if edits:\n",
        "        for e in edits:\n",
        "            doc.add_paragraph(f\"â€¢ {e}\")\n",
        "\n",
        "# Back-cover blurb + retailer hook + social snippets\n",
        "blurb_data = {}\n",
        "try:\n",
        "    blurb_raw = blurb_chain.invoke({\n",
        "        \"title\": BOOK_TITLE,\n",
        "        \"logline\": THEME_BIBLE.get(\"logline\",\"\"),\n",
        "        \"themes\": \", \".join(THEME_BIBLE.get(\"themes\", [])),\n",
        "        \"promises\": \", \".join(THEME_BIBLE.get(\"promises\", []))\n",
        "    })\n",
        "    blurb_data = parse_strict_json(blurb_raw) or {}\n",
        "except Exception:\n",
        "    blurb_data = {}\n",
        "\n",
        "doc.add_page_break()\n",
        "doc.add_heading(\"Back-Cover Copy & Retailer Hook\", level=1)\n",
        "if blurb_data.get(\"blurb\"):\n",
        "    doc.add_paragraph(blurb_data[\"blurb\"])\n",
        "if blurb_data.get(\"product_hook\"):\n",
        "    doc.add_paragraph(f\"\\nRetailer Hook: {blurb_data['product_hook']}\")\n",
        "if blurb_data.get(\"snippets\"):\n",
        "    doc.add_heading(\"Short Social Snippets\", level=2)\n",
        "    for s in blurb_data[\"snippets\"]:\n",
        "        doc.add_paragraph(f\"â€¢ {s}\")\n",
        "\n",
        "# Save & download\n",
        "fn = BOOK_TITLE.replace(\" \", \"_\") + \".docx\"\n",
        "doc.save(fn)\n",
        "print(f\"ğŸ“˜ Saved {fn}\")\n",
        "files.download(fn)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "1u1QUkthupmS",
        "outputId": "4d348f2d-e3d4-466c-ed4a-e2027d40dc7b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "âœ… Ollama health: 200\n",
            "ğŸ–¥ï¸ GPU: not detected\n",
            "ğŸ¯ Target pages: 320  â†’ target words â‰ˆ 88,000\n",
            "ğŸ“ Chapter target: ~3,000 words â†’ initial chapters: 30\n",
            "â†’ Generating 30-chapter outline in chunks of ~10â€¦\n",
            "âš ï¸ Outline chunk parse failed (empty); retryingâ€¦\n",
            "âš ï¸ Outline chunk parse failed (empty); retryingâ€¦\n",
            "âš ï¸ Outline chunk parse failed (empty); retryingâ€¦\n",
            "âš ï¸ Outline chunk parse failed (empty); retryingâ€¦\n",
            "âš ï¸ Outline chunk parse failed (empty); retryingâ€¦\n",
            "âš ï¸ Outline chunk parse failed (empty); retryingâ€¦\n",
            "âš ï¸ Outline chunk parse failed (empty); retryingâ€¦\n",
            "âš ï¸ Outline chunk parse failed (empty); retryingâ€¦\n",
            "âš ï¸ Outline chunk parse failed (empty); retryingâ€¦\n",
            "âš ï¸ Outline chunk parse failed (empty); retryingâ€¦\n",
            "âš ï¸ Outline chunk parse failed (empty); retryingâ€¦\n",
            "âš ï¸ Outline chunk parse failed (empty); retryingâ€¦\n",
            "âš ï¸ Outline chunk parse failed (empty); retryingâ€¦\n",
            "âš ï¸ Outline chunk parse failed (empty); retryingâ€¦\n",
            "âš ï¸ Outline chunk parse failed (empty); retryingâ€¦\n",
            "âš ï¸ Outline chunk parse failed (empty); retryingâ€¦\n",
            "âš ï¸ Outline chunk parse failed (empty); retryingâ€¦\n",
            "âš ï¸ Outline chunk parse failed (empty); retryingâ€¦\n",
            "âš ï¸ Outline chunk parse failed (empty); retryingâ€¦\n",
            "âš ï¸ Outline chunk parse failed (empty); retryingâ€¦\n",
            "âš ï¸ Outline chunk parse failed (empty); retryingâ€¦\n",
            "âš ï¸ Outline chunk parse failed (empty); retryingâ€¦\n",
            "âš ï¸ Outline chunk parse failed (empty); retryingâ€¦\n",
            "âš ï¸ Outline chunk parse failed (empty); retryingâ€¦\n",
            "âš ï¸ Outline chunk parse failed (empty); retryingâ€¦\n",
            "âš ï¸ Outline chunk parse failed (empty); retryingâ€¦\n",
            "âš ï¸ Outline chunk parse failed (empty); retryingâ€¦\n",
            "âš ï¸ Outline chunk parse failed (empty); retryingâ€¦\n",
            "âš ï¸ Outline chunk parse failed (empty); retryingâ€¦\n",
            "âš ï¸ Outline chunk parse failed (empty); retryingâ€¦\n",
            "âš ï¸ Outline chunk parse failed (empty); retryingâ€¦\n",
            "âš ï¸ Outline chunk parse failed (empty); retryingâ€¦\n",
            "âš ï¸ Outline chunk parse failed (empty); retryingâ€¦\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-1235652250.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    502\u001b[0m \u001b[0;32mwhile\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutline\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0mNUM_CH\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mattempts\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0mMAX_ATTEMPTS\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    503\u001b[0m     \u001b[0mask\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mchunk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mNUM_CH\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutline\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 504\u001b[0;31m     \u001b[0mraw\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moutline_chain\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minvoke\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m\"topic\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mSEED_IDEA\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"count\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mask\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    505\u001b[0m     \u001b[0mattempts\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    506\u001b[0m     \u001b[0mlines\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparse_ndjson\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstrip_think\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mraw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexpected\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mask\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/langchain_core/runnables/base.py\u001b[0m in \u001b[0;36minvoke\u001b[0;34m(self, input, config, **kwargs)\u001b[0m\n\u001b[1;32m   3047\u001b[0m                         \u001b[0minput_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minvoke\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3048\u001b[0m                     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3049\u001b[0;31m                         \u001b[0minput_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minvoke\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3050\u001b[0m         \u001b[0;31m# finish the root run\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3051\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mBaseException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/langchain_core/language_models/llms.py\u001b[0m in \u001b[0;36minvoke\u001b[0;34m(self, input, config, stop, **kwargs)\u001b[0m\n\u001b[1;32m    387\u001b[0m         \u001b[0mconfig\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mensure_config\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    388\u001b[0m         return (\n\u001b[0;32m--> 389\u001b[0;31m             self.generate_prompt(\n\u001b[0m\u001b[1;32m    390\u001b[0m                 \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_convert_input\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    391\u001b[0m                 \u001b[0mstop\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstop\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/langchain_core/language_models/llms.py\u001b[0m in \u001b[0;36mgenerate_prompt\u001b[0;34m(self, prompts, stop, callbacks, **kwargs)\u001b[0m\n\u001b[1;32m    764\u001b[0m     ) -> LLMResult:\n\u001b[1;32m    765\u001b[0m         \u001b[0mprompt_strings\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_string\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mp\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mprompts\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 766\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgenerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprompt_strings\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstop\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    767\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    768\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0moverride\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/langchain_core/language_models/llms.py\u001b[0m in \u001b[0;36mgenerate\u001b[0;34m(self, prompts, stop, callbacks, tags, metadata, run_name, run_id, **kwargs)\u001b[0m\n\u001b[1;32m    969\u001b[0m                 )\n\u001b[1;32m    970\u001b[0m             ]\n\u001b[0;32m--> 971\u001b[0;31m             return self._generate_helper(\n\u001b[0m\u001b[1;32m    972\u001b[0m                 \u001b[0mprompts\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    973\u001b[0m                 \u001b[0mstop\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/langchain_core/language_models/llms.py\u001b[0m in \u001b[0;36m_generate_helper\u001b[0;34m(self, prompts, stop, run_managers, new_arg_supported, **kwargs)\u001b[0m\n\u001b[1;32m    790\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    791\u001b[0m             output = (\n\u001b[0;32m--> 792\u001b[0;31m                 self._generate(\n\u001b[0m\u001b[1;32m    793\u001b[0m                     \u001b[0mprompts\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    794\u001b[0m                     \u001b[0mstop\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstop\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/langchain_ollama/llms.py\u001b[0m in \u001b[0;36m_generate\u001b[0;34m(self, prompts, stop, run_manager, **kwargs)\u001b[0m\n\u001b[1;32m    360\u001b[0m         \u001b[0mgenerations\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    361\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mprompt\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mprompts\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 362\u001b[0;31m             final_chunk = self._stream_with_aggregation(\n\u001b[0m\u001b[1;32m    363\u001b[0m                 \u001b[0mprompt\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    364\u001b[0m                 \u001b[0mstop\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstop\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/langchain_ollama/llms.py\u001b[0m in \u001b[0;36m_stream_with_aggregation\u001b[0;34m(self, prompt, stop, run_manager, verbose, **kwargs)\u001b[0m\n\u001b[1;32m    319\u001b[0m         \u001b[0mfinal_chunk\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    320\u001b[0m         \u001b[0mthinking_content\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 321\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0mstream_resp\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_create_generate_stream\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprompt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    322\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstream_resp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    323\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mstream_resp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"thinking\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/langchain_ollama/llms.py\u001b[0m in \u001b[0;36m_create_generate_stream\u001b[0;34m(self, prompt, stop, **kwargs)\u001b[0m\n\u001b[1;32m    263\u001b[0m     ) -> Iterator[Union[Mapping[str, Any], str]]:\n\u001b[1;32m    264\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_client\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 265\u001b[0;31m             yield from self._client.generate(\n\u001b[0m\u001b[1;32m    266\u001b[0m                 \u001b[0;34m**\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_generate_params\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprompt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstop\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    267\u001b[0m             )\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/ollama/_client.py\u001b[0m in \u001b[0;36minner\u001b[0;34m()\u001b[0m\n\u001b[1;32m    170\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mResponseError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresponse\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresponse\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstatus_code\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    171\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 172\u001b[0;31m           \u001b[0;32mfor\u001b[0m \u001b[0mline\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miter_lines\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    173\u001b[0m             \u001b[0mpart\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mjson\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloads\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mline\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    174\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0merr\u001b[0m \u001b[0;34m:=\u001b[0m \u001b[0mpart\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'error'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/httpx/_models.py\u001b[0m in \u001b[0;36miter_lines\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    927\u001b[0m         \u001b[0mdecoder\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mLineDecoder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    928\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mrequest_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_request\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 929\u001b[0;31m             \u001b[0;32mfor\u001b[0m \u001b[0mtext\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miter_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    930\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0mline\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdecoder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    931\u001b[0m                     \u001b[0;32myield\u001b[0m \u001b[0mline\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/httpx/_models.py\u001b[0m in \u001b[0;36miter_text\u001b[0;34m(self, chunk_size)\u001b[0m\n\u001b[1;32m    914\u001b[0m         \u001b[0mchunker\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextChunker\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mchunk_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mchunk_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    915\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mrequest_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_request\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 916\u001b[0;31m             \u001b[0;32mfor\u001b[0m \u001b[0mbyte_content\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miter_bytes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    917\u001b[0m                 \u001b[0mtext_content\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdecoder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbyte_content\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    918\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0mchunk\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mchunker\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext_content\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/httpx/_models.py\u001b[0m in \u001b[0;36miter_bytes\u001b[0;34m(self, chunk_size)\u001b[0m\n\u001b[1;32m    895\u001b[0m             \u001b[0mchunker\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mByteChunker\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mchunk_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mchunk_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    896\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mrequest_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_request\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 897\u001b[0;31m                 \u001b[0;32mfor\u001b[0m \u001b[0mraw_bytes\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miter_raw\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    898\u001b[0m                     \u001b[0mdecoded\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdecoder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mraw_bytes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    899\u001b[0m                     \u001b[0;32mfor\u001b[0m \u001b[0mchunk\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mchunker\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdecoded\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/httpx/_models.py\u001b[0m in \u001b[0;36miter_raw\u001b[0;34m(self, chunk_size)\u001b[0m\n\u001b[1;32m    949\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    950\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mrequest_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_request\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 951\u001b[0;31m             \u001b[0;32mfor\u001b[0m \u001b[0mraw_stream_bytes\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstream\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    952\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_bytes_downloaded\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mraw_stream_bytes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    953\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0mchunk\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mchunker\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mraw_stream_bytes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/httpx/_client.py\u001b[0m in \u001b[0;36m__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    151\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__iter__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mtyping\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIterator\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mbytes\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 153\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0mchunk\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stream\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    154\u001b[0m             \u001b[0;32myield\u001b[0m \u001b[0mchunk\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    155\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/httpx/_transports/default.py\u001b[0m in \u001b[0;36m__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    125\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__iter__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mtyping\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIterator\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mbytes\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    126\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mmap_httpcore_exceptions\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 127\u001b[0;31m             \u001b[0;32mfor\u001b[0m \u001b[0mpart\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_httpcore_stream\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    128\u001b[0m                 \u001b[0;32myield\u001b[0m \u001b[0mpart\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    129\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/httpcore/_sync/connection_pool.py\u001b[0m in \u001b[0;36m__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    405\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mBaseException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mexc\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    406\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 407\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mexc\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    408\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    409\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/httpcore/_sync/connection_pool.py\u001b[0m in \u001b[0;36m__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    401\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__iter__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mtyping\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIterator\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mbytes\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    402\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 403\u001b[0;31m             \u001b[0;32mfor\u001b[0m \u001b[0mpart\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stream\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    404\u001b[0m                 \u001b[0;32myield\u001b[0m \u001b[0mpart\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    405\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mBaseException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mexc\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/httpcore/_sync/http11.py\u001b[0m in \u001b[0;36m__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    340\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mShieldCancellation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    341\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 342\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mexc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    343\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    344\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/httpcore/_sync/http11.py\u001b[0m in \u001b[0;36m__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    332\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    333\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mTrace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"receive_response_body\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogger\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_request\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 334\u001b[0;31m                 \u001b[0;32mfor\u001b[0m \u001b[0mchunk\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_connection\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_receive_response_body\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    335\u001b[0m                     \u001b[0;32myield\u001b[0m \u001b[0mchunk\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    336\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mBaseException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mexc\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/httpcore/_sync/http11.py\u001b[0m in \u001b[0;36m_receive_response_body\u001b[0;34m(self, request)\u001b[0m\n\u001b[1;32m    201\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    202\u001b[0m         \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 203\u001b[0;31m             \u001b[0mevent\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_receive_event\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    204\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mevent\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mh11\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mData\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    205\u001b[0m                 \u001b[0;32myield\u001b[0m \u001b[0mbytes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mevent\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/httpcore/_sync/http11.py\u001b[0m in \u001b[0;36m_receive_event\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    215\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    216\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mevent\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mh11\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mNEED_DATA\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 217\u001b[0;31m                 data = self._network_stream.read(\n\u001b[0m\u001b[1;32m    218\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mREAD_NUM_BYTES\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    219\u001b[0m                 )\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/httpcore/_backends/sync.py\u001b[0m in \u001b[0;36mread\u001b[0;34m(self, max_bytes, timeout)\u001b[0m\n\u001b[1;32m    126\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mmap_exceptions\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexc_map\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    127\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sock\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msettimeout\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 128\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sock\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmax_bytes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    129\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    130\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mwrite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbuffer\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mbytes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mfloat\u001b[0m \u001b[0;34m|\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "83UcHpRi37ag"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "CyyPDLD637Xt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
        "# 0) Colab Setup: install & launch Ollama (speed toggles, checkpoints, resolver)\n",
        "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
        "!pip install --quiet langchain-ollama python-docx tqdm\n",
        "\n",
        "import os, threading, subprocess, time, requests, json, re, shutil, pathlib, math, sys\n",
        "from typing import List, Any, Dict\n",
        "from concurrent.futures import ThreadPoolExecutor, as_completed\n",
        "from collections import Counter\n",
        "from tqdm import tqdm\n",
        "import docx\n",
        "from google.colab import files\n",
        "\n",
        "# Avoid LangChain provider hijacks\n",
        "for v in [\n",
        "    \"OPENAI_API_KEY\",\n",
        "    \"LITELLM_PROVIDER\", \"LITELLM_MODEL\", \"LITELLM_BASE_URL\",\n",
        "    \"LITELL M_PROVIDER\", \"LITELL M_MODEL\", \"LITELL M_BASE_URL\"  # catch stray typos\n",
        "]:\n",
        "    os.environ.pop(v, None)\n",
        "\n",
        "# â€”â€” Speed/robustness knobs â€”â€”\n",
        "FAST_MODE = True                 # Flip to False when you're happy with the outputs\n",
        "CHECKPOINT_DIR = \"book_ckpt\"     # Saves each chapter & metadata\n",
        "os.makedirs(CHECKPOINT_DIR, exist_ok=True)\n",
        "\n",
        "# Make Ollama conservative about parallelism in Colab\n",
        "os.environ[\"OLLAMA_MAX_LOADED_MODELS\"] = \"1\"\n",
        "os.environ[\"OLLAMA_NUM_PARALLEL\"] = \"1\"\n",
        "\n",
        "# Launch Ollama daemon\n",
        "os.environ[\"OLLAMA_HOST\"]    = \"127.0.0.1:11434\"\n",
        "os.environ[\"OLLAMA_ORIGINS\"] = \"*\"\n",
        "\n",
        "!curl -fsSL https://ollama.com/install.sh -o install.sh\n",
        "!bash install.sh >/dev/null 2>&1 || true\n",
        "\n",
        "def _serve_ollama():\n",
        "    subprocess.Popen([\"ollama\",\"serve\"], stderr=subprocess.DEVNULL, stdout=subprocess.DEVNULL)\n",
        "\n",
        "threading.Thread(target=_serve_ollama, daemon=True).start()\n",
        "time.sleep(8)\n",
        "print(\"âœ… Ollama health:\", requests.get(\"http://127.0.0.1:11434\").status_code)\n",
        "\n",
        "# GPU detection to size workers\n",
        "def _has_gpu():\n",
        "    try:\n",
        "        return shutil.which(\"nvidia-smi\") and (subprocess.run([\"nvidia-smi\"], capture_output=True).returncode==0)\n",
        "    except Exception:\n",
        "        return False\n",
        "HAS_GPU = bool(_has_gpu())\n",
        "print(\"ğŸ–¥ï¸ GPU:\", \"available\" if HAS_GPU else \"not detected\")\n",
        "\n",
        "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
        "# Helper: choose models that actually exist locally/remote via pull\n",
        "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
        "def pick_first_available(candidates: List[str]) -> str:\n",
        "    for m in candidates:\n",
        "        try:\n",
        "            r = subprocess.run([\"ollama\", \"pull\", m], capture_output=True, text=True)\n",
        "            if r.returncode == 0:\n",
        "                print(f\"âœ” Using model: {m}\")\n",
        "                return m\n",
        "            else:\n",
        "                print(f\"âœ– Pull failed for {m} â†’ {r.stderr.strip() or r.stdout.strip()}\")\n",
        "        except Exception as e:\n",
        "            print(f\"âœ– Error pulling {m}: {e}\")\n",
        "    raise RuntimeError(f\"No candidate models could be pulled: {candidates}\")\n",
        "\n",
        "# Good planner-size candidates (small & widely available)\n",
        "PLANNER_CANDIDATES = [\n",
        "    \"llama3.2:3b\",\n",
        "    \"qwen2.5:3b\",\n",
        "    \"phi3:3.8b-mini\",\n",
        "    \"gemma2:2b\",\n",
        "    \"mistral:7b\",\n",
        "    \"llama3.1:8b\",\n",
        "]\n",
        "\n",
        "# Writer candidates\n",
        "WRITER_FAST_CANDIDATES = [\n",
        "    \"llama3.2:3b\",\n",
        "    \"qwen2.5:3b\",\n",
        "    \"phi3:3.8b-mini\",\n",
        "    \"gemma2:2b\",\n",
        "    \"mistral:7b\",\n",
        "    \"llama3.1:8b\",\n",
        "]\n",
        "WRITER_QUALITY_CANDIDATES = [\n",
        "    \"llama3.1:8b\",\n",
        "    \"mistral:7b\",\n",
        "    \"qwen2.5:7b\",\n",
        "]\n",
        "\n",
        "# Resolve models now\n",
        "PLANNER_MODEL = pick_first_available(PLANNER_CANDIDATES)\n",
        "WRITER_MODEL  = pick_first_available(WRITER_FAST_CANDIDATES if FAST_MODE else WRITER_QUALITY_CANDIDATES)\n",
        "\n",
        "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
        "# 1) User parameters (auto size by target pages â†’ chapters)\n",
        "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
        "BOOK_TITLE   = \"Artificial Influencers 2\"\n",
        "MODE         = \"fiction\"  # or \"nonfiction\"\n",
        "\n",
        "# Either set an explicit target page count, or leave None to auto-center the profile\n",
        "TARGET_PAGES = 320 if MODE == \"fiction\" else 280\n",
        "\n",
        "GENRE_PROFILE = {\n",
        "    \"fiction\":   {\"pages_min\": 280, \"pages_max\": 360, \"chapter_words_typical\": (2400, 3600)},\n",
        "    \"nonfiction\":{\"pages_min\": 220, \"pages_max\": 320, \"chapter_words_typical\": (3000, 4500)}\n",
        "}[MODE]\n",
        "\n",
        "if TARGET_PAGES is None:\n",
        "    TARGET_PAGES = (GENRE_PROFILE[\"pages_min\"] + GENRE_PROFILE[\"pages_max\"]) // 2\n",
        "\n",
        "# Words-per-page assumption (trade paperback-ish)\n",
        "WORDS_PER_PAGE = 275\n",
        "TARGET_WORDS   = int(TARGET_PAGES * WORDS_PER_PAGE)\n",
        "\n",
        "# Choose a target chapter length (midpoint of typical band), and derive initial chapter count:\n",
        "CH_MIN, CH_MAX = GENRE_PROFILE[\"chapter_words_typical\"]\n",
        "CH_TARGET_WORDS = int((CH_MIN + CH_MAX) / 2)\n",
        "NUM_CH = max(12, min(80, (TARGET_WORDS + CH_TARGET_WORDS - 1) // CH_TARGET_WORDS))\n",
        "\n",
        "# Your story seed:\n",
        "SEED_IDEA = (\n",
        "    \"Dr. Lena Park â€” a brilliant but introverted data scientist at Datum, \"\n",
        "    \"a social-media analytics startup. She notices impossible engagement \"\n",
        "    \"patterns in a rising star; her investigation unravels a conspiracy \"\n",
        "    \"of AI-driven 'influencers' masquerading as humansâ€”and she must decide \"\n",
        "    \"whether to expose the truth or risk blowing up the platform.\"\n",
        ")\n",
        "\n",
        "print(f\"ğŸ¯ Target pages: {TARGET_PAGES}  â†’ target words â‰ˆ {TARGET_WORDS:,}\")\n",
        "print(f\"ğŸ“ Chapter target: ~{CH_TARGET_WORDS:,} words â†’ initial chapters: {NUM_CH}\")\n",
        "\n",
        "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
        "# 2) LLMs & Prompts (planner JSON+fallbacks baked in later)\n",
        "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
        "from langchain_ollama import OllamaLLM\n",
        "from langchain_core.prompts import PromptTemplate  # modern import\n",
        "\n",
        "PLANNER_NUM_PREDICT = 900 if FAST_MODE else 1400\n",
        "WRITER_NUM_PREDICT  = 1600 if FAST_MODE else 3000\n",
        "MAX_WORKERS = 1 if (FAST_MODE or not HAS_GPU) else 3   # conservative on CPU\n",
        "\n",
        "# Two planner clients: free-form and JSON-locked\n",
        "planner_llm = OllamaLLM(\n",
        "    model=PLANNER_MODEL,\n",
        "    base_url=\"http://127.0.0.1:11434\",\n",
        "    temperature=0.25,\n",
        "    num_predict=PLANNER_NUM_PREDICT,\n",
        ")\n",
        "planner_llm_json = OllamaLLM(\n",
        "    model=PLANNER_MODEL,\n",
        "    base_url=\"http://127.0.0.1:11434\",\n",
        "    temperature=0.2,\n",
        "    num_predict=PLANNER_NUM_PREDICT,\n",
        "    format=\"json\",                 # ask for pure JSON (we still robustly fallback)\n",
        ")\n",
        "\n",
        "writer_llm  = OllamaLLM(\n",
        "    model=WRITER_MODEL,\n",
        "    base_url=\"http://127.0.0.1:11434\",\n",
        "    temperature=0.8,\n",
        "    num_ctx=4096,\n",
        "    num_predict=WRITER_NUM_PREDICT,\n",
        ")\n",
        "\n",
        "# â€” Prompts â€”\n",
        "# Outline prompts: JSON and NDJSON\n",
        "OUTLINE_JSON_PROMPT = PromptTemplate(\n",
        "    input_variables=[\"topic\",\"count\"],\n",
        "    template=(\n",
        "\"\"\"Generate exactly {count} UNIQUE chapter seeds for this novel as a JSON ARRAY.\n",
        "Each item is an object: {{\"title\":\"...\", \"description\":\"...\"}}\n",
        "Return JSON ONLY. No commentary.\n",
        "\n",
        "Book idea: {topic}\n",
        "\"\"\"\n",
        "    )\n",
        ")\n",
        "\n",
        "OUTLINE_NDJSON_PROMPT = PromptTemplate(\n",
        "    input_variables=[\"topic\",\"count\"],\n",
        "    template=(\n",
        "\"\"\"Generate exactly {count} UNIQUE chapter seeds for this novel as NDJSON (one JSON object per line).\n",
        "Each line: {{\"title\":\"...\", \"description\":\"...\"}}\n",
        "No commentary, no numbering, no code fences.\n",
        "\n",
        "Book idea: {topic}\n",
        "\"\"\"\n",
        "    )\n",
        ")\n",
        "\n",
        "# Character prompt (JSON)\n",
        "CHAR_JSON_PROMPT = PromptTemplate(\n",
        "    input_variables=[\"outline\",\"num_chars\"],\n",
        "    template=(\n",
        "\"\"\"Given this chapter outline (JSON list): {outline}\n",
        "Create exactly {num_chars} MAIN CHARACTERS as a JSON ARRAY.\n",
        "Each item: {{\"name\":\"...\",\"role\":\"...\",\"development_arc\":\"...\"}}\n",
        "Return JSON ONLY. No commentary.\"\"\"\n",
        "    )\n",
        ")\n",
        "\n",
        "# Chapter & editing prompts\n",
        "chapter_prompt = PromptTemplate(\n",
        "    input_variables=[\"title\",\"description\",\"idea\"],\n",
        "    template=(\n",
        "\"\"\"Write a ~2200â€“3200 word chapter titled \"{title}\".\n",
        "Seed idea: {idea}\n",
        "Chapter description: \"{description}\"\n",
        "\n",
        "Constraints:\n",
        "- NO meta commentary, NO analysis of your process, NO decision making.\n",
        "- Assume the reader remembers prior chapters; do not re-explain backstory.\n",
        "- Maintain continuity, but introduce at least one fresh obstacle, one vivid sensory beat, and one believable surprise.\n",
        "- Use concrete, precise details; avoid clichÃ©s.\n",
        "- End with a small but real unresolved tension.\n",
        "Return TEXT ONLY.\n",
        "\"\"\"\n",
        "    )\n",
        ")\n",
        "\n",
        "REVISION_PROMPT = PromptTemplate(\n",
        "    input_variables=[\"chapter\",\"title\",\"description\",\"ledger\"],\n",
        "    template=(\n",
        "\"\"\"Revise the chapter to reduce repetition with earlier chapters while improving novelty and tension.\n",
        "Keep the same characters and continuity, but change scene dynamics, setting details, and micro-beats.\n",
        "\n",
        "Rules:\n",
        "- Do NOT re-explain backstory already known.\n",
        "- Add at least one fresh obstacle, one specific sensory detail, and one surprising but plausible turn.\n",
        "- Preserve voice and POV.\n",
        "Return TEXT ONLY.\n",
        "\n",
        "Title: {title}\n",
        "Description: {description}\n",
        "\n",
        "Do-not-repeat ledger (phrases/scenes to avoid): {ledger}\n",
        "\n",
        "Chapter draft:\n",
        "{chapter}\n",
        "\"\"\"\n",
        "    )\n",
        ")\n",
        "\n",
        "EVAL_PROMPT = PromptTemplate(\n",
        "    input_variables=[\"chapter\"],\n",
        "    template=(\n",
        "\"\"\"You are a tough fiction editor. Rate the chapter (1â€“10) on:\n",
        "- pacing\n",
        "- tension\n",
        "- voice\n",
        "- imagery\n",
        "- dialogue\n",
        "- novelty\n",
        "\n",
        "Return STRICT JSON only:\n",
        "{{\"scores\":{{\"pacing\":x,\"tension\":x,\"voice\":x,\"imagery\":x,\"dialogue\":x,\"novelty\":x}},\"one_sentence_note\":\"...\",\"three_micro_edits\":[\"...\",\"...\",\"...\"]}}\n",
        "\n",
        "Chapter:\n",
        "{chapter}\n",
        "\"\"\"\n",
        "    )\n",
        ")\n",
        "\n",
        "PUNCHUP_PROMPT = PromptTemplate(\n",
        "    input_variables=[\"chapter\",\"edits\"],\n",
        "    template=(\n",
        "\"\"\"Apply these micro-edits to strengthen the chapter without changing the plot:\n",
        "- {edits}\n",
        "\n",
        "Rules:\n",
        "- Keep POV, continuity, and length roughly the same (Â±10%).\n",
        "- Add concrete sensory details.\n",
        "- Tighten weak sentences; remove clichÃ©s.\n",
        "Return TEXT ONLY.\n",
        "\n",
        "Chapter:\n",
        "{chapter}\n",
        "\"\"\"\n",
        "    )\n",
        ")\n",
        "\n",
        "# Theme/Motif bible, beats, dialogue tuner, decliche, motif miner, blurb\n",
        "THEME_PROMPT = PromptTemplate(\n",
        "    input_variables=[\"topic\",\"outline\"],\n",
        "    template=(\n",
        "\"\"\"From the seed idea and outline, produce STRICT JSON:\n",
        "{{\n",
        "  \"themes\": [\"...\"],         # 3â€“5 core themes\n",
        "  \"motifs\": [\"...\"],         # 6â€“12 recurring props/images\n",
        "  \"promises\": [\"...\"],       # 3â€“6 promises to the reader\n",
        "  \"logline\": \"...\",          # one sentence\n",
        "  \"genre_signals\": [\"...\"]   # 5â€“8 setting/imagery signals\n",
        "}}\n",
        "Seed idea: {topic}\n",
        "Outline: {outline}\n",
        "\"\"\"\n",
        "    )\n",
        ")\n",
        "\n",
        "BEATS_PROMPT = PromptTemplate(\n",
        "    input_variables=[\"title\",\"description\",\"theme_bible\",\"motif_ledger\"],\n",
        "    template=(\n",
        "\"\"\"Plan a beat sheet for the chapter as STRICT JSON:\n",
        "{{\n",
        "  \"beats\": [\n",
        "    {{\"name\":\"Hook\",\"goal\":\"...\",\"conflict\":\"...\",\"setting\":\"...\",\"emotion\":\"...\"}},\n",
        "    ...\n",
        "  ],\n",
        "  \"dialogue_target_pct\": 0.38,\n",
        "  \"sensory_palette\": [\"sound\",\"smell\"],\n",
        "  \"foreshadow\":\"...\",\n",
        "  \"callback_motif\":\"...\"\n",
        "}}\n",
        "Requirements:\n",
        "- 8â€“12 beats, with a mid-chapter reversal and a cliffhanger/stinger.\n",
        "- Use 1â€“2 motifs from MOTIF_LEDGER and add 1 fresh setting element aligned to GENRE_SIGNALS.\n",
        "\n",
        "TITLE: {title}\n",
        "DESC: {description}\n",
        "THEME_BIBLE: {theme_bible}\n",
        "MOTIF_LEDGER: {motif_ledger}\n",
        "\"\"\"\n",
        "    )\n",
        ")\n",
        "\n",
        "CHAPTER_WITH_BEATS_PROMPT = PromptTemplate(\n",
        "    input_variables=[\"title\",\"description\",\"idea\",\"plan\",\"themes\",\"sensory_palette\",\"dialogue_target\"],\n",
        "    template=(\n",
        "\"\"\"Write a ~2200â€“3200 word chapter titled \"{title}\".\n",
        "\n",
        "Seed idea: {idea}\n",
        "Mini-brief: {description}\n",
        "Plan (beats): {plan}\n",
        "\n",
        "Must do:\n",
        "- OPEN with a punchy 1â€“2 sentence HOOK that raises a concrete question.\n",
        "- Emphasize SENSORY PALETTE: {sensory_palette}\n",
        "- Aim for DIALOGUE DENSITY â‰ˆ {dialogue_target:.2f} (about 30â€“45% lines include dialogue).\n",
        "- Integrate 1 motif or prop from the plan naturally.\n",
        "- Midpoint reversal that reframes stakes.\n",
        "- END with a plausible CLIFFHANGER/STINGER (no meta).\n",
        "\n",
        "Style:\n",
        "- Concrete details, crisp verbs; avoid clichÃ©s.\n",
        "- Maintain POV and continuity; no backstory dumps.\n",
        "\n",
        "Themes to subtly reinforce: {themes}\n",
        "Return TEXT ONLY.\n",
        "\"\"\"\n",
        "    )\n",
        ")\n",
        "\n",
        "DIALOGUE_TUNER_PROMPT = PromptTemplate(\n",
        "    input_variables=[\"chapter\",\"target\"],\n",
        "    template=(\n",
        "\"\"\"Revise the chapter to adjust dialogue density to â‰ˆ {target:.2f} (Â±0.08).\n",
        "Keep plot and beats intact. Do not shorten by more than 10% or lengthen by more than 10%.\n",
        "Return TEXT ONLY.\n",
        "\n",
        "Chapter:\n",
        "{chapter}\n",
        "\"\"\"\n",
        "    )\n",
        ")\n",
        "\n",
        "DECLICHE_PROMPT = PromptTemplate(\n",
        "    input_variables=[\"chapter\"],\n",
        "    template=(\n",
        "\"\"\"Rewrite at sentence-level to remove clichÃ©s and filler.\n",
        "Replace with specific, concrete imagery fitting a near-future techno-thriller vibe.\n",
        "Preserve plot, POV, beats, and length (Â±5%). Return TEXT ONLY.\n",
        "\n",
        "Chapter:\n",
        "{chapter}\n",
        "\"\"\"\n",
        "    )\n",
        ")\n",
        "\n",
        "MOTIF_MINER_PROMPT = PromptTemplate(\n",
        "    input_variables=[\"chapter\"],\n",
        "    template=(\n",
        "\"\"\"Extract 1â€“3 recurring motifs/props/images present in this chapter (short noun phrases).\n",
        "Return STRICT JSON: {{\"motifs\":[\"...\"]}}\n",
        "\n",
        "Chapter:\n",
        "{chapter}\n",
        "\"\"\"\n",
        "    )\n",
        ")\n",
        "\n",
        "BLURB_PROMPT = PromptTemplate(\n",
        "    input_variables=[\"title\",\"logline\",\"themes\",\"promises\"],\n",
        "    template=(\n",
        "\"\"\"Write STRICT JSON:\n",
        "{{\n",
        "  \"blurb\":\"...\",           # 120â€“160 words\n",
        "  \"product_hook\":\"...\",    # 1 sentence\n",
        "  \"snippets\": [\"...\",\"...\",\"...\"]  # â‰¤140 chars each\n",
        "}}\n",
        "Title: {title}\n",
        "Logline: {logline}\n",
        "Themes: {themes}\n",
        "Promises: {promises}\n",
        "\"\"\"\n",
        "    )\n",
        ")\n",
        "\n",
        "# Build chains\n",
        "outline_chain_json          = OUTLINE_JSON_PROMPT       | planner_llm_json  # JSON mode\n",
        "outline_chain_ndjson_plan   = OUTLINE_NDJSON_PROMPT     | planner_llm       # NDJSON (planner)\n",
        "outline_chain_ndjson_writer = OUTLINE_NDJSON_PROMPT     | writer_llm        # NDJSON (writer)\n",
        "# Writer JSON chain created on demand later if needed\n",
        "\n",
        "character_chain_json = CHAR_JSON_PROMPT | planner_llm_json\n",
        "\n",
        "chapter_chain     = chapter_prompt               | writer_llm\n",
        "revision_chain    = REVISION_PROMPT              | writer_llm\n",
        "eval_chain        = EVAL_PROMPT                  | planner_llm\n",
        "punchup_chain     = PUNCHUP_PROMPT               | writer_llm\n",
        "\n",
        "theme_chain       = THEME_PROMPT                 | planner_llm\n",
        "beats_chain       = BEATS_PROMPT                 | planner_llm\n",
        "chapter_beats_llm = CHAPTER_WITH_BEATS_PROMPT    | writer_llm\n",
        "dialogue_tuner    = DIALOGUE_TUNER_PROMPT        | writer_llm\n",
        "decliche_chain    = DECLICHE_PROMPT              | writer_llm\n",
        "motif_miner       = MOTIF_MINER_PROMPT           | planner_llm\n",
        "blurb_chain       = BLURB_PROMPT                 | planner_llm\n",
        "\n",
        "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
        "# 3) Utilities: parse, similarity, IO helpers\n",
        "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
        "THINK_RE = re.compile(r\"<think>.*?</think>\\s*\", flags=re.S|re.I)\n",
        "FENCE_RE = re.compile(r\"```(?:json)?|```\", flags=re.I)\n",
        "\n",
        "def strip_think(x: Any) -> str:\n",
        "    s = x[\"text\"] if isinstance(x, dict) and \"text\" in x else str(x)\n",
        "    s = THINK_RE.sub(\"\", s)\n",
        "    s = FENCE_RE.sub(\"\", s)\n",
        "    return s.strip()\n",
        "\n",
        "def parse_json_value(s: str):\n",
        "    \"\"\"Parse last JSON value ({...} or [...]) in a string; return Python obj or None.\"\"\"\n",
        "    s = strip_think(s)\n",
        "    m = re.search(r\"(\\{.*\\}|\\[.*\\])\\s*$\", s, flags=re.S)\n",
        "    if not m: return None\n",
        "    blob = m.group(1)\n",
        "    try:\n",
        "        return json.loads(blob)\n",
        "    except Exception:\n",
        "        fix = blob.replace(\"â€œ\",\"\\\"\").replace(\"â€\",\"\\\"\").replace(\"â€™\",\"'\")\n",
        "        fix = re.sub(r\",\\s*}\", \"}\", fix); fix = re.sub(r\",\\s*]\", \"]\", fix)\n",
        "        try: return json.loads(fix)\n",
        "        except Exception: return None\n",
        "\n",
        "def parse_strict_json(s: str) -> dict:\n",
        "    obj = parse_json_value(s)\n",
        "    return obj if isinstance(obj, dict) else {}\n",
        "\n",
        "# Extract individual JSON objects even if an array is truncated\n",
        "OBJ_RE = re.compile(r\"\\{(?:[^{}]|\\\"[^\\\"\\\\]*(?:\\\\.[^\\\"\\\\]*)*\\\")*\\}\")\n",
        "def extract_json_objects(text: str):\n",
        "    text = strip_think(text)\n",
        "    objs = []\n",
        "    for m in OBJ_RE.finditer(text):\n",
        "        blob = m.group(0)\n",
        "        try:\n",
        "            obj = json.loads(blob)\n",
        "            if isinstance(obj, dict):\n",
        "                objs.append(obj)\n",
        "        except Exception:\n",
        "            try:\n",
        "                fix = blob.replace(\"â€œ\",\"\\\"\").replace(\"â€\",\"\\\"\").replace(\"â€™\",\"'\")\n",
        "                fix = re.sub(r\",\\s*}\", \"}\", fix)\n",
        "                obj = json.loads(fix)\n",
        "                if isinstance(obj, dict):\n",
        "                    objs.append(obj)\n",
        "            except Exception:\n",
        "                pass\n",
        "    return objs\n",
        "\n",
        "def jaccard(a: str, b: str) -> float:\n",
        "    A = set(re.findall(r\"[a-z0-9']+\", a.lower()))\n",
        "    B = set(re.findall(r\"[a-z0-9']+\", b.lower()))\n",
        "    if not A or not B: return 0.0\n",
        "    return len(A & B) / len(A | B)\n",
        "\n",
        "def too_similar(ch1: Dict[str,str], ch2: Dict[str,str]) -> bool:\n",
        "    t_sim = jaccard(ch1[\"title\"], ch2[\"title\"])\n",
        "    d_sim = jaccard(ch1[\"description\"], ch2[\"description\"])\n",
        "    return (t_sim > 0.65) or (t_sim > 0.45 and d_sim > 0.55)\n",
        "\n",
        "def bigram_overlap(a: str, b: str) -> float:\n",
        "    def bigrams(s):\n",
        "        toks = re.findall(r\"[a-z0-9']+\", s.lower())\n",
        "        return set(zip(toks, toks[1:])) if len(toks) > 1 else set()\n",
        "    A, B = bigrams(a), bigrams(b)\n",
        "    denom = len(A | B) if (A or B) else 1\n",
        "    return len(A & B) / denom\n",
        "\n",
        "def top_trigrams(text: str, k: int = 30) -> List[str]:\n",
        "    toks = re.findall(r\"[a-z0-9']+\", text.lower())\n",
        "    tris = Counter(zip(toks, toks[1:], toks[2:]))\n",
        "    return [\" \".join(t) for t,_ in tris.most_common(k)]\n",
        "\n",
        "def approx_dialogue_ratio(text: str) -> float:\n",
        "    lines = [ln.strip() for ln in text.splitlines() if ln.strip()]\n",
        "    if not lines: return 0.0\n",
        "    dial = sum(1 for ln in lines if re.search(r'[\"â€œâ€]|^â€”', ln))\n",
        "    return dial / max(1, len(lines))\n",
        "\n",
        "def word_count(text: str) -> int:\n",
        "    return len(re.findall(r\"[A-Za-z0-9']+\", text or \"\"))\n",
        "\n",
        "# Checkpoint helpers\n",
        "def _slug(s):\n",
        "    return re.sub(r\"[^a-z0-9]+\", \"-\", s.lower()).strip(\"-\")[:60]\n",
        "\n",
        "def _ck_paths(i, title):\n",
        "    base = f\"{i:03d}-{_slug(title)}\"\n",
        "    p = pathlib.Path(CHECKPOINT_DIR)\n",
        "    return p / (base + \".txt\"), p / (base + \".json\")\n",
        "\n",
        "def save_ckpt(i, title, text, notes):\n",
        "    p_txt, p_meta = _ck_paths(i, title)\n",
        "    p_txt.write_text(text or \"\", encoding=\"utf-8\")\n",
        "    meta = {\"chapter_index\": i, \"title\": title, \"notes\": notes}\n",
        "    p_meta.write_text(json.dumps(meta, ensure_ascii=False, indent=2), encoding=\"utf-8\")\n",
        "\n",
        "def load_ckpt_if_any(i, title):\n",
        "    p_txt, p_meta = _ck_paths(i, title)\n",
        "    if p_txt.exists():\n",
        "        text = p_txt.read_text(encoding=\"utf-8\")\n",
        "        notes = None\n",
        "        if p_meta.exists():\n",
        "            try: notes = json.loads(p_meta.read_text(encoding=\"utf-8\"))\n",
        "            except Exception: notes = None\n",
        "        return text, notes\n",
        "    return None, None\n",
        "\n",
        "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
        "# 4) Robust multi-strategy OUTLINE generator (JSON â†’ NDJSON; planner â†’ writer)\n",
        "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
        "print(f\"â†’ Generating {NUM_CH}-chapter outline with robust fallbacks â€¦\")\n",
        "chunk = 5 if not HAS_GPU else 10  # smaller on CPU\n",
        "attempts = 0\n",
        "MAX_ATTEMPTS = 40\n",
        "\n",
        "def clean_outline_items(items):\n",
        "    out = []\n",
        "    for obj in items:\n",
        "        if not isinstance(obj, dict):\n",
        "            continue\n",
        "        title = (obj.get(\"title\") or \"\").strip()\n",
        "        desc  = (obj.get(\"description\") or \"\").strip()\n",
        "        if title and desc:\n",
        "            out.append({\"title\": title, \"description\": desc})\n",
        "    return out\n",
        "\n",
        "def robust_outline_batch(topic: str, ask: int):\n",
        "    # (A) Planner JSON mode\n",
        "    try:\n",
        "        raw = (OUTLINE_JSON_PROMPT | planner_llm_json).invoke({\"topic\": topic, \"count\": ask})\n",
        "        arr = parse_json_value(raw)\n",
        "        if isinstance(arr, list) and arr:\n",
        "            print(\"   âœ“ Outline via planner JSON\")\n",
        "            return clean_outline_items(arr)\n",
        "        objs = extract_json_objects(str(raw))\n",
        "        if objs:\n",
        "            print(\"   âœ“ Outline via planner JSON (partial array rescued)\")\n",
        "            return clean_outline_items(objs)\n",
        "    except Exception as e:\n",
        "        print(f\"   Â· Planner JSON failed: {e}\")\n",
        "\n",
        "    # (B) Planner NDJSON\n",
        "    try:\n",
        "        raw = (OUTLINE_NDJSON_PROMPT | planner_llm).invoke({\"topic\": topic, \"count\": ask})\n",
        "        lines = [ln for ln in strip_think(raw).splitlines() if ln.strip()]\n",
        "        objs = []\n",
        "        for ln in lines:\n",
        "            try:\n",
        "                objs.append(json.loads(ln))\n",
        "            except Exception:\n",
        "                fix = ln.replace(\"â€œ\",\"\\\"\").replace(\"â€\",\"\\\"\").replace(\"â€™\",\"'\")\n",
        "                fix = re.sub(r\",\\s*}\", \"}\", fix)\n",
        "                try: objs.append(json.loads(fix))\n",
        "                except Exception: pass\n",
        "        if objs:\n",
        "            print(\"   âœ“ Outline via planner NDJSON\")\n",
        "            return clean_outline_items(objs)\n",
        "    except Exception as e:\n",
        "        print(f\"   Â· Planner NDJSON failed: {e}\")\n",
        "\n",
        "    # (C) Writer JSON mode\n",
        "    try:\n",
        "        outline_chain_json_writer = OUTLINE_JSON_PROMPT | writer_llm\n",
        "        raw = outline_chain_json_writer.invoke({\"topic\": topic, \"count\": ask})\n",
        "        arr = parse_json_value(raw)\n",
        "        if isinstance(arr, list) and arr:\n",
        "            print(\"   âœ“ Outline via writer JSON\")\n",
        "            return clean_outline_items(arr)\n",
        "        objs = extract_json_objects(str(raw))\n",
        "        if objs:\n",
        "            print(\"   âœ“ Outline via writer JSON (partial array rescued)\")\n",
        "            return clean_outline_items(objs)\n",
        "    except Exception as e:\n",
        "        print(f\"   Â· Writer JSON failed: {e}\")\n",
        "\n",
        "    # (D) Writer NDJSON\n",
        "    try:\n",
        "        raw = (OUTLINE_NDJSON_PROMPT | writer_llm).invoke({\"topic\": topic, \"count\": ask})\n",
        "        lines = [ln for ln in strip_think(raw).splitlines() if ln.strip()]\n",
        "        objs = []\n",
        "        for ln in lines:\n",
        "            try:\n",
        "                objs.append(json.loads(ln))\n",
        "            except Exception:\n",
        "                fix = ln.replace(\"â€œ\",\"\\\"\").replace(\"â€\",\"\\\"\").replace(\"â€™\",\"'\")\n",
        "                fix = re.sub(r\",\\s*}\", \"}\", fix)\n",
        "                try: objs.append(json.loads(fix))\n",
        "                except Exception: pass\n",
        "        if objs:\n",
        "            print(\"   âœ“ Outline via writer NDJSON\")\n",
        "            return clean_outline_items(objs)\n",
        "    except Exception as e:\n",
        "        print(f\"   Â· Writer NDJSON failed: {e}\")\n",
        "\n",
        "    # (E) Last-resort stub generation so the pipeline can proceed\n",
        "    print(\"   âš ï¸ Using stubbed outline seeds (fallback).\")\n",
        "    return [\n",
        "        {\"title\": f\"Thread {i+1}: Anomalous Signal\",\n",
        "         \"description\": \"A troubling pattern emerges in the influencer data; tension escalates and a new obstacle appears.\"}\n",
        "        for i in range(ask)\n",
        "    ]\n",
        "\n",
        "# Build the outline with dedupe\n",
        "outline, seen_titles = [], set()\n",
        "needed = NUM_CH\n",
        "while len(outline) < needed and attempts < MAX_ATTEMPTS:\n",
        "    ask = min(chunk, needed - len(outline))\n",
        "    batch = robust_outline_batch(SEED_IDEA, ask)\n",
        "    attempts += 1\n",
        "    added = 0\n",
        "    for ch in batch:\n",
        "        if not ch[\"title\"] or not ch[\"description\"]:\n",
        "            continue\n",
        "        if ch[\"title\"] in seen_titles:\n",
        "            continue\n",
        "        if any(too_similar(ch, e) for e in outline):\n",
        "            continue\n",
        "        outline.append(ch)\n",
        "        seen_titles.add(ch[\"title\"])\n",
        "        added += 1\n",
        "        if len(outline) >= needed:\n",
        "            break\n",
        "    if added == 0:\n",
        "        print(\"   Â· No unique chapters accepted from batch; retryingâ€¦\")\n",
        "\n",
        "print(f\"âœ” Final outline: {len(outline)} chapters\\n\")\n",
        "if len(outline) < needed:\n",
        "    print(\"âš ï¸ Could not reach target count; proceeding with what we have.\")\n",
        "\n",
        "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
        "# 5) Character Bible (robust JSON) + Theme/Motif Bible\n",
        "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
        "def robust_characters(outline_list, n_chars):\n",
        "    # Try planner JSON first\n",
        "    for stage in [\"planner_json\", \"writer_json\", \"planner_fallback\"]:\n",
        "        try:\n",
        "            if stage == \"planner_json\":\n",
        "                raw = character_chain_json.invoke({\n",
        "                    \"outline\": json.dumps(outline_list, ensure_ascii=False),\n",
        "                    \"num_chars\": n_chars\n",
        "                })\n",
        "                arr = parse_json_value(raw)\n",
        "                if isinstance(arr, list) and len(arr) >= min(3, n_chars//2):\n",
        "                    return [c for c in arr if isinstance(c, dict)][:n_chars]\n",
        "            elif stage == \"writer_json\":\n",
        "                char_chain_json_writer = CHAR_JSON_PROMPT | writer_llm\n",
        "                raw = char_chain_json_writer.invoke({\n",
        "                    \"outline\": json.dumps(outline_list, ensure_ascii=False),\n",
        "                    \"num_chars\": n_chars\n",
        "                })\n",
        "                arr = parse_json_value(raw)\n",
        "                if isinstance(arr, list) and len(arr) >= min(3, n_chars//2):\n",
        "                    return [c for c in arr if isinstance(c, dict)][:n_chars]\n",
        "            else:\n",
        "                # last-resort minimal characters\n",
        "                return [\n",
        "                    {\"name\": \"Lena Park\", \"role\": \"Protagonist\",\n",
        "                     \"development_arc\": \"From isolated analyst to whistleblower forging unlikely alliances.\"},\n",
        "                    {\"name\": \"Mara Voss\", \"role\": \"Rising Influencer\",\n",
        "                     \"development_arc\": \"Charismatic star reveals engineered persona; torn between truth and fame.\"},\n",
        "                    {\"name\": \"Rex Calder\", \"role\": \"Datum Executive\",\n",
        "                     \"development_arc\": \"From mentor figure to antagonist entangled in AI-influence scheme.\"},\n",
        "                ][:n_chars]\n",
        "        except Exception:\n",
        "            continue\n",
        "    return []\n",
        "\n",
        "NUM_CHAR = max(3, min(10, len(outline)//8))\n",
        "print(f\"â†’ Generating {NUM_CHAR} characters (robust)â€¦\")\n",
        "characters = robust_characters(outline, NUM_CHAR)\n",
        "print(f\"âœ” Got {len(characters)} characters\\n\")\n",
        "\n",
        "print(\"â†’ Building theme/motif bibleâ€¦\")\n",
        "theme_raw = theme_chain.invoke({\n",
        "    \"topic\": SEED_IDEA,\n",
        "    \"outline\": json.dumps(outline, ensure_ascii=False)\n",
        "})\n",
        "THEME_BIBLE = parse_strict_json(theme_raw) or {\n",
        "    \"themes\": [],\n",
        "    \"motifs\": [],\n",
        "    \"promises\": [],\n",
        "    \"logline\": \"\",\n",
        "    \"genre_signals\": []\n",
        "}\n",
        "MOTIF_LEDGER = list(THEME_BIBLE.get(\"motifs\", []))  # seed with global motifs\n",
        "print(\"âœ” Theme bible ready.\\n\")\n",
        "\n",
        "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
        "# 6) Chapter Generation with beats + checkpointing + early re-calibration\n",
        "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
        "print(\"â†’ Generating chaptersâ€¦\")\n",
        "chap_texts = [None]*len(outline)\n",
        "editor_notes = [None]*len(outline)\n",
        "BIGRAM_THRESHOLD = 0.22  # repetition strictness\n",
        "\n",
        "def write_one(idx):\n",
        "    meta = outline[idx]\n",
        "    title = meta[\"title\"]\n",
        "\n",
        "    # Resume if checkpoint exists\n",
        "    cached_txt, cached_notes = load_ckpt_if_any(idx, title)\n",
        "    if cached_txt:\n",
        "        return cached_txt, cached_notes\n",
        "\n",
        "    # 1) Plan beats with callbacks to existing motif ledger\n",
        "    plan_raw = beats_chain.invoke({\n",
        "        \"title\": meta[\"title\"],\n",
        "        \"description\": meta[\"description\"],\n",
        "        \"theme_bible\": json.dumps(THEME_BIBLE, ensure_ascii=False),\n",
        "        \"motif_ledger\": json.dumps(MOTIF_LEDGER[-12:], ensure_ascii=False)\n",
        "    })\n",
        "    plan = parse_strict_json(plan_raw)\n",
        "    dialogue_target = float(plan.get(\"dialogue_target_pct\", 0.36))\n",
        "    sensory_palette = plan.get(\"sensory_palette\", [\"sight\",\"sound\"])\n",
        "    plan_json = json.dumps(plan.get(\"beats\", []), ensure_ascii=False)\n",
        "\n",
        "    # 2) Draft with hooks, sensory palette, dialogue target\n",
        "    res = chapter_beats_llm.invoke({\n",
        "        \"title\": meta[\"title\"],\n",
        "        \"description\": meta[\"description\"],\n",
        "        \"idea\": SEED_IDEA,\n",
        "        \"plan\": plan_json,\n",
        "        \"themes\": \", \".join(THEME_BIBLE.get(\"themes\", [])),\n",
        "        \"sensory_palette\": \", \".join(sensory_palette),\n",
        "        \"dialogue_target\": dialogue_target\n",
        "    })\n",
        "    chapter_txt = strip_think(res)\n",
        "\n",
        "    # 3) Repetition guard vs earlier chapters\n",
        "    ledger = []\n",
        "    for j in range(idx):\n",
        "        prev = chap_texts[j]\n",
        "        if not prev: continue\n",
        "        if bigram_overlap(chapter_txt, prev) > BIGRAM_THRESHOLD:\n",
        "            ledger.extend(top_trigrams(prev, k=10))\n",
        "    ledger = list(dict.fromkeys(ledger))[:60]\n",
        "    if ledger:\n",
        "        revised = revision_chain.invoke({\n",
        "            \"chapter\": chapter_txt,\n",
        "            \"title\": meta[\"title\"],\n",
        "            \"description\": meta[\"description\"],\n",
        "            \"ledger\": \"; \".join(ledger)\n",
        "        })\n",
        "        chapter_txt = strip_think(revised)\n",
        "\n",
        "    # 4/5) Auto-evaluation â†’ only run heavy passes if needed\n",
        "    data = None\n",
        "    try:\n",
        "        report_raw = eval_chain.invoke({\"chapter\": chapter_txt})\n",
        "        report_txt = strip_think(report_raw)\n",
        "        m = re.search(r\"\\{[\\s\\S]*\\}\\s*$\", report_txt)\n",
        "        if m:\n",
        "            data = json.loads(m.group(0))\n",
        "        if data and \"scores\" in data:\n",
        "            scores = data[\"scores\"]\n",
        "            avg_score = sum(float(scores[k]) for k in scores)/len(scores)\n",
        "\n",
        "            # Dialogue tuner if notably off target\n",
        "            dr = approx_dialogue_ratio(chapter_txt)\n",
        "            if abs(dr - dialogue_target) > 0.10:\n",
        "                tuned = dialogue_tuner.invoke({\"chapter\": chapter_txt, \"target\": dialogue_target})\n",
        "                chapter_txt = strip_think(tuned)\n",
        "\n",
        "            # DeclichÃ© only when quality is mid or FAST_MODE off\n",
        "            if (avg_score < 7.6) or (not FAST_MODE):\n",
        "                polished = decliche_chain.invoke({\"chapter\": chapter_txt})\n",
        "                chapter_txt = strip_think(polished)\n",
        "\n",
        "            # Punch-up if still low\n",
        "            if avg_score < 7.4:\n",
        "                edits = \" | \".join(data.get(\"three_micro_edits\", [])) or \\\n",
        "                        \"Sharpen hooks; escalate midpoint; add concrete sensory beats.\"\n",
        "                punched = punchup_chain.invoke({\"chapter\": chapter_txt, \"edits\": edits})\n",
        "                chapter_txt = strip_think(punched)\n",
        "    except Exception:\n",
        "        data = None\n",
        "\n",
        "    # 6) Mine motifs from this chapter â†’ update global ledger\n",
        "    try:\n",
        "        mined_raw = motif_miner.invoke({\"chapter\": chapter_txt})\n",
        "        mined = parse_strict_json(mined_raw)\n",
        "        for m in (mined.get(\"motifs\") or []):\n",
        "            if m not in MOTIF_LEDGER:\n",
        "                MOTIF_LEDGER.append(m)\n",
        "    except Exception:\n",
        "        pass\n",
        "\n",
        "    # Save checkpoint\n",
        "    save_ckpt(idx, title, chapter_txt, data)\n",
        "    return chapter_txt, data\n",
        "\n",
        "# â€”â€” Early calibration: write first few chapters serially, resize outline\n",
        "PREGEN = min(3, len(outline))\n",
        "for i in range(PREGEN):\n",
        "    ch_txt, notes = write_one(i)\n",
        "    chap_texts[i] = ch_txt\n",
        "    editor_notes[i] = notes\n",
        "\n",
        "# Measure actual words/chapter and re-size remaining outline to hit target pages\n",
        "actual_avg = max(500, sum(word_count(chap_texts[i]) for i in range(PREGEN)) // PREGEN)\n",
        "recalc_num_ch = max(12, min(80, (TARGET_WORDS + actual_avg - 1) // actual_avg))\n",
        "\n",
        "if recalc_num_ch != len(outline):\n",
        "    delta = recalc_num_ch - len(outline)\n",
        "    if delta > 0:\n",
        "        ask_more = delta\n",
        "        extra = robust_outline_batch(SEED_IDEA, ask_more)\n",
        "        seen_titles = set([c[\"title\"] for c in outline])\n",
        "        for obj in extra:\n",
        "            cand = {\"title\": (obj.get(\"title\") or \"\").strip(),\n",
        "                    \"description\": (obj.get(\"description\") or \"\").strip()}\n",
        "            if not cand[\"title\"] or not cand[\"description\"]:\n",
        "                continue\n",
        "            if cand[\"title\"] in seen_titles:\n",
        "                continue\n",
        "            if any(too_similar(cand, e) for e in outline):\n",
        "                continue\n",
        "            outline.append(cand); seen_titles.add(cand[\"title\"])\n",
        "            chap_texts.append(None); editor_notes.append(None)\n",
        "            if len(outline) >= recalc_num_ch: break\n",
        "        print(f\"ğŸ” Resized outline: +{max(0, delta)} â†’ total {len(outline)} chapters\")\n",
        "    elif delta < 0:\n",
        "        keep = max(PREGEN, recalc_num_ch)\n",
        "        outline = outline[:keep]\n",
        "        chap_texts = chap_texts[:keep]\n",
        "        editor_notes = editor_notes[:keep]\n",
        "        print(f\"âœ‚ï¸  Trimmed outline to {len(outline)} chapters\")\n",
        "\n",
        "# Generate remaining chapters\n",
        "remaining_idxs = [i for i, t in enumerate(chap_texts) if t is None]\n",
        "with ThreadPoolExecutor(max_workers=MAX_WORKERS) as ex:\n",
        "    futures = { ex.submit(write_one, i): i for i in remaining_idxs }\n",
        "    for fut in tqdm(as_completed(futures), total=len(futures), desc=\"Chapters\"):\n",
        "        idx = futures[fut]\n",
        "        try:\n",
        "            ch_txt, notes = fut.result()\n",
        "        except Exception as e:\n",
        "            ch_txt, notes = f\"[Generation failed: {e}]\", None\n",
        "        chap_texts[idx] = ch_txt\n",
        "        editor_notes[idx] = notes\n",
        "\n",
        "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
        "# 7) Pre-save totals â†’ Save to Word + Back-cover copy + Download\n",
        "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
        "total_words = sum(word_count(t or \"\") for t in chap_texts)\n",
        "est_pages  = total_words / WORDS_PER_PAGE\n",
        "suggested_ch = max(12, min(80, round(total_words / CH_TARGET_WORDS)))\n",
        "print(f\"ğŸ§® Total words: {total_words:,}  â†’ est. pages â‰ˆ {est_pages:.0f}\")\n",
        "print(f\"ğŸ”§ If you rerun, suggested chapters for this style â‰ˆ {suggested_ch}\")\n",
        "\n",
        "doc = docx.Document()\n",
        "doc.add_heading(BOOK_TITLE, 0)\n",
        "doc.add_paragraph(f\"Seed idea: {SEED_IDEA}\")\n",
        "doc.add_paragraph(f\"Estimated pages: ~{est_pages:.0f}\")\n",
        "\n",
        "# Character Development Section\n",
        "if characters:\n",
        "    doc.add_page_break()\n",
        "    doc.add_heading(\"Character Development\", level=1)\n",
        "    for c in characters:\n",
        "        name = c.get(\"name\",\"(Unnamed)\")\n",
        "        role = c.get(\"role\",\"\")\n",
        "        arc  = c.get(\"development_arc\",\"\")\n",
        "        doc.add_heading(name, level=2)\n",
        "        if role: doc.add_paragraph(f\"Role: {role}\")\n",
        "        if arc:  doc.add_paragraph(arc)\n",
        "\n",
        "# Chapters\n",
        "for i, (meta, text) in enumerate(zip(outline, chap_texts), start=1):\n",
        "    doc.add_page_break()\n",
        "    doc.add_heading(f\"Chapter {i}: {meta['title']}\", level=1)\n",
        "    doc.add_paragraph(meta['description'], style=\"Intense Quote\")\n",
        "    doc.add_paragraph((text or \"\").strip())\n",
        "\n",
        "# Editorâ€™s Notes (Auto-Eval)\n",
        "doc.add_page_break()\n",
        "doc.add_heading(\"Editorâ€™s Notes (Auto-Eval)\", level=1)\n",
        "for i, (meta, notes) in enumerate(zip(outline, editor_notes), start=1):\n",
        "    doc.add_heading(f\"Chapter {i}: {meta['title']}\", level=2)\n",
        "    if not notes or \"scores\" not in (notes or {}):\n",
        "        doc.add_paragraph(\"No evaluation available.\")\n",
        "        continue\n",
        "    scores = notes[\"scores\"]\n",
        "    one_liner = notes.get(\"one_sentence_note\",\"\")\n",
        "    edits = notes.get(\"three_micro_edits\", [])\n",
        "    try:\n",
        "        avg_score = sum(float(scores[k]) for k in scores)/len(scores)\n",
        "    except Exception:\n",
        "        avg_score = None\n",
        "    doc.add_paragraph(\"Scores: \" + \", \".join(f\"{k}: {scores[k]}\" for k in scores))\n",
        "    if avg_score is not None:\n",
        "        doc.add_paragraph(f\"Average: {avg_score:.2f}\")\n",
        "    if one_liner:\n",
        "        doc.add_paragraph(f\"Note: {one_liner}\")\n",
        "    if edits:\n",
        "        for e in edits:\n",
        "            doc.add_paragraph(f\"â€¢ {e}\")\n",
        "\n",
        "# Back-cover blurb + retailer hook + social snippets\n",
        "blurb_data = {}\n",
        "try:\n",
        "    blurb_raw = blurb_chain.invoke({\n",
        "        \"title\": BOOK_TITLE,\n",
        "        \"logline\": THEME_BIBLE.get(\"logline\",\"\"),\n",
        "        \"themes\": \", \".join(THEME_BIBLE.get(\"themes\", [])),\n",
        "        \"promises\": \", \".join(THEME_BIBLE.get(\"promises\", []))\n",
        "    })\n",
        "    blurb_data = parse_strict_json(blurb_raw) or {}\n",
        "except Exception:\n",
        "    blurb_data = {}\n",
        "\n",
        "doc.add_page_break()\n",
        "doc.add_heading(\"Back-Cover Copy & Retailer Hook\", level=1)\n",
        "if blurb_data.get(\"blurb\"):\n",
        "    doc.add_paragraph(blurb_data[\"blurb\"])\n",
        "if blurb_data.get(\"product_hook\"):\n",
        "    doc.add_paragraph(f\"\\nRetailer Hook: {blurb_data['product_hook']}\")\n",
        "if blurb_data.get(\"snippets\"):\n",
        "    doc.add_heading(\"Short Social Snippets\", level=2)\n",
        "    for s in blurb_data[\"snippets\"]:\n",
        "        doc.add_paragraph(f\"â€¢ {s}\")\n",
        "\n",
        "# Save & download\n",
        "fn = BOOK_TITLE.replace(\" \", \"_\") + \".docx\"\n",
        "doc.save(fn)\n",
        "print(f\"ğŸ“˜ Saved {fn}\")\n",
        "files.download(fn)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "TRXa6Tuz37Uh",
        "outputId": "12344420-5d6e-49c8-dc77-4d53d65be145"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "âœ… Ollama health: 200\n",
            "ğŸ–¥ï¸ GPU: not detected\n",
            "âœ” Using model: llama3.2:3b\n",
            "âœ” Using model: llama3.2:3b\n",
            "ğŸ¯ Target pages: 320  â†’ target words â‰ˆ 88,000\n",
            "ğŸ“ Chapter target: ~3,000 words â†’ initial chapters: 30\n",
            "â†’ Generating 30-chapter outline with robust fallbacks â€¦\n",
            "   âœ“ Outline via planner JSON (partial array rescued)\n",
            "   âœ“ Outline via planner JSON (partial array rescued)\n",
            "   âœ“ Outline via planner JSON (partial array rescued)\n",
            "   âœ“ Outline via planner JSON (partial array rescued)\n",
            "   Â· No unique chapters accepted from batch; retryingâ€¦\n",
            "   âœ“ Outline via planner JSON (partial array rescued)\n",
            "   Â· No unique chapters accepted from batch; retryingâ€¦\n",
            "   âœ“ Outline via planner JSON (partial array rescued)\n",
            "   Â· No unique chapters accepted from batch; retryingâ€¦\n",
            "   âœ“ Outline via planner JSON (partial array rescued)\n",
            "   Â· No unique chapters accepted from batch; retryingâ€¦\n",
            "   âœ“ Outline via planner JSON (partial array rescued)\n",
            "   Â· No unique chapters accepted from batch; retryingâ€¦\n",
            "   âœ“ Outline via planner JSON (partial array rescued)\n",
            "   Â· No unique chapters accepted from batch; retryingâ€¦\n",
            "   âœ“ Outline via planner JSON (partial array rescued)\n",
            "   Â· No unique chapters accepted from batch; retryingâ€¦\n",
            "   âœ“ Outline via planner JSON (partial array rescued)\n",
            "   Â· No unique chapters accepted from batch; retryingâ€¦\n",
            "   âœ“ Outline via planner JSON (partial array rescued)\n",
            "   Â· No unique chapters accepted from batch; retryingâ€¦\n",
            "   âœ“ Outline via planner JSON (partial array rescued)\n",
            "   Â· No unique chapters accepted from batch; retryingâ€¦\n",
            "   âœ“ Outline via planner JSON (partial array rescued)\n",
            "   Â· No unique chapters accepted from batch; retryingâ€¦\n",
            "   âœ“ Outline via planner JSON (partial array rescued)\n",
            "   Â· No unique chapters accepted from batch; retryingâ€¦\n",
            "   âœ“ Outline via planner JSON (partial array rescued)\n",
            "   Â· No unique chapters accepted from batch; retryingâ€¦\n",
            "   âœ“ Outline via planner JSON (partial array rescued)\n",
            "   Â· No unique chapters accepted from batch; retryingâ€¦\n",
            "   âœ“ Outline via planner JSON (partial array rescued)\n",
            "   Â· No unique chapters accepted from batch; retryingâ€¦\n",
            "   âœ“ Outline via planner JSON (partial array rescued)\n",
            "   Â· No unique chapters accepted from batch; retryingâ€¦\n",
            "   âœ“ Outline via planner JSON (partial array rescued)\n",
            "   Â· No unique chapters accepted from batch; retryingâ€¦\n",
            "   âœ“ Outline via planner JSON (partial array rescued)\n",
            "   âœ“ Outline via planner JSON (partial array rescued)\n",
            "   Â· No unique chapters accepted from batch; retryingâ€¦\n",
            "   âœ“ Outline via planner JSON (partial array rescued)\n",
            "   Â· No unique chapters accepted from batch; retryingâ€¦\n",
            "   âœ“ Outline via planner JSON (partial array rescued)\n",
            "   Â· No unique chapters accepted from batch; retryingâ€¦\n",
            "   âœ“ Outline via planner JSON (partial array rescued)\n",
            "   Â· No unique chapters accepted from batch; retryingâ€¦\n",
            "   âœ“ Outline via planner JSON (partial array rescued)\n",
            "   Â· No unique chapters accepted from batch; retryingâ€¦\n",
            "   âœ“ Outline via planner JSON (partial array rescued)\n",
            "   Â· No unique chapters accepted from batch; retryingâ€¦\n",
            "   âœ“ Outline via planner JSON (partial array rescued)\n",
            "   Â· No unique chapters accepted from batch; retryingâ€¦\n",
            "   âœ“ Outline via planner JSON (partial array rescued)\n",
            "   Â· No unique chapters accepted from batch; retryingâ€¦\n",
            "   âœ“ Outline via planner JSON (partial array rescued)\n",
            "   Â· No unique chapters accepted from batch; retryingâ€¦\n",
            "   âœ“ Outline via planner JSON (partial array rescued)\n",
            "   Â· No unique chapters accepted from batch; retryingâ€¦\n",
            "   âœ“ Outline via planner JSON (partial array rescued)\n",
            "   Â· No unique chapters accepted from batch; retryingâ€¦\n",
            "   âœ“ Outline via planner JSON (partial array rescued)\n",
            "   Â· No unique chapters accepted from batch; retryingâ€¦\n",
            "   âœ“ Outline via planner JSON (partial array rescued)\n",
            "   Â· No unique chapters accepted from batch; retryingâ€¦\n",
            "   âœ“ Outline via planner JSON (partial array rescued)\n",
            "   Â· No unique chapters accepted from batch; retryingâ€¦\n",
            "   âœ“ Outline via planner JSON (partial array rescued)\n",
            "   Â· No unique chapters accepted from batch; retryingâ€¦\n",
            "   âœ“ Outline via planner JSON (partial array rescued)\n",
            "   Â· No unique chapters accepted from batch; retryingâ€¦\n",
            "   âœ“ Outline via planner JSON (partial array rescued)\n",
            "   Â· No unique chapters accepted from batch; retryingâ€¦\n",
            "   âœ“ Outline via planner JSON (partial array rescued)\n",
            "   Â· No unique chapters accepted from batch; retryingâ€¦\n",
            "   âœ“ Outline via planner JSON (partial array rescued)\n",
            "   Â· No unique chapters accepted from batch; retryingâ€¦\n",
            "âœ” Final outline: 4 chapters\n",
            "\n",
            "âš ï¸ Could not reach target count; proceeding with what we have.\n",
            "â†’ Generating 3 characters (robust)â€¦\n",
            "âœ” Got 3 characters\n",
            "\n",
            "â†’ Building theme/motif bibleâ€¦\n",
            "âœ” Theme bible ready.\n",
            "\n",
            "â†’ Generating chaptersâ€¦\n",
            "   âœ“ Outline via planner JSON (partial array rescued)\n",
            "ğŸ” Resized outline: +76 â†’ total 4 chapters\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Chapters: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [20:37<00:00, 1237.66s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ğŸ§® Total words: 3,043  â†’ est. pages â‰ˆ 11\n",
            "ğŸ”§ If you rerun, suggested chapters for this style â‰ˆ 12\n",
            "ğŸ“˜ Saved Artificial_Influencers_2.docx\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_ce26b045-5834-499b-b28f-18b4b13123eb\", \"Artificial_Influencers_2.docx\", 45029)"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "oU8k_ySqT4I2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
        "# 0) Colab Setup: install & launch Ollama (speed toggles, checkpoints, resolver)\n",
        "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
        "!pip install --quiet langchain-ollama python-docx tqdm\n",
        "\n",
        "import os, threading, subprocess, time, requests, json, re, shutil, pathlib, math, sys, random\n",
        "from typing import List, Any, Dict\n",
        "from concurrent.futures import ThreadPoolExecutor, as_completed\n",
        "from collections import Counter\n",
        "from tqdm import tqdm\n",
        "import docx\n",
        "from google.colab import files\n",
        "\n",
        "# Avoid LangChain provider hijacks\n",
        "for v in [\n",
        "    \"OPENAI_API_KEY\",\n",
        "    \"LITELLM_PROVIDER\", \"LITELLM_MODEL\", \"LITELLM_BASE_URL\",\n",
        "    \"LITELL M_PROVIDER\", \"LITELL M_MODEL\", \"LITELL M_BASE_URL\"  # catch stray typos\n",
        "]:\n",
        "    os.environ.pop(v, None)\n",
        "\n",
        "# â€”â€” Speed/robustness knobs â€”â€”\n",
        "FAST_MODE = True                 # Flip to False when you're happy with the outputs\n",
        "CHECKPOINT_DIR = \"book_ckpt\"     # Saves each chapter & metadata\n",
        "os.makedirs(CHECKPOINT_DIR, exist_ok=True)\n",
        "\n",
        "# Make Ollama conservative about parallelism in Colab\n",
        "os.environ[\"OLLAMA_MAX_LOADED_MODELS\"] = \"1\"\n",
        "os.environ[\"OLLAMA_NUM_PARALLEL\"] = \"1\"\n",
        "\n",
        "# Launch Ollama daemon\n",
        "os.environ[\"OLLAMA_HOST\"]    = \"127.0.0.1:11434\"\n",
        "os.environ[\"OLLAMA_ORIGINS\"] = \"*\"\n",
        "\n",
        "!curl -fsSL https://ollama.com/install.sh -o install.sh\n",
        "!bash install.sh >/dev/null 2>&1 || true\n",
        "\n",
        "def _serve_ollama():\n",
        "    subprocess.Popen([\"ollama\",\"serve\"], stderr=subprocess.DEVNULL, stdout=subprocess.DEVNULL)\n",
        "\n",
        "threading.Thread(target=_serve_ollama, daemon=True).start()\n",
        "time.sleep(8)\n",
        "print(\"âœ… Ollama health:\", requests.get(\"http://127.0.0.1:11434\").status_code)\n",
        "\n",
        "# GPU detection to size workers\n",
        "def _has_gpu():\n",
        "    try:\n",
        "        return shutil.which(\"nvidia-smi\") and (subprocess.run([\"nvidia-smi\"], capture_output=True).returncode==0)\n",
        "    except Exception:\n",
        "        return False\n",
        "HAS_GPU = bool(_has_gpu())\n",
        "print(\"ğŸ–¥ï¸ GPU:\", \"available\" if HAS_GPU else \"not detected\")\n",
        "\n",
        "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
        "# Helper: choose models that actually exist locally/remote via pull\n",
        "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
        "def pick_first_available(candidates: List[str]) -> str:\n",
        "    for m in candidates:\n",
        "        try:\n",
        "            r = subprocess.run([\"ollama\", \"pull\", m], capture_output=True, text=True)\n",
        "            if r.returncode == 0:\n",
        "                print(f\"âœ” Using model: {m}\")\n",
        "                return m\n",
        "            else:\n",
        "                print(f\"âœ– Pull failed for {m} â†’ {r.stderr.strip() or r.stdout.strip()}\")\n",
        "        except Exception as e:\n",
        "            print(f\"âœ– Error pulling {m}: {e}\")\n",
        "    raise RuntimeError(f\"No candidate models could be pulled: {candidates}\")\n",
        "\n",
        "# Good planner-size candidates (small & widely available)\n",
        "PLANNER_CANDIDATES = [\n",
        "    \"llama3.2:3b\",\n",
        "    \"qwen2.5:3b\",\n",
        "    \"phi3:3.8b-mini\",\n",
        "    \"gemma2:2b\",\n",
        "    \"mistral:7b\",\n",
        "    \"llama3.1:8b\",\n",
        "]\n",
        "\n",
        "# Writer candidates\n",
        "WRITER_FAST_CANDIDATES = [\n",
        "    \"llama3.2:3b\",\n",
        "    \"qwen2.5:3b\",\n",
        "    \"phi3:3.8b-mini\",\n",
        "    \"gemma2:2b\",\n",
        "    \"mistral:7b\",\n",
        "    \"llama3.1:8b\",\n",
        "]\n",
        "WRITER_QUALITY_CANDIDATES = [\n",
        "    \"llama3.1:8b\",\n",
        "    \"mistral:7b\",\n",
        "    \"qwen2.5:7b\",\n",
        "]\n",
        "\n",
        "# Resolve models now\n",
        "PLANNER_MODEL = pick_first_available(PLANNER_CANDIDATES)\n",
        "WRITER_MODEL  = pick_first_available(WRITER_FAST_CANDIDATES if FAST_MODE else WRITER_QUALITY_CANDIDATES)\n",
        "\n",
        "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
        "# 1) User parameters (auto size by target pages â†’ chapters)\n",
        "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
        "BOOK_TITLE   = \"Artificial Influencers 2\"\n",
        "MODE         = \"fiction\"  # or \"nonfiction\"\n",
        "\n",
        "# Either set an explicit target page count, or leave None to auto-center the profile\n",
        "TARGET_PAGES = 320 if MODE == \"fiction\" else 280\n",
        "\n",
        "GENRE_PROFILE = {\n",
        "    \"fiction\":   {\"pages_min\": 280, \"pages_max\": 360, \"chapter_words_typical\": (2400, 3600)},\n",
        "    \"nonfiction\":{\"pages_min\": 220, \"pages_max\": 320, \"chapter_words_typical\": (3000, 4500)}\n",
        "}[MODE]\n",
        "\n",
        "if TARGET_PAGES is None:\n",
        "    TARGET_PAGES = (GENRE_PROFILE[\"pages_min\"] + GENRE_PROFILE[\"pages_max\"]) // 2\n",
        "\n",
        "# Words-per-page assumption (trade paperback-ish)\n",
        "WORDS_PER_PAGE = 275\n",
        "TARGET_WORDS   = int(TARGET_PAGES * WORDS_PER_PAGE)\n",
        "\n",
        "# Choose a target chapter length (midpoint of typical band), and derive initial chapter count:\n",
        "CH_MIN, CH_MAX = GENRE_PROFILE[\"chapter_words_typical\"]\n",
        "CH_TARGET_WORDS = int((CH_MIN + CH_MAX) / 2)\n",
        "NUM_CH = max(12, min(80, (TARGET_WORDS + CH_TARGET_WORDS - 1) // CH_TARGET_WORDS))\n",
        "\n",
        "# Your story seed:\n",
        "SEED_IDEA = (\n",
        "    \"an idea for an alternative history story: What would have happended if Hillary Clinton  won the 2016 election instead of Donald J Trump.\"\n",
        ")\n",
        "\n",
        "print(f\"ğŸ¯ Target pages: {TARGET_PAGES}  â†’ target words â‰ˆ {TARGET_WORDS:,}\")\n",
        "print(f\"ğŸ“ Chapter target: ~{CH_TARGET_WORDS:,} words â†’ initial chapters: {NUM_CH}\")\n",
        "\n",
        "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
        "# 2) LLMs & Prompts (planner JSON+fallbacks baked in)\n",
        "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
        "from langchain_ollama import OllamaLLM\n",
        "from langchain_core.prompts import PromptTemplate  # modern import\n",
        "\n",
        "PLANNER_NUM_PREDICT = 900 if FAST_MODE else 1400\n",
        "WRITER_NUM_PREDICT  = 1600 if FAST_MODE else 3000\n",
        "MAX_WORKERS = 1 if (FAST_MODE or not HAS_GPU) else 3   # conservative on CPU\n",
        "\n",
        "# Planner: free-form and JSON-locked\n",
        "planner_llm = OllamaLLM(\n",
        "    model=PLANNER_MODEL,\n",
        "    base_url=\"http://127.0.0.1:11434\",\n",
        "    temperature=0.25,\n",
        "    num_predict=PLANNER_NUM_PREDICT,\n",
        ")\n",
        "planner_llm_json = OllamaLLM(\n",
        "    model=PLANNER_MODEL,\n",
        "    base_url=\"http://127.0.0.1:11434\",\n",
        "    temperature=0.2,\n",
        "    num_predict=PLANNER_NUM_PREDICT,\n",
        "    format=\"json\",  # ask for pure JSON (we still robustly fallback)\n",
        ")\n",
        "\n",
        "writer_llm  = OllamaLLM(\n",
        "    model=WRITER_MODEL,\n",
        "    base_url=\"http://127.0.0.1:11434\",\n",
        "    temperature=0.8,\n",
        "    num_ctx=4096,\n",
        "    num_predict=WRITER_NUM_PREDICT,\n",
        ")\n",
        "\n",
        "# Outline prompts: JSON and NDJSON with \"avoid\" lists for diversity\n",
        "OUTLINE_JSON_PROMPT = PromptTemplate(\n",
        "    input_variables=[\"topic\",\"count\",\"avoid_titles\",\"avoid_phrases\"],\n",
        "    template=(\n",
        "\"\"\"Generate exactly {count} DIFFERENT chapter seeds for this novel as a JSON ARRAY.\n",
        "Each item is an object: {{\"title\":\"...\", \"description\":\"...\"}}\n",
        "\n",
        "HARD RULES:\n",
        "- Vary SETTING, MODE OF CONFLICT, and REVERSAL TYPE across items.\n",
        "- Avoid any titles in AVOID_TITLES and any phrases in AVOID_PHRASES.\n",
        "- Return JSON ONLY. No commentary.\n",
        "\n",
        "Book idea: {topic}\n",
        "AVOID_TITLES: {avoid_titles}\n",
        "AVOID_PHRASES: {avoid_phrases}\n",
        "\"\"\"\n",
        "    )\n",
        ")\n",
        "\n",
        "OUTLINE_NDJSON_PROMPT = PromptTemplate(\n",
        "    input_variables=[\"topic\",\"count\",\"avoid_titles\",\"avoid_phrases\"],\n",
        "    template=(\n",
        "\"\"\"Generate exactly {count} DIFFERENT chapter seeds as NDJSON (one JSON object per line).\n",
        "Each line: {{\"title\":\"...\", \"description\":\"...\"}}\n",
        "\n",
        "HARD RULES:\n",
        "- Vary SETTING, MODE OF CONFLICT, and REVERSAL TYPE across items.\n",
        "- Avoid any titles in AVOID_TITLES and any phrases in AVOID_PHRASES.\n",
        "- No numbering, no code fences, no commentary.\n",
        "\n",
        "Book idea: {topic}\n",
        "AVOID_TITLES: {avoid_titles}\n",
        "AVOID_PHRASES: {avoid_phrases}\n",
        "\"\"\"\n",
        "    )\n",
        ")\n",
        "\n",
        "# Character prompt (JSON)\n",
        "CHAR_JSON_PROMPT = PromptTemplate(\n",
        "    input_variables=[\"outline\",\"num_chars\"],\n",
        "    template=(\n",
        "\"\"\"Given this chapter outline (JSON list): {outline}\n",
        "Create exactly {num_chars} MAIN CHARACTERS as a JSON ARRAY.\n",
        "Each item: {{\"name\":\"...\",\"role\":\"...\",\"development_arc\":\"...\"}}\n",
        "Return JSON ONLY. No commentary.\"\"\"\n",
        "    )\n",
        ")\n",
        "\n",
        "# Chapter & editing prompts\n",
        "chapter_prompt = PromptTemplate(\n",
        "    input_variables=[\"title\",\"description\",\"idea\"],\n",
        "    template=(\n",
        "\"\"\"Write a ~2200â€“3200 word chapter titled \"{title}\".\n",
        "Seed idea: {idea}\n",
        "Chapter description: \"{description}\"\n",
        "\n",
        "Constraints:\n",
        "- NO meta commentary, NO analysis of your process, NO decision making.\n",
        "- Assume the reader remembers prior chapters; do not re-explain backstory.\n",
        "- Maintain continuity, but introduce at least one fresh obstacle, one vivid sensory beat, and one believable surprise.\n",
        "- Use concrete, precise details; avoid clichÃ©s.\n",
        "- End with a small but real unresolved tension.\n",
        "Return TEXT ONLY.\n",
        "\"\"\"\n",
        "    )\n",
        ")\n",
        "\n",
        "REVISION_PROMPT = PromptTemplate(\n",
        "    input_variables=[\"chapter\",\"title\",\"description\",\"ledger\"],\n",
        "    template=(\n",
        "\"\"\"Revise the chapter to reduce repetition with earlier chapters while improving novelty and tension.\n",
        "Keep the same characters and continuity, but change scene dynamics, setting details, and micro-beats.\n",
        "\n",
        "Rules:\n",
        "- Do NOT re-explain backstory already known.\n",
        "- Add at least one fresh obstacle, one specific sensory detail, and one surprising but plausible turn.\n",
        "- Preserve voice and POV.\n",
        "Return TEXT ONLY.\n",
        "\n",
        "Title: {title}\n",
        "Description: {description}\n",
        "\n",
        "Do-not-repeat ledger (phrases/scenes to avoid): {ledger}\n",
        "\n",
        "Chapter draft:\n",
        "{chapter}\n",
        "\"\"\"\n",
        "    )\n",
        ")\n",
        "\n",
        "EVAL_PROMPT = PromptTemplate(\n",
        "    input_variables=[\"chapter\"],\n",
        "    template=(\n",
        "\"\"\"You are a tough fiction editor. Rate the chapter (1â€“10) on:\n",
        "- pacing\n",
        "- tension\n",
        "- voice\n",
        "- imagery\n",
        "- dialogue\n",
        "- novelty\n",
        "\n",
        "Return STRICT JSON only:\n",
        "{{\"scores\":{{\"pacing\":x,\"tension\":x,\"voice\":x,\"imagery\":x,\"dialogue\":x,\"novelty\":x}},\"one_sentence_note\":\"...\",\"three_micro_edits\":[\"...\",\"...\",\"...\"]}}\n",
        "\n",
        "Chapter:\n",
        "{chapter}\n",
        "\"\"\"\n",
        "    )\n",
        ")\n",
        "\n",
        "PUNCHUP_PROMPT = PromptTemplate(\n",
        "    input_variables=[\"chapter\",\"edits\"],\n",
        "    template=(\n",
        "\"\"\"Apply these micro-edits to strengthen the chapter without changing the plot:\n",
        "- {edits}\n",
        "\n",
        "Rules:\n",
        "- Keep POV, continuity, and length roughly the same (Â±10%).\n",
        "- Add concrete sensory details.\n",
        "- Tighten weak sentences; remove clichÃ©s.\n",
        "Return TEXT ONLY.\n",
        "\n",
        "Chapter:\n",
        "{chapter}\n",
        "\"\"\"\n",
        "    )\n",
        ")\n",
        "\n",
        "# Theme/Motif bible, beats, dialogue tuner, decliche, motif miner, blurb\n",
        "THEME_PROMPT = PromptTemplate(\n",
        "    input_variables=[\"topic\",\"outline\"],\n",
        "    template=(\n",
        "\"\"\"From the seed idea and outline, produce STRICT JSON:\n",
        "{{\n",
        "  \"themes\": [\"...\"],         # 3â€“5 core themes\n",
        "  \"motifs\": [\"...\"],         # 6â€“12 recurring props/images\n",
        "  \"promises\": [\"...\"],       # 3â€“6 promises to the reader\n",
        "  \"logline\": \"...\",          # one sentence\n",
        "  \"genre_signals\": [\"...\"]   # 5â€“8 setting/imagery signals\n",
        "}}\n",
        "Seed idea: {topic}\n",
        "Outline: {outline}\n",
        "\"\"\"\n",
        "    )\n",
        ")\n",
        "\n",
        "BEATS_PROMPT = PromptTemplate(\n",
        "    input_variables=[\"title\",\"description\",\"theme_bible\",\"motif_ledger\"],\n",
        "    template=(\n",
        "\"\"\"Plan a beat sheet for the chapter as STRICT JSON:\n",
        "{{\n",
        "  \"beats\": [\n",
        "    {{\"name\":\"Hook\",\"goal\":\"...\",\"conflict\":\"...\",\"setting\":\"...\",\"emotion\":\"...\"}},\n",
        "    ...\n",
        "  ],\n",
        "  \"dialogue_target_pct\": 0.38,\n",
        "  \"sensory_palette\": [\"sound\",\"smell\"],\n",
        "  \"foreshadow\":\"...\",\n",
        "  \"callback_motif\":\"...\"\n",
        "}}\n",
        "Requirements:\n",
        "- 8â€“12 beats, with a mid-chapter reversal and a cliffhanger/stinger.\n",
        "- Use 1â€“2 motifs from MOTIF_LEDGER and add 1 fresh setting element aligned to GENRE_SIGNALS.\n",
        "\n",
        "TITLE: {title}\n",
        "DESC: {description}\n",
        "THEME_BIBLE: {theme_bible}\n",
        "MOTIF_LEDGER: {motif_ledger}\n",
        "\"\"\"\n",
        "    )\n",
        ")\n",
        "\n",
        "CHAPTER_WITH_BEATS_PROMPT = PromptTemplate(\n",
        "    input_variables=[\"title\",\"description\",\"idea\",\"plan\",\"themes\",\"sensory_palette\",\"dialogue_target\"],\n",
        "    template=(\n",
        "\"\"\"Write a ~2200â€“3200 word chapter titled \"{title}\".\n",
        "\n",
        "Seed idea: {idea}\n",
        "Mini-brief: {description}\n",
        "Plan (beats): {plan}\n",
        "\n",
        "Must do:\n",
        "- OPEN with a punchy 1â€“2 sentence HOOK that raises a concrete question.\n",
        "- Emphasize SENSORY PALETTE: {sensory_palette}\n",
        "- Aim for DIALOGUE DENSITY â‰ˆ {dialogue_target:.2f} (about 30â€“45% lines include dialogue).\n",
        "- Integrate 1 motif or prop from the plan naturally.\n",
        "- Midpoint reversal that reframes stakes.\n",
        "- END with a plausible CLIFFHANGER/STINGER (no meta).\n",
        "\n",
        "Style:\n",
        "- Concrete details, crisp verbs; avoid clichÃ©s.\n",
        "- Maintain POV and continuity; no backstory dumps.\n",
        "\n",
        "Themes to subtly reinforce: {themes}\n",
        "Return TEXT ONLY.\n",
        "\"\"\"\n",
        "    )\n",
        ")\n",
        "\n",
        "DIALOGUE_TUNER_PROMPT = PromptTemplate(\n",
        "    input_variables=[\"chapter\",\"target\"],\n",
        "    template=(\n",
        "\"\"\"Revise the chapter to adjust dialogue density to â‰ˆ {target:.2f} (Â±0.08).\n",
        "Keep plot and beats intact. Do not shorten by more than 10% or lengthen by more than 10%.\n",
        "Return TEXT ONLY.\n",
        "\n",
        "Chapter:\n",
        "{chapter}\n",
        "\"\"\"\n",
        "    )\n",
        ")\n",
        "\n",
        "DECLICHE_PROMPT = PromptTemplate(\n",
        "    input_variables=[\"chapter\"],\n",
        "    template=(\n",
        "\"\"\"Rewrite at sentence-level to remove clichÃ©s and filler.\n",
        "Replace with specific, concrete imagery fitting a near-future techno-thriller vibe.\n",
        "Preserve plot, POV, beats, and length (Â±5%). Return TEXT ONLY.\n",
        "\n",
        "Chapter:\n",
        "{chapter}\n",
        "\"\"\"\n",
        "    )\n",
        ")\n",
        "\n",
        "MOTIF_MINER_PROMPT = PromptTemplate(\n",
        "    input_variables=[\"chapter\"],\n",
        "    template=(\n",
        "\"\"\"Extract 1â€“3 recurring motifs/props/images present in this chapter (short noun phrases).\n",
        "Return STRICT JSON: {{\"motifs\":[\"...\"]}}\n",
        "\n",
        "Chapter:\n",
        "{chapter}\n",
        "\"\"\"\n",
        "    )\n",
        ")\n",
        "\n",
        "BLURB_PROMPT = PromptTemplate(\n",
        "    input_variables=[\"title\",\"logline\",\"themes\",\"promises\"],\n",
        "    template=(\n",
        "\"\"\"Write STRICT JSON:\n",
        "{{\n",
        "  \"blurb\":\"...\",           # 120â€“160 words\n",
        "  \"product_hook\":\"...\",    # 1 sentence\n",
        "  \"snippets\": [\"...\",\"...\",\"...\"]  # â‰¤140 chars each\n",
        "}}\n",
        "Title: {title}\n",
        "Logline: {logline}\n",
        "Themes: {themes}\n",
        "Promises: {promises}\n",
        "\"\"\"\n",
        "    )\n",
        ")\n",
        "\n",
        "# Build chains\n",
        "outline_chain_json_planner  = OUTLINE_JSON_PROMPT   | planner_llm_json   # JSON mode\n",
        "outline_chain_ndjson_plan   = OUTLINE_NDJSON_PROMPT | planner_llm        # NDJSON (planner)\n",
        "outline_chain_ndjson_writer = OUTLINE_NDJSON_PROMPT | writer_llm         # NDJSON (writer)\n",
        "\n",
        "character_chain_json = CHAR_JSON_PROMPT | planner_llm_json\n",
        "\n",
        "chapter_chain     = chapter_prompt               | writer_llm\n",
        "revision_chain    = REVISION_PROMPT              | writer_llm\n",
        "eval_chain        = EVAL_PROMPT                  | planner_llm\n",
        "punchup_chain     = PUNCHUP_PROMPT               | writer_llm\n",
        "\n",
        "theme_chain       = THEME_PROMPT                 | planner_llm\n",
        "beats_chain       = BEATS_PROMPT                 | planner_llm\n",
        "chapter_beats_llm = CHAPTER_WITH_BEATS_PROMPT    | writer_llm\n",
        "dialogue_tuner    = DIALOGUE_TUNER_PROMPT        | writer_llm\n",
        "decliche_chain    = DECLICHE_PROMPT              | writer_llm\n",
        "motif_miner       = MOTIF_MINER_PROMPT           | planner_llm\n",
        "blurb_chain       = BLURB_PROMPT                 | planner_llm\n",
        "\n",
        "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
        "# 3) Utilities: parse, similarity, IO helpers\n",
        "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
        "THINK_RE = re.compile(r\"<think>.*?</think>\\s*\", flags=re.S|re.I)\n",
        "FENCE_RE = re.compile(r\"```(?:json)?|```\", flags=re.I)\n",
        "\n",
        "def strip_think(x: Any) -> str:\n",
        "    s = x[\"text\"] if isinstance(x, dict) and \"text\" in x else str(x)\n",
        "    s = THINK_RE.sub(\"\", s)\n",
        "    s = FENCE_RE.sub(\"\", s)\n",
        "    return s.strip()\n",
        "\n",
        "def parse_json_value(s: str):\n",
        "    \"\"\"Parse last JSON value ({...} or [...]) in a string; return Python obj or None.\"\"\"\n",
        "    s = strip_think(s)\n",
        "    m = re.search(r\"(\\{.*\\}|\\[.*\\])\\s*$\", s, flags=re.S)\n",
        "    if not m: return None\n",
        "    blob = m.group(1)\n",
        "    try:\n",
        "        return json.loads(blob)\n",
        "    except Exception:\n",
        "        fix = blob.replace(\"â€œ\",\"\\\"\").replace(\"â€\",\"\\\"\").replace(\"â€™\",\"'\")\n",
        "        fix = re.sub(r\",\\s*}\", \"}\", fix); fix = re.sub(r\",\\s*]\", \"]\", fix)\n",
        "        try: return json.loads(fix)\n",
        "        except Exception: return None\n",
        "\n",
        "def parse_strict_json(s: str) -> dict:\n",
        "    obj = parse_json_value(s)\n",
        "    return obj if isinstance(obj, dict) else {}\n",
        "\n",
        "# Extract individual JSON objects even if an array is truncated\n",
        "OBJ_RE = re.compile(r\"\\{(?:[^{}]|\\\"[^\\\"\\\\]*(?:\\\\.[^\\\"\\\\]*)*\\\")*\\}\")\n",
        "def extract_json_objects(text: str):\n",
        "    text = strip_think(text)\n",
        "    objs = []\n",
        "    for m in OBJ_RE.finditer(text):\n",
        "        blob = m.group(0)\n",
        "        try:\n",
        "            obj = json.loads(blob)\n",
        "            if isinstance(obj, dict):\n",
        "                objs.append(obj)\n",
        "        except Exception:\n",
        "            try:\n",
        "                fix = blob.replace(\"â€œ\",\"\\\"\").replace(\"â€\",\"\\\"\").replace(\"â€™\",\"'\")\n",
        "                fix = re.sub(r\",\\s*}\", \"}\", fix)\n",
        "                obj = json.loads(fix)\n",
        "                if isinstance(obj, dict):\n",
        "                    objs.append(obj)\n",
        "            except Exception:\n",
        "                pass\n",
        "    return objs\n",
        "\n",
        "def jaccard(a: str, b: str) -> float:\n",
        "    A = set(re.findall(r\"[a-z0-9']+\", (a or \"\").lower()))\n",
        "    B = set(re.findall(r\"[a-z0-9']+\", (b or \"\").lower()))\n",
        "    if not A or not B: return 0.0\n",
        "    return len(A & B) / len(A | B)\n",
        "\n",
        "# Dedup thresholds â€” slightly relaxed to avoid over-filtering on small models\n",
        "def too_similar_relaxed(ch1: Dict[str,str], ch2: Dict[str,str]) -> bool:\n",
        "    t_sim = jaccard(ch1[\"title\"], ch2[\"title\"])\n",
        "    d_sim = jaccard(ch1[\"description\"], ch2[\"description\"])\n",
        "    return (t_sim > 0.80) or (t_sim > 0.55 and d_sim > 0.62)\n",
        "\n",
        "def bigram_overlap(a: str, b: str) -> float:\n",
        "    def bigrams(s):\n",
        "        toks = re.findall(r\"[a-z0-9']+\", (s or \"\").lower())\n",
        "        return set(zip(toks, toks[1:])) if len(toks) > 1 else set()\n",
        "    A, B = bigrams(a), bigrams(b)\n",
        "    denom = len(A | B) if (A or B) else 1\n",
        "    return len(A & B) / denom\n",
        "\n",
        "def top_trigrams(text: str, k: int = 30) -> List[str]:\n",
        "    toks = re.findall(r\"[a-z0-9']+\", (text or \"\").lower())\n",
        "    tris = Counter(zip(toks, toks[1:], toks[2:]))\n",
        "    return [\" \".join(t) for t,_ in tris.most_common(k)]\n",
        "\n",
        "def approx_dialogue_ratio(text: str) -> float:\n",
        "    lines = [ln.strip() for ln in (text or \"\").splitlines() if ln.strip()]\n",
        "    if not lines: return 0.0\n",
        "    dial = sum(1 for ln in lines if re.search(r'[\"â€œâ€]|^â€”', ln))\n",
        "    return dial / max(1, len(lines))\n",
        "\n",
        "def word_count(text: str) -> int:\n",
        "    return len(re.findall(r\"[A-Za-z0-9']+\", text or \"\"))\n",
        "\n",
        "# Checkpoint helpers\n",
        "def _slug(s):\n",
        "    return re.sub(r\"[^a-z0-9]+\", \"-\", s.lower()).strip(\"-\")[:60]\n",
        "\n",
        "def _ck_paths(i, title):\n",
        "    base = f\"{i:03d}-{_slug(title)}\"\n",
        "    p = pathlib.Path(CHECKPOINT_DIR)\n",
        "    return p / (base + \".txt\"), p / (base + \".json\")\n",
        "\n",
        "def save_ckpt(i, title, text, notes):\n",
        "    p_txt, p_meta = _ck_paths(i, title)\n",
        "    p_txt.write_text(text or \"\", encoding=\"utf-8\")\n",
        "    meta = {\"chapter_index\": i, \"title\": title, \"notes\": notes}\n",
        "    p_meta.write_text(json.dumps(meta, ensure_ascii=False, indent=2), encoding=\"utf-8\")\n",
        "\n",
        "def load_ckpt_if_any(i, title):\n",
        "    p_txt, p_meta = _ck_paths(i, title)\n",
        "    if p_txt.exists():\n",
        "        text = p_txt.read_text(encoding=\"utf-8\")\n",
        "        notes = None\n",
        "        if p_meta.exists():\n",
        "            try: notes = json.loads(p_meta.read_text(encoding=\"utf-8\"))\n",
        "            except Exception: notes = None\n",
        "        return text, notes\n",
        "    return None, None\n",
        "\n",
        "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
        "# 4) Booster-grade OUTLINE generator (JSONâ†’NDJSON; plannerâ†’writer; avoid lists)\n",
        "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
        "def clean_outline_items(items):\n",
        "    out = []\n",
        "    for obj in items:\n",
        "        if not isinstance(obj, dict):\n",
        "            continue\n",
        "        title = (obj.get(\"title\") or \"\").strip()\n",
        "        desc  = (obj.get(\"description\") or \"\").strip()\n",
        "        if title and desc:\n",
        "            out.append({\"title\": title, \"description\": desc})\n",
        "    return out\n",
        "\n",
        "def robust_outline_batch(topic: str, ask: int, avoid_titles: List[str], avoid_phrases: List[str]):\n",
        "    payload = {\n",
        "        \"topic\": topic,\n",
        "        \"count\": ask,\n",
        "        \"avoid_titles\": \", \".join(sorted(set(avoid_titles))[:50]),\n",
        "        \"avoid_phrases\": \", \".join(sorted(set(avoid_phrases))[:50]),\n",
        "    }\n",
        "    # (A) Planner JSON\n",
        "    try:\n",
        "        raw = outline_chain_json_planner.invoke(payload)\n",
        "        arr = parse_json_value(raw)\n",
        "        if isinstance(arr, list) and arr:\n",
        "            print(\"   âœ“ planner JSON\")\n",
        "            return clean_outline_items(arr)\n",
        "        objs = extract_json_objects(str(raw))\n",
        "        if objs:\n",
        "            print(\"   âœ“ planner JSON (rescued)\")\n",
        "            return clean_outline_items(objs)\n",
        "    except Exception as e:\n",
        "        print(f\"   Â· planner JSON failed: {e}\")\n",
        "\n",
        "    # (B) Planner NDJSON\n",
        "    try:\n",
        "        raw = outline_chain_ndjson_plan.invoke(payload)\n",
        "        lines = [ln for ln in strip_think(raw).splitlines() if ln.strip()]\n",
        "        objs = []\n",
        "        for ln in lines:\n",
        "            try:\n",
        "                objs.append(json.loads(ln))\n",
        "            except Exception:\n",
        "                fix = ln.replace(\"â€œ\",\"\\\"\").replace(\"â€\",\"\\\"\").replace(\"â€™\",\"'\")\n",
        "                fix = re.sub(r\",\\s*}\", \"}\", fix)\n",
        "                try: objs.append(json.loads(fix))\n",
        "                except Exception: pass\n",
        "        if objs:\n",
        "            print(\"   âœ“ planner NDJSON\")\n",
        "            return clean_outline_items(objs)\n",
        "    except Exception as e:\n",
        "        print(f\"   Â· planner NDJSON failed: {e}\")\n",
        "\n",
        "    # (C) Writer NDJSON\n",
        "    try:\n",
        "        raw = outline_chain_ndjson_writer.invoke(payload)\n",
        "        lines = [ln for ln in strip_think(raw).splitlines() if ln.strip()]\n",
        "        objs = []\n",
        "        for ln in lines:\n",
        "            try:\n",
        "                objs.append(json.loads(ln))\n",
        "            except Exception:\n",
        "                fix = ln.replace(\"â€œ\",\"\\\"\").replace(\"â€\",\"\\\"\").replace(\"â€™\",\"'\")\n",
        "                fix = re.sub(r\",\\s*}\", \"}\", fix)\n",
        "                try: objs.append(json.loads(fix))\n",
        "                except Exception: pass\n",
        "        if objs:\n",
        "            print(\"   âœ“ writer NDJSON\")\n",
        "            return clean_outline_items(objs)\n",
        "    except Exception as e:\n",
        "        print(f\"   Â· writer NDJSON failed: {e}\")\n",
        "\n",
        "    # (D) Writer JSON (on demand) â€” sometimes strong for small asks\n",
        "    try:\n",
        "        outline_chain_json_writer = OUTLINE_JSON_PROMPT | writer_llm\n",
        "        raw = outline_chain_json_writer.invoke(payload)\n",
        "        arr = parse_json_value(raw)\n",
        "        if isinstance(arr, list) and arr:\n",
        "            print(\"   âœ“ writer JSON\")\n",
        "            return clean_outline_items(arr)\n",
        "        objs = extract_json_objects(str(raw))\n",
        "        if objs:\n",
        "            print(\"   âœ“ writer JSON (rescued)\")\n",
        "            return clean_outline_items(objs)\n",
        "    except Exception as e:\n",
        "        print(f\"   Â· writer JSON failed: {e}\")\n",
        "\n",
        "    # (E) Stub fallback to guarantee forward progress\n",
        "    print(\"   âš ï¸ stub fallback\")\n",
        "    TEMPLATES = [\n",
        "        (\"A Cold Start\", \"A data blackout forces Lena to rely on analog sleuthing; a new ally reveals a risky lead.\"),\n",
        "        (\"Flood the Zone\", \"Bots overwhelm a protest; Lena must choose between saving one friend or saving the dataset.\"),\n",
        "        (\"Paper Trail\", \"A mundane invoice uncovers a laundering loop; a quiet break-in turns into a chase.\"),\n",
        "        (\"Mirror Test\", \"An influencer glitches live; the team stages a Turing-style trap with unintended consequences.\"),\n",
        "        (\"Dead Channel\", \"The platform buries a scandal; Lena weaponizes a forgotten API endpoint to surface the truth.\"),\n",
        "        (\"The Honeypot\", \"A romance subplot intersects with an op; trust fractures as a private archive leaks.\"),\n",
        "        (\"Proxy War\", \"A rival startup dangles a deal; double agents swap models and the ground truth shifts.\"),\n",
        "    ]\n",
        "    random.shuffle(TEMPLATES)\n",
        "    return [{\"title\": t, \"description\": d} for t,d in TEMPLATES[:ask]]\n",
        "\n",
        "print(f\"â†’ Generating {NUM_CH}-chapter outline (booster mode) â€¦\")\n",
        "outline, seen_titles = [], set()\n",
        "needed = NUM_CH\n",
        "chunk = 3  # small asks are more reliable on CPU\n",
        "attempts, MAX_ATTEMPTS = 0, 60\n",
        "\n",
        "while len(outline) < needed and attempts < MAX_ATTEMPTS:\n",
        "    attempts += 1\n",
        "    ask = min(chunk, needed - len(outline))\n",
        "    # Build avoid lists from what we already have to promote variety\n",
        "    avoid_titles = list(seen_titles)\n",
        "    recent_phrases = []\n",
        "    for it in outline[-12:]:\n",
        "        recent_phrases.extend(top_trigrams(it.get(\"description\",\"\"), k=6))\n",
        "    batch = robust_outline_batch(SEED_IDEA, ask, avoid_titles, recent_phrases)\n",
        "    added = 0\n",
        "    for ch in batch:\n",
        "        if not ch[\"title\"] or not ch[\"description\"]:\n",
        "            continue\n",
        "        if ch[\"title\"] in seen_titles:\n",
        "            continue\n",
        "        if any(too_similar_relaxed(ch, e) for e in outline):\n",
        "            continue\n",
        "        outline.append(ch)\n",
        "        seen_titles.add(ch[\"title\"])\n",
        "        added += 1\n",
        "        if len(outline) >= needed:\n",
        "            break\n",
        "    print(f\"   â†’ accepted {added}; total now {len(outline)}/{needed}\")\n",
        "    if added == 0:\n",
        "        print(\"   Â· No unique chapters accepted from batch; retryingâ€¦\")\n",
        "\n",
        "print(f\"âœ” Final outline: {len(outline)} chapters\\n\")\n",
        "if len(outline) < needed:\n",
        "    print(\"âš ï¸ Could not reach target; proceeding with what we have.\")\n",
        "\n",
        "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
        "# 5) Character Bible (robust JSON) + Theme/Motif Bible\n",
        "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
        "def robust_characters(outline_list, n_chars):\n",
        "    # Try planner JSON first; then writer JSON; finally stub trio\n",
        "    try:\n",
        "        raw = character_chain_json.invoke({\n",
        "            \"outline\": json.dumps(outline_list, ensure_ascii=False),\n",
        "            \"num_chars\": n_chars\n",
        "        })\n",
        "        arr = parse_json_value(raw)\n",
        "        if isinstance(arr, list) and len(arr) >= min(3, n_chars//2):\n",
        "            return [c for c in arr if isinstance(c, dict)][:n_chars]\n",
        "    except Exception:\n",
        "        pass\n",
        "    try:\n",
        "        char_chain_json_writer = CHAR_JSON_PROMPT | writer_llm\n",
        "        raw = char_chain_json_writer.invoke({\n",
        "            \"outline\": json.dumps(outline_list, ensure_ascii=False),\n",
        "            \"num_chars\": n_chars\n",
        "        })\n",
        "        arr = parse_json_value(raw)\n",
        "        if isinstance(arr, list) and len(arr) >= min(3, n_chars//2):\n",
        "            return [c for c in arr if isinstance(c, dict)][:n_chars]\n",
        "    except Exception:\n",
        "        pass\n",
        "    return [\n",
        "        {\"name\": \"Lena Park\", \"role\": \"Protagonist\",\n",
        "         \"development_arc\": \"From isolated analyst to whistleblower forging unlikely alliances.\"},\n",
        "        {\"name\": \"Mara Voss\", \"role\": \"Rising Influencer\",\n",
        "         \"development_arc\": \"Charismatic star reveals engineered persona; torn between truth and fame.\"},\n",
        "        {\"name\": \"Rex Calder\", \"role\": \"Datum Executive\",\n",
        "         \"development_arc\": \"Mentor becomes antagonist entangled in AI-influence scheme.\"},\n",
        "    ][:n_chars]\n",
        "\n",
        "NUM_CHAR = max(3, min(10, len(outline)//8))\n",
        "print(f\"â†’ Generating {NUM_CHAR} characters (robust)â€¦\")\n",
        "characters = robust_characters(outline, NUM_CHAR)\n",
        "print(f\"âœ” Got {len(characters)} characters\\n\")\n",
        "\n",
        "print(\"â†’ Building theme/motif bibleâ€¦\")\n",
        "theme_raw = theme_chain.invoke({\n",
        "    \"topic\": SEED_IDEA,\n",
        "    \"outline\": json.dumps(outline, ensure_ascii=False)\n",
        "})\n",
        "THEME_BIBLE = parse_strict_json(theme_raw) or {\n",
        "    \"themes\": [],\n",
        "    \"motifs\": [],\n",
        "    \"promises\": [],\n",
        "    \"logline\": \"\",\n",
        "    \"genre_signals\": []\n",
        "}\n",
        "MOTIF_LEDGER = list(THEME_BIBLE.get(\"motifs\", []))  # seed with global motifs\n",
        "print(\"âœ” Theme bible ready.\\n\")\n",
        "\n",
        "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
        "# 6) Chapter Generation with beats + checkpointing + early re-calibration\n",
        "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
        "print(\"â†’ Generating chaptersâ€¦\")\n",
        "chap_texts = [None]*len(outline)\n",
        "editor_notes = [None]*len(outline)\n",
        "BIGRAM_THRESHOLD = 0.22  # repetition strictness\n",
        "\n",
        "def write_one(idx):\n",
        "    meta = outline[idx]\n",
        "    title = meta[\"title\"]\n",
        "\n",
        "    # Resume if checkpoint exists\n",
        "    cached_txt, cached_notes = load_ckpt_if_any(idx, title)\n",
        "    if cached_txt:\n",
        "        return cached_txt, cached_notes\n",
        "\n",
        "    # 1) Plan beats with callbacks to existing motif ledger\n",
        "    plan_raw = beats_chain.invoke({\n",
        "        \"title\": meta[\"title\"],\n",
        "        \"description\": meta[\"description\"],\n",
        "        \"theme_bible\": json.dumps(THEME_BIBLE, ensure_ascii=False),\n",
        "        \"motif_ledger\": json.dumps(MOTIF_LEDGER[-12:], ensure_ascii=False)\n",
        "    })\n",
        "    plan = parse_strict_json(plan_raw)\n",
        "    dialogue_target = float(plan.get(\"dialogue_target_pct\", 0.36))\n",
        "    sensory_palette = plan.get(\"sensory_palette\", [\"sight\",\"sound\"])\n",
        "    plan_json = json.dumps(plan.get(\"beats\", []), ensure_ascii=False)\n",
        "\n",
        "    # 2) Draft with hooks, sensory palette, dialogue target\n",
        "    res = chapter_beats_llm.invoke({\n",
        "        \"title\": meta[\"title\"],\n",
        "        \"description\": meta[\"description\"],\n",
        "        \"idea\": SEED_IDEA,\n",
        "        \"plan\": plan_json,\n",
        "        \"themes\": \", \".join(THEME_BIBLE.get(\"themes\", [])),\n",
        "        \"sensory_palette\": \", \".join(sensory_palette),\n",
        "        \"dialogue_target\": dialogue_target\n",
        "    })\n",
        "    chapter_txt = strip_think(res)\n",
        "\n",
        "    # 3) Repetition guard vs earlier chapters\n",
        "    ledger = []\n",
        "    for j in range(idx):\n",
        "        prev = chap_texts[j]\n",
        "        if not prev: continue\n",
        "        if bigram_overlap(chapter_txt, prev) > BIGRAM_THRESHOLD:\n",
        "            ledger.extend(top_trigrams(prev, k=10))\n",
        "    ledger = list(dict.fromkeys(ledger))[:60]\n",
        "    if ledger:\n",
        "        revised = revision_chain.invoke({\n",
        "            \"chapter\": chapter_txt,\n",
        "            \"title\": meta[\"title\"],\n",
        "            \"description\": meta[\"description\"],\n",
        "            \"ledger\": \"; \".join(ledger)\n",
        "        })\n",
        "        chapter_txt = strip_think(revised)\n",
        "\n",
        "    # 4/5) Auto-evaluation â†’ conditional polish\n",
        "    data = None\n",
        "    try:\n",
        "        report_raw = eval_chain.invoke({\"chapter\": chapter_txt})\n",
        "        report_txt = strip_think(report_raw)\n",
        "        m = re.search(r\"\\{[\\s\\S]*\\}\\s*$\", report_txt)\n",
        "        if m:\n",
        "            data = json.loads(m.group(0))\n",
        "        if data and \"scores\" in data:\n",
        "            scores = data[\"scores\"]\n",
        "            avg_score = sum(float(scores[k]) for k in scores)/len(scores)\n",
        "\n",
        "            # Dialogue tuner if notably off target\n",
        "            dr = approx_dialogue_ratio(chapter_txt)\n",
        "            if abs(dr - dialogue_target) > 0.10:\n",
        "                tuned = dialogue_tuner.invoke({\"chapter\": chapter_txt, \"target\": dialogue_target})\n",
        "                chapter_txt = strip_think(tuned)\n",
        "\n",
        "            # DeclichÃ© only when quality is mid or FAST_MODE off\n",
        "            if (avg_score < 7.6) or (not FAST_MODE):\n",
        "                polished = decliche_chain.invoke({\"chapter\": chapter_txt})\n",
        "                chapter_txt = strip_think(polished)\n",
        "\n",
        "            # Punch-up if still low\n",
        "            if avg_score < 7.4:\n",
        "                edits = \" | \".join(data.get(\"three_micro_edits\", [])) or \\\n",
        "                        \"Sharpen hooks; escalate midpoint; add concrete sensory beats.\"\n",
        "                punched = punchup_chain.invoke({\"chapter\": chapter_txt, \"edits\": edits})\n",
        "                chapter_txt = strip_think(punched)\n",
        "    except Exception:\n",
        "        data = None\n",
        "\n",
        "    # 6) Mine motifs from this chapter â†’ update global ledger\n",
        "    try:\n",
        "        mined_raw = motif_miner.invoke({\"chapter\": chapter_txt})\n",
        "        mined = parse_strict_json(mined_raw)\n",
        "        for m in (mined.get(\"motifs\") or []):\n",
        "            if m not in MOTIF_LEDGER:\n",
        "                MOTIF_LEDGER.append(m)\n",
        "    except Exception:\n",
        "        pass\n",
        "\n",
        "    # Save checkpoint\n",
        "    save_ckpt(idx, title, chapter_txt, data)\n",
        "    return chapter_txt, data\n",
        "\n",
        "# â€”â€” Early calibration: write first few chapters serially, resize outline\n",
        "PREGEN = min(3, len(outline))\n",
        "for i in range(PREGEN):\n",
        "    ch_txt, notes = write_one(i)\n",
        "    chap_texts[i] = ch_txt\n",
        "    editor_notes[i] = notes\n",
        "\n",
        "# Measure actual words/chapter and re-size remaining outline to hit target pages\n",
        "actual_avg = max(500, sum(word_count(chap_texts[i]) for i in range(PREGEN)) // PREGEN)\n",
        "recalc_num_ch = max(12, min(80, (TARGET_WORDS + actual_avg - 1) // actual_avg))\n",
        "\n",
        "if recalc_num_ch != len(outline):\n",
        "    delta = recalc_num_ch - len(outline)\n",
        "    if delta > 0:\n",
        "        ask_more = delta\n",
        "        print(f\"ğŸ” Resizing outline: need +{delta} more chaptersâ€¦\")\n",
        "        extra = robust_outline_batch(SEED_IDEA, ask_more, list(seen_titles), [])\n",
        "        for obj in extra:\n",
        "            cand = {\"title\": (obj.get(\"title\") or \"\").strip(),\n",
        "                    \"description\": (obj.get(\"description\") or \"\").strip()}\n",
        "            if not cand[\"title\"] or not cand[\"description\"]:\n",
        "                continue\n",
        "            if cand[\"title\"] in seen_titles:\n",
        "                continue\n",
        "            if any(too_similar_relaxed(cand, e) for e in outline):\n",
        "                continue\n",
        "            outline.append(cand); seen_titles.add(cand[\"title\"])\n",
        "            chap_texts.append(None); editor_notes.append(None)\n",
        "            if len(outline) >= recalc_num_ch: break\n",
        "        print(f\"   â†’ total {len(outline)} chapters after resize\")\n",
        "    elif delta < 0:\n",
        "        keep = max(PREGEN, recalc_num_ch)\n",
        "        outline = outline[:keep]\n",
        "        chap_texts = chap_texts[:keep]\n",
        "        editor_notes = editor_notes[:keep]\n",
        "        print(f\"âœ‚ï¸  Trimmed outline to {len(outline)} chapters\")\n",
        "\n",
        "# Generate remaining chapters\n",
        "remaining_idxs = [i for i, t in enumerate(chap_texts) if t is None]\n",
        "with ThreadPoolExecutor(max_workers=MAX_WORKERS) as ex:\n",
        "    futures = { ex.submit(write_one, i): i for i in remaining_idxs }\n",
        "    for fut in tqdm(as_completed(futures), total=len(futures), desc=\"Chapters\"):\n",
        "        idx = futures[fut]\n",
        "        try:\n",
        "            ch_txt, notes = fut.result()\n",
        "        except Exception as e:\n",
        "            ch_txt, notes = f\"[Generation failed: {e}]\", None\n",
        "        chap_texts[idx] = ch_txt\n",
        "        editor_notes[idx] = notes\n",
        "\n",
        "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
        "# 7) Pre-save totals â†’ Save to Word + Back-cover copy + Download\n",
        "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
        "total_words = sum(word_count(t or \"\") for t in chap_texts)\n",
        "est_pages  = total_words / WORDS_PER_PAGE\n",
        "suggested_ch = max(12, min(80, round(total_words / CH_TARGET_WORDS)))\n",
        "print(f\"ğŸ§® Total words: {total_words:,}  â†’ est. pages â‰ˆ {est_pages:.0f}\")\n",
        "print(f\"ğŸ”§ If you rerun, suggested chapters for this style â‰ˆ {suggested_ch}\")\n",
        "\n",
        "doc = docx.Document()\n",
        "doc.add_heading(BOOK_TITLE, 0)\n",
        "doc.add_paragraph(f\"Seed idea: {SEED_IDEA}\")\n",
        "doc.add_paragraph(f\"Estimated pages: ~{est_pages:.0f}\")\n",
        "\n",
        "# Character Development Section\n",
        "if characters:\n",
        "    doc.add_page_break()\n",
        "    doc.add_heading(\"Character Development\", level=1)\n",
        "    for c in characters:\n",
        "        name = c.get(\"name\",\"(Unnamed)\")\n",
        "        role = c.get(\"role\",\"\")\n",
        "        arc  = c.get(\"development_arc\",\"\")\n",
        "        doc.add_heading(name, level=2)\n",
        "        if role: doc.add_paragraph(f\"Role: {role}\")\n",
        "        if arc:  doc.add_paragraph(arc)\n",
        "\n",
        "# Chapters\n",
        "for i, (meta, text) in enumerate(zip(outline, chap_texts), start=1):\n",
        "    doc.add_page_break()\n",
        "    doc.add_heading(f\"Chapter {i}: {meta['title']}\", level=1)\n",
        "    doc.add_paragraph(meta['description'], style=\"Intense Quote\")\n",
        "    doc.add_paragraph((text or \"\").strip())\n",
        "\n",
        "# Editorâ€™s Notes (Auto-Eval)\n",
        "doc.add_page_break()\n",
        "doc.add_heading(\"Editorâ€™s Notes (Auto-Eval)\", level=1)\n",
        "for i, (meta, notes) in enumerate(zip(outline, editor_notes), start=1):\n",
        "    doc.add_heading(f\"Chapter {i}: {meta['title']}\", level=2)\n",
        "    if not notes or \"scores\" not in (notes or {}):\n",
        "        doc.add_paragraph(\"No evaluation available.\")\n",
        "        continue\n",
        "    scores = notes[\"scores\"]\n",
        "    one_liner = notes.get(\"one_sentence_note\",\"\")\n",
        "    edits = notes.get(\"three_micro_edits\", [])\n",
        "    try:\n",
        "        avg_score = sum(float(scores[k]) for k in scores)/len(scores)\n",
        "    except Exception:\n",
        "        avg_score = None\n",
        "    doc.add_paragraph(\"Scores: \" + \", \".join(f\"{k}: {scores[k]}\" for k in scores))\n",
        "    if avg_score is not None:\n",
        "        doc.add_paragraph(f\"Average: {avg_score:.2f}\")\n",
        "    if one_liner:\n",
        "        doc.add_paragraph(f\"Note: {one_liner}\")\n",
        "    if edits:\n",
        "        for e in edits:\n",
        "            doc.add_paragraph(f\"â€¢ {e}\")\n",
        "\n",
        "# Back-cover blurb + retailer hook + social snippets\n",
        "blurb_data = {}\n",
        "try:\n",
        "    blurb_raw = blurb_chain.invoke({\n",
        "        \"title\": BOOK_TITLE,\n",
        "        \"logline\": THEME_BIBLE.get(\"logline\",\"\"),\n",
        "        \"themes\": \", \".join(THEME_BIBLE.get(\"themes\", [])),\n",
        "        \"promises\": \", \".join(THEME_BIBLE.get(\"promises\", []))\n",
        "    })\n",
        "    blurb_data = parse_strict_json(blurb_raw) or {}\n",
        "except Exception:\n",
        "    blurb_data = {}\n",
        "\n",
        "doc.add_page_break()\n",
        "doc.add_heading(\"Back-Cover Copy & Retailer Hook\", level=1)\n",
        "if blurb_data.get(\"blurb\"):\n",
        "    doc.add_paragraph(blurb_data[\"blurb\"])\n",
        "if blurb_data.get(\"product_hook\"):\n",
        "    doc.add_paragraph(f\"\\nRetailer Hook: {blurb_data['product_hook']}\")\n",
        "if blurb_data.get(\"snippets\"):\n",
        "    doc.add_heading(\"Short Social Snippets\", level=2)\n",
        "    for s in blurb_data[\"snippets\"]:\n",
        "        doc.add_paragraph(f\"â€¢ {s}\")\n",
        "\n",
        "# Save & download\n",
        "fn = BOOK_TITLE.replace(\" \", \"_\") + \".docx\"\n",
        "doc.save(fn)\n",
        "print(f\"ğŸ“˜ Saved {fn}\")\n",
        "files.download(fn)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "DrUkID0FT3_v",
        "outputId": "1dcee8fc-48dc-4498-8ba2-cc0be4dd61f2"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m0.0/253.0 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[91mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[91mâ•¸\u001b[0m\u001b[90mâ”\u001b[0m \u001b[32m245.8/253.0 kB\u001b[0m \u001b[31m12.0 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m253.0/253.0 kB\u001b[0m \u001b[31m6.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hâœ… Ollama health: 200\n",
            "ğŸ–¥ï¸ GPU: not detected\n",
            "âœ” Using model: llama3.2:3b\n",
            "âœ” Using model: llama3.2:3b\n",
            "ğŸ¯ Target pages: 320  â†’ target words â‰ˆ 88,000\n",
            "ğŸ“ Chapter target: ~3,000 words â†’ initial chapters: 30\n",
            "â†’ Generating 30-chapter outline (booster mode) â€¦\n",
            "   âœ“ planner JSON (rescued)\n",
            "   â†’ accepted 1; total now 1/30\n",
            "   âœ“ planner JSON (rescued)\n",
            "   â†’ accepted 1; total now 2/30\n",
            "   âœ“ planner JSON (rescued)\n",
            "   â†’ accepted 1; total now 3/30\n",
            "   âœ“ planner JSON (rescued)\n",
            "   â†’ accepted 1; total now 4/30\n",
            "   âœ“ planner JSON (rescued)\n",
            "   â†’ accepted 1; total now 5/30\n",
            "   âœ“ planner JSON (rescued)\n",
            "   â†’ accepted 1; total now 6/30\n",
            "   âœ“ planner JSON (rescued)\n",
            "   â†’ accepted 1; total now 7/30\n",
            "   âœ“ planner JSON (rescued)\n",
            "   â†’ accepted 0; total now 7/30\n",
            "   Â· No unique chapters accepted from batch; retryingâ€¦\n",
            "   âœ“ planner JSON (rescued)\n",
            "   â†’ accepted 1; total now 8/30\n",
            "   âœ“ planner JSON (rescued)\n",
            "   â†’ accepted 1; total now 9/30\n",
            "   âœ“ planner JSON (rescued)\n",
            "   â†’ accepted 1; total now 10/30\n",
            "   âœ“ planner JSON (rescued)\n",
            "   â†’ accepted 1; total now 11/30\n",
            "   âœ“ planner JSON (rescued)\n",
            "   â†’ accepted 1; total now 12/30\n",
            "   âœ“ planner JSON (rescued)\n",
            "   â†’ accepted 1; total now 13/30\n",
            "   âœ“ planner JSON (rescued)\n",
            "   â†’ accepted 0; total now 13/30\n",
            "   Â· No unique chapters accepted from batch; retryingâ€¦\n",
            "   âœ“ planner JSON (rescued)\n",
            "   â†’ accepted 0; total now 13/30\n",
            "   Â· No unique chapters accepted from batch; retryingâ€¦\n",
            "   âœ“ planner JSON (rescued)\n",
            "   â†’ accepted 0; total now 13/30\n",
            "   Â· No unique chapters accepted from batch; retryingâ€¦\n",
            "   âœ“ planner JSON (rescued)\n",
            "   â†’ accepted 0; total now 13/30\n",
            "   Â· No unique chapters accepted from batch; retryingâ€¦\n",
            "   âœ“ planner JSON (rescued)\n",
            "   â†’ accepted 1; total now 14/30\n",
            "   âœ“ planner JSON (rescued)\n",
            "   â†’ accepted 1; total now 15/30\n",
            "   âœ“ planner JSON (rescued)\n",
            "   â†’ accepted 1; total now 16/30\n",
            "   âœ“ planner JSON (rescued)\n",
            "   â†’ accepted 0; total now 16/30\n",
            "   Â· No unique chapters accepted from batch; retryingâ€¦\n",
            "   âœ“ planner JSON (rescued)\n",
            "   â†’ accepted 0; total now 16/30\n",
            "   Â· No unique chapters accepted from batch; retryingâ€¦\n",
            "   âœ“ planner JSON (rescued)\n",
            "   â†’ accepted 0; total now 16/30\n",
            "   Â· No unique chapters accepted from batch; retryingâ€¦\n",
            "   âœ“ planner JSON (rescued)\n",
            "   â†’ accepted 0; total now 16/30\n",
            "   Â· No unique chapters accepted from batch; retryingâ€¦\n",
            "   âœ“ planner JSON (rescued)\n",
            "   â†’ accepted 0; total now 16/30\n",
            "   Â· No unique chapters accepted from batch; retryingâ€¦\n",
            "   âœ“ planner JSON (rescued)\n",
            "   â†’ accepted 0; total now 16/30\n",
            "   Â· No unique chapters accepted from batch; retryingâ€¦\n",
            "   âœ“ planner JSON (rescued)\n",
            "   â†’ accepted 0; total now 16/30\n",
            "   Â· No unique chapters accepted from batch; retryingâ€¦\n",
            "   âœ“ planner JSON (rescued)\n",
            "   â†’ accepted 0; total now 16/30\n",
            "   Â· No unique chapters accepted from batch; retryingâ€¦\n",
            "   âœ“ planner JSON (rescued)\n",
            "   â†’ accepted 0; total now 16/30\n",
            "   Â· No unique chapters accepted from batch; retryingâ€¦\n",
            "   âœ“ planner JSON (rescued)\n",
            "   â†’ accepted 0; total now 16/30\n",
            "   Â· No unique chapters accepted from batch; retryingâ€¦\n",
            "   âœ“ planner JSON (rescued)\n",
            "   â†’ accepted 0; total now 16/30\n",
            "   Â· No unique chapters accepted from batch; retryingâ€¦\n",
            "   âœ“ planner JSON (rescued)\n",
            "   â†’ accepted 0; total now 16/30\n",
            "   Â· No unique chapters accepted from batch; retryingâ€¦\n",
            "   âœ“ planner JSON (rescued)\n",
            "   â†’ accepted 0; total now 16/30\n",
            "   Â· No unique chapters accepted from batch; retryingâ€¦\n",
            "   âœ“ planner JSON (rescued)\n",
            "   â†’ accepted 0; total now 16/30\n",
            "   Â· No unique chapters accepted from batch; retryingâ€¦\n",
            "   âœ“ planner JSON (rescued)\n",
            "   â†’ accepted 0; total now 16/30\n",
            "   Â· No unique chapters accepted from batch; retryingâ€¦\n",
            "   âœ“ planner JSON (rescued)\n",
            "   â†’ accepted 1; total now 17/30\n",
            "   âœ“ planner JSON (rescued)\n",
            "   â†’ accepted 0; total now 17/30\n",
            "   Â· No unique chapters accepted from batch; retryingâ€¦\n",
            "   âœ“ planner JSON (rescued)\n",
            "   â†’ accepted 0; total now 17/30\n",
            "   Â· No unique chapters accepted from batch; retryingâ€¦\n",
            "   âœ“ planner JSON (rescued)\n",
            "   â†’ accepted 0; total now 17/30\n",
            "   Â· No unique chapters accepted from batch; retryingâ€¦\n",
            "   âœ“ planner JSON (rescued)\n",
            "   â†’ accepted 0; total now 17/30\n",
            "   Â· No unique chapters accepted from batch; retryingâ€¦\n",
            "   âœ“ planner JSON (rescued)\n",
            "   â†’ accepted 0; total now 17/30\n",
            "   Â· No unique chapters accepted from batch; retryingâ€¦\n",
            "   âœ“ planner JSON (rescued)\n",
            "   â†’ accepted 0; total now 17/30\n",
            "   Â· No unique chapters accepted from batch; retryingâ€¦\n",
            "   âœ“ planner JSON (rescued)\n",
            "   â†’ accepted 0; total now 17/30\n",
            "   Â· No unique chapters accepted from batch; retryingâ€¦\n",
            "   âœ“ planner JSON (rescued)\n",
            "   â†’ accepted 0; total now 17/30\n",
            "   Â· No unique chapters accepted from batch; retryingâ€¦\n",
            "   âœ“ planner JSON (rescued)\n",
            "   â†’ accepted 0; total now 17/30\n",
            "   Â· No unique chapters accepted from batch; retryingâ€¦\n",
            "   âœ“ planner JSON (rescued)\n",
            "   â†’ accepted 1; total now 18/30\n",
            "   âœ“ planner JSON (rescued)\n",
            "   â†’ accepted 0; total now 18/30\n",
            "   Â· No unique chapters accepted from batch; retryingâ€¦\n",
            "   âœ“ planner JSON (rescued)\n",
            "   â†’ accepted 0; total now 18/30\n",
            "   Â· No unique chapters accepted from batch; retryingâ€¦\n",
            "   âœ“ planner JSON (rescued)\n",
            "   â†’ accepted 0; total now 18/30\n",
            "   Â· No unique chapters accepted from batch; retryingâ€¦\n",
            "   âœ“ planner JSON (rescued)\n",
            "   â†’ accepted 0; total now 18/30\n",
            "   Â· No unique chapters accepted from batch; retryingâ€¦\n",
            "   âœ“ planner JSON (rescued)\n",
            "   â†’ accepted 0; total now 18/30\n",
            "   Â· No unique chapters accepted from batch; retryingâ€¦\n",
            "   âœ“ planner JSON (rescued)\n",
            "   â†’ accepted 0; total now 18/30\n",
            "   Â· No unique chapters accepted from batch; retryingâ€¦\n",
            "   âœ“ planner JSON (rescued)\n",
            "   â†’ accepted 0; total now 18/30\n",
            "   Â· No unique chapters accepted from batch; retryingâ€¦\n",
            "   âœ“ planner JSON (rescued)\n",
            "   â†’ accepted 0; total now 18/30\n",
            "   Â· No unique chapters accepted from batch; retryingâ€¦\n",
            "   âœ“ planner JSON (rescued)\n",
            "   â†’ accepted 0; total now 18/30\n",
            "   Â· No unique chapters accepted from batch; retryingâ€¦\n",
            "   âœ“ planner JSON (rescued)\n",
            "   â†’ accepted 0; total now 18/30\n",
            "   Â· No unique chapters accepted from batch; retryingâ€¦\n",
            "   âœ“ planner JSON (rescued)\n",
            "   â†’ accepted 0; total now 18/30\n",
            "   Â· No unique chapters accepted from batch; retryingâ€¦\n",
            "   âœ“ planner JSON (rescued)\n",
            "   â†’ accepted 0; total now 18/30\n",
            "   Â· No unique chapters accepted from batch; retryingâ€¦\n",
            "   âœ“ planner JSON (rescued)\n",
            "   â†’ accepted 0; total now 18/30\n",
            "   Â· No unique chapters accepted from batch; retryingâ€¦\n",
            "âœ” Final outline: 18 chapters\n",
            "\n",
            "âš ï¸ Could not reach target; proceeding with what we have.\n",
            "â†’ Generating 3 characters (robust)â€¦\n",
            "âœ” Got 3 characters\n",
            "\n",
            "â†’ Building theme/motif bibleâ€¦\n",
            "âœ” Theme bible ready.\n",
            "\n",
            "â†’ Generating chaptersâ€¦\n",
            "ğŸ” Resizing outline: need +62 more chaptersâ€¦\n",
            "   âœ“ planner JSON (rescued)\n",
            "   â†’ total 19 chapters after resize\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Chapters: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 16/16 [6:15:53<00:00, 1409.59s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ğŸ§® Total words: 15,899  â†’ est. pages â‰ˆ 58\n",
            "ğŸ”§ If you rerun, suggested chapters for this style â‰ˆ 12\n",
            "ğŸ“˜ Saved Artificial_Influencers_2.docx\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_886e876f-f5b0-4242-aa19-edbbe16f6e45\", \"Artificial_Influencers_2.docx\", 73711)"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "lRU6y2CX_jgc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "njNws9kS_jc7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "dOKTEnvX_jYs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
        "# 0) Colab Setup: install & launch Ollama (+ research agent deps, toggles)\n",
        "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
        "!pip install --quiet langchain-ollama python-docx tqdm duckduckgo-search trafilatura readability-lxml\n",
        "\n",
        "import os, threading, subprocess, time, requests, json, re, shutil, pathlib, sys, random, math\n",
        "from typing import List, Any, Dict, Tuple\n",
        "from concurrent.futures import ThreadPoolExecutor, as_completed\n",
        "from collections import Counter\n",
        "from tqdm import tqdm\n",
        "import docx\n",
        "from google.colab import files\n",
        "\n",
        "# Avoid LangChain provider hijacks\n",
        "for v in [\n",
        "    \"OPENAI_API_KEY\",\n",
        "    \"LITELLM_PROVIDER\", \"LITELLM_MODEL\", \"LITELLM_BASE_URL\",\n",
        "    \"LITELL M_PROVIDER\", \"LITELL M_MODEL\", \"LITELL M_BASE_URL\"\n",
        "]:\n",
        "    os.environ.pop(v, None)\n",
        "\n",
        "# â€”â€” Toggles â€”â€”\n",
        "FAST_MODE = True                   # faster pass with lighter sampling\n",
        "RESEARCH_AGENT_ENABLED = True      # turn on/off the web research step\n",
        "CHECKPOINT_DIR = \"book_ckpt\"       # per-chapter cache\n",
        "os.makedirs(CHECKPOINT_DIR, exist_ok=True)\n",
        "\n",
        "# Conservative Ollama parallelism for Colab\n",
        "os.environ[\"OLLAMA_MAX_LOADED_MODELS\"] = \"1\"\n",
        "os.environ[\"OLLAMA_NUM_PARALLEL\"] = \"1\"\n",
        "\n",
        "# Launch Ollama\n",
        "os.environ[\"OLLAMA_HOST\"]    = \"127.0.0.1:11434\"\n",
        "os.environ[\"OLLAMA_ORIGINS\"] = \"*\"\n",
        "!curl -fsSL https://ollama.com/install.sh -o install.sh\n",
        "!bash install.sh >/dev/null 2>&1 || true\n",
        "\n",
        "def _serve_ollama():\n",
        "    subprocess.Popen([\"ollama\",\"serve\"], stderr=subprocess.DEVNULL, stdout=subprocess.DEVNULL)\n",
        "threading.Thread(target=_serve_ollama, daemon=True).start()\n",
        "time.sleep(8)\n",
        "print(\"âœ… Ollama health:\", requests.get(\"http://127.0.0.1:11434\").status_code)\n",
        "\n",
        "def _has_gpu():\n",
        "    try:\n",
        "        return shutil.which(\"nvidia-smi\") and (subprocess.run([\"nvidia-smi\"], capture_output=True).returncode==0)\n",
        "    except Exception:\n",
        "        return False\n",
        "HAS_GPU = bool(_has_gpu())\n",
        "print(\"ğŸ–¥ï¸ GPU:\", \"available\" if HAS_GPU else \"not detected\")\n",
        "\n",
        "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
        "# 1) Model resolver: pick the first available model from candidates\n",
        "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
        "def pick_first_available(candidates: List[str]) -> str:\n",
        "    for m in candidates:\n",
        "        try:\n",
        "            r = subprocess.run([\"ollama\", \"pull\", m], capture_output=True, text=True)\n",
        "            if r.returncode == 0:\n",
        "                print(f\"âœ” Using model: {m}\")\n",
        "                return m\n",
        "            else:\n",
        "                print(f\"âœ– Pull failed for {m} â†’ {r.stderr.strip() or r.stdout.strip()}\")\n",
        "        except Exception as e:\n",
        "            print(f\"âœ– Error pulling {m}: {e}\")\n",
        "    raise RuntimeError(f\"No candidate models could be pulled: {candidates}\")\n",
        "\n",
        "PLANNER_CANDIDATES = [\"llama3.2:3b\",\"qwen2.5:3b\",\"phi3:3.8b-mini\",\"gemma2:2b\",\"mistral:7b\",\"llama3.1:8b\"]\n",
        "WRITER_FAST_CANDIDATES = [\"llama3.2:3b\",\"qwen2.5:3b\",\"phi3:3.8b-mini\",\"gemma2:2b\",\"mistral:7b\",\"llama3.1:8b\"]\n",
        "WRITER_QUALITY_CANDIDATES = [\"llama3.1:8b\",\"mistral:7b\",\"qwen2.5:7b\"]\n",
        "\n",
        "PLANNER_MODEL = pick_first_available(PLANNER_CANDIDATES)\n",
        "WRITER_MODEL  = pick_first_available(WRITER_FAST_CANDIDATES if FAST_MODE else WRITER_QUALITY_CANDIDATES)\n",
        "\n",
        "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
        "# 2) User targets: auto pages â†’ words â†’ chapters\n",
        "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
        "BOOK_TITLE   = \"What Could Have Been: An Alternative History\"\n",
        "MODE         = \"fiction\"  # or \"nonfiction\"\n",
        "TARGET_PAGES = 320 if MODE == \"fiction\" else 280\n",
        "\n",
        "GENRE_PROFILE = {\n",
        "    \"fiction\":   {\"pages_min\": 280, \"pages_max\": 360, \"chapter_words_typical\": (2400, 3600)},\n",
        "    \"nonfiction\":{\"pages_min\": 220, \"pages_max\": 320, \"chapter_words_typical\": (3000, 4500)}\n",
        "}[MODE]\n",
        "\n",
        "if TARGET_PAGES is None:\n",
        "    TARGET_PAGES = (GENRE_PROFILE[\"pages_min\"] + GENRE_PROFILE[\"pages_max\"]) // 2\n",
        "\n",
        "WORDS_PER_PAGE = 275\n",
        "TARGET_WORDS   = int(TARGET_PAGES * WORDS_PER_PAGE)\n",
        "\n",
        "CH_MIN, CH_MAX = GENRE_PROFILE[\"chapter_words_typical\"]\n",
        "CH_TARGET_WORDS = int((CH_MIN + CH_MAX) / 2)\n",
        "NUM_CH = max(12, min(80, (TARGET_WORDS + CH_TARGET_WORDS - 1) // CH_TARGET_WORDS))\n",
        "\n",
        "SEED_IDEA = (\"Counterfactual: Hillary Clinton wins the 2016 U.S. election. \"\n",
        "             \"Track real 2017â€“2021 events as baseline, then explore plausible divergences \"\n",
        "             \"in domestic policy, foreign affairs, courts, and tech/social media dynamics.\")\n",
        "\n",
        "print(f\"ğŸ¯ Target pages: {TARGET_PAGES}  â†’ target words â‰ˆ {TARGET_WORDS:,}\")\n",
        "print(f\"ğŸ“ Chapter target: ~{CH_TARGET_WORDS:,} words â†’ initial chapters: {NUM_CH}\")\n",
        "\n",
        "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
        "# 3) LLMs & prompts (incl. research-aware chapter prompt)\n",
        "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
        "from langchain_ollama import OllamaLLM\n",
        "from langchain_core.prompts import PromptTemplate\n",
        "\n",
        "PLANNER_NUM_PREDICT = 900 if FAST_MODE else 1400\n",
        "WRITER_NUM_PREDICT  = 1600 if FAST_MODE else 3000\n",
        "MAX_WORKERS = 1 if (FAST_MODE or not HAS_GPU) else 3\n",
        "\n",
        "planner_llm = OllamaLLM(model=PLANNER_MODEL, base_url=\"http://127.0.0.1:11434\",\n",
        "                        temperature=0.25, num_predict=PLANNER_NUM_PREDICT)\n",
        "planner_llm_json = OllamaLLM(model=PLANNER_MODEL, base_url=\"http://127.0.0.1:11434\",\n",
        "                             temperature=0.2, num_predict=PLANNER_NUM_PREDICT, format=\"json\")\n",
        "writer_llm  = OllamaLLM(model=WRITER_MODEL, base_url=\"http://127.0.0.1:11434\",\n",
        "                        temperature=0.8, num_ctx=4096, num_predict=WRITER_NUM_PREDICT)\n",
        "\n",
        "# Outline prompts with diversity/avoid lists\n",
        "OUTLINE_JSON_PROMPT = PromptTemplate(\n",
        "    input_variables=[\"topic\",\"count\",\"avoid_titles\",\"avoid_phrases\"],\n",
        "    template=(\n",
        "\"\"\"Generate exactly {count} DIFFERENT chapter seeds for this novel as a JSON ARRAY.\n",
        "Each item: {{\"title\":\"...\", \"description\":\"...\"}}\n",
        "Rules:\n",
        "- Vary SETTING, MODE OF CONFLICT, and REVERSAL TYPE across items.\n",
        "- Avoid any titles in AVOID_TITLES and any phrases in AVOID_PHRASES.\n",
        "- Return JSON ONLY (no commentary).\n",
        "Book idea: {topic}\n",
        "AVOID_TITLES: {avoid_titles}\n",
        "AVOID_PHRASES: {avoid_phrases}\n",
        "\"\"\"))\n",
        "\n",
        "OUTLINE_NDJSON_PROMPT = PromptTemplate(\n",
        "    input_variables=[\"topic\",\"count\",\"avoid_titles\",\"avoid_phrases\"],\n",
        "    template=(\n",
        "\"\"\"Generate exactly {count} DIFFERENT chapter seeds as NDJSON (one JSON object per line).\n",
        "Each line: {{\"title\":\"...\", \"description\":\"...\"}}\n",
        "Rules:\n",
        "- Vary SETTING, MODE OF CONFLICT, and REVERSAL TYPE across items.\n",
        "- Avoid any titles in AVOID_TITLES and any phrases in AVOID_PHRASES.\n",
        "- No numbering, no code fences, no commentary.\n",
        "Book idea: {topic}\n",
        "AVOID_TITLES: {avoid_titles}\n",
        "AVOID_PHRASES: {avoid_phrases}\n",
        "\"\"\"))\n",
        "\n",
        "CHAR_JSON_PROMPT = PromptTemplate(\n",
        "    input_variables=[\"outline\",\"num_chars\"],\n",
        "    template=(\n",
        "\"\"\"Given this chapter outline (JSON list): {outline}\n",
        "Create exactly {num_chars} MAIN CHARACTERS as a JSON ARRAY.\n",
        "Each item: {{\"name\":\"...\",\"role\":\"...\",\"development_arc\":\"...\"}}\n",
        "Return JSON ONLY.\"\"\"\n",
        "))\n",
        "\n",
        "# Research-aware chapter flow\n",
        "THEME_PROMPT = PromptTemplate(\n",
        "    input_variables=[\"topic\",\"outline\"],\n",
        "    template=(\n",
        "\"\"\"From the seed idea and outline, produce STRICT JSON:\n",
        "{{\n",
        "  \"themes\": [\"...\"], \"motifs\": [\"...\"], \"promises\": [\"...\"],\n",
        "  \"logline\": \"...\", \"genre_signals\": [\"...\"]\n",
        "}}\n",
        "Seed idea: {topic}\n",
        "Outline: {outline}\n",
        "\"\"\"))\n",
        "\n",
        "BEATS_PROMPT = PromptTemplate(\n",
        "    input_variables=[\"title\",\"description\",\"theme_bible\",\"motif_ledger\",\"worldbrief\"],\n",
        "    template=(\n",
        "\"\"\"Plan a beat sheet as STRICT JSON:\n",
        "{{\n",
        "  \"beats\": [\n",
        "    {{\"name\":\"Hook\",\"goal\":\"...\",\"conflict\":\"...\",\"setting\":\"...\",\"emotion\":\"...\"}}, ...\n",
        "  ],\n",
        "  \"dialogue_target_pct\": 0.36,\n",
        "  \"sensory_palette\": [\"sound\",\"smell\"],\n",
        "  \"foreshadow\":\"...\",\n",
        "  \"callback_motif\":\"...\"\n",
        "}}\n",
        "Requirements:\n",
        "- 8â€“12 beats with a midpoint reversal and a stinger.\n",
        "- Weave in WORLD BRIEF lightly (do not info-dump): {worldbrief}\n",
        "TITLE: {title}\n",
        "DESC: {description}\n",
        "THEME_BIBLE: {theme_bible}\n",
        "MOTIF_LEDGER: {motif_ledger}\n",
        "\"\"\"))\n",
        "\n",
        "CHAPTER_WITH_BEATS_PROMPT = PromptTemplate(\n",
        "    input_variables=[\"title\",\"description\",\"idea\",\"plan\",\"themes\",\"sensory_palette\",\"dialogue_target\",\"worldbrief\"],\n",
        "    template=(\n",
        "\"\"\"Write a ~2200â€“3200 word chapter titled \"{title}\".\n",
        "Seed idea: {idea}\n",
        "Mini-brief: {description}\n",
        "Plan (beats): {plan}\n",
        "Context to weave subtly (no info-dumps; show, don't tell): {worldbrief}\n",
        "\n",
        "Must do:\n",
        "- Open with a punchy 1â€“2 sentence hook.\n",
        "- Emphasize SENSORY PALETTE: {sensory_palette}\n",
        "- Aim for DIALOGUE DENSITY â‰ˆ {dialogue_target:.2f}.\n",
        "- Integrate 1 motif/prop from the plan naturally.\n",
        "- Midpoint reversal that reframes stakes.\n",
        "- End with a plausible cliffhanger/stinger.\n",
        "\n",
        "Style: concrete details, crisp verbs; avoid clichÃ©s; maintain POV & continuity.\n",
        "Themes to reinforce: {themes}\n",
        "Return TEXT ONLY.\n",
        "\"\"\"))\n",
        "\n",
        "chapter_prompt = PromptTemplate(\n",
        "    input_variables=[\"title\",\"description\",\"idea\"],\n",
        "    template=(\n",
        "\"\"\"Write a ~2200â€“3200 word chapter titled \"{title}\".\n",
        "Seed idea: {idea}\n",
        "Chapter description: \"{description}\"\n",
        "(If WORLD BRIEF is present in your system prompt, weave it subtly.)\n",
        "Return TEXT ONLY.\n",
        "\"\"\"))\n",
        "\n",
        "REVISION_PROMPT = PromptTemplate(\n",
        "    input_variables=[\"chapter\",\"title\",\"description\",\"ledger\"],\n",
        "    template=(\n",
        "\"\"\"Revise to reduce repetition with earlier chapters while improving novelty and tension.\n",
        "Keep continuity; change micro-beats and setting details.\n",
        "- Add one fresh obstacle, one specific sensory detail, one plausible surprise.\n",
        "Return TEXT ONLY.\n",
        "\n",
        "Title: {title}\n",
        "Description: {description}\n",
        "Do-not-repeat ledger: {ledger}\n",
        "Chapter draft:\n",
        "{chapter}\n",
        "\"\"\"))\n",
        "\n",
        "EVAL_PROMPT = PromptTemplate(\n",
        "    input_variables=[\"chapter\"],\n",
        "    template=(\n",
        "\"\"\"You are a tough fiction editor. Rate the chapter (1â€“10) on:\n",
        "pacing, tension, voice, imagery, dialogue, novelty.\n",
        "Return STRICT JSON only:\n",
        "{{\"scores\":{{\"pacing\":x,\"tension\":x,\"voice\":x,\"imagery\":x,\"dialogue\":x,\"novelty\":x}},\n",
        " \"one_sentence_note\":\"...\", \"three_micro_edits\":[\"...\",\"...\",\"...\"]}}\n",
        "Chapter:\n",
        "{chapter}\n",
        "\"\"\"))\n",
        "\n",
        "PUNCHUP_PROMPT = PromptTemplate(\n",
        "    input_variables=[\"chapter\",\"edits\"],\n",
        "    template=(\n",
        "\"\"\"Apply these micro-edits without changing plot:\n",
        "- {edits}\n",
        "Keep length Â±10%. Add concrete sensory details. Remove clichÃ©s.\n",
        "Return TEXT ONLY.\n",
        "\n",
        "Chapter:\n",
        "{chapter}\n",
        "\"\"\"))\n",
        "\n",
        "DIALOGUE_TUNER_PROMPT = PromptTemplate(\n",
        "    input_variables=[\"chapter\",\"target\"],\n",
        "    template=(\n",
        "\"\"\"Revise chapter to adjust dialogue density to â‰ˆ {target:.2f} (Â±0.08).\n",
        "Keep plot and beats intact. Length change â‰¤10%.\n",
        "Return TEXT ONLY.\n",
        "\n",
        "Chapter:\n",
        "{chapter}\n",
        "\"\"\"))\n",
        "\n",
        "DECLICHE_PROMPT = PromptTemplate(\n",
        "    input_variables=[\"chapter\"],\n",
        "    template=(\n",
        "\"\"\"Line-edit to remove clichÃ©s and filler. Replace with specific, concrete imagery.\n",
        "Preserve plot, POV, beats, and length (Â±5%). Return TEXT ONLY.\n",
        "\n",
        "Chapter:\n",
        "{chapter}\n",
        "\"\"\"))\n",
        "\n",
        "MOTIF_MINER_PROMPT = PromptTemplate(\n",
        "    input_variables=[\"chapter\"],\n",
        "    template=(\n",
        "\"\"\"Extract 1â€“3 recurring motifs/props/images (short noun phrases).\n",
        "Return STRICT JSON: {{\"motifs\":[\"...\"]}}\n",
        "Chapter:\n",
        "{chapter}\n",
        "\"\"\"))\n",
        "\n",
        "BLURB_PROMPT = PromptTemplate(\n",
        "    input_variables=[\"title\",\"logline\",\"themes\",\"promises\"],\n",
        "    template=(\n",
        "\"\"\"Write STRICT JSON:\n",
        "{{\"blurb\":\"(120â€“160 words)\",\"product_hook\":\"(1 sentence)\",\"snippets\":[\"...\",\"...\",\"...\"]}}\n",
        "Title: {title}\n",
        "Logline: {logline}\n",
        "Themes: {themes}\n",
        "Promises: {promises}\n",
        "\"\"\"))\n",
        "\n",
        "# Build chains\n",
        "outline_chain_json_planner  = OUTLINE_JSON_PROMPT   | planner_llm_json\n",
        "outline_chain_ndjson_plan   = OUTLINE_NDJSON_PROMPT | planner_llm\n",
        "outline_chain_ndjson_writer = OUTLINE_NDJSON_PROMPT | writer_llm\n",
        "character_chain_json        = CHAR_JSON_PROMPT      | planner_llm_json\n",
        "theme_chain                 = THEME_PROMPT          | planner_llm\n",
        "beats_chain                 = BEATS_PROMPT          | planner_llm\n",
        "chapter_beats_llm           = CHAPTER_WITH_BEATS_PROMPT | writer_llm\n",
        "chapter_chain               = chapter_prompt        | writer_llm\n",
        "revision_chain              = REVISION_PROMPT       | writer_llm\n",
        "eval_chain                  = EVAL_PROMPT           | planner_llm\n",
        "punchup_chain               = PUNCHUP_PROMPT        | writer_llm\n",
        "dialogue_tuner              = DIALOGUE_TUNER_PROMPT | writer_llm\n",
        "decliche_chain              = DECLICHE_PROMPT       | writer_llm\n",
        "motif_miner                 = MOTIF_MINER_PROMPT    | planner_llm\n",
        "blurb_chain                 = BLURB_PROMPT          | planner_llm\n",
        "\n",
        "# Counterfactual scaffolder (for HRC presidency)\n",
        "COUNTERFACTUAL_PROMPT = PromptTemplate(\n",
        "    input_variables=[\"history_brief\",\"premise\"],\n",
        "    template=(\n",
        "\"\"\"Based on this real history brief:\\n{history_brief}\\n\\n\n",
        "Propose 10 plausible DIVERGENCE POINTS if Hillary Clinton had won in 2016.\n",
        "For each: {{ \"title\": \"...\", \"what_changes\": \"...\", \"downstream_ripples\": \"...\", \"conflicts\": [\"...\",\"...\"] }}\n",
        "Return a STRICT JSON array of 10 items only.\n",
        "Premise: {premise}\n",
        "\"\"\"))\n",
        "counterfactual_chain = COUNTERFACTUAL_PROMPT | planner_llm_json\n",
        "\n",
        "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
        "# 4) Utilities: parsing, similarity, checkpoints, etc.\n",
        "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
        "THINK_RE = re.compile(r\"<think>.*?</think>\\s*\", flags=re.S|re.I)\n",
        "FENCE_RE = re.compile(r\"```(?:json)?|```\", flags=re.I)\n",
        "\n",
        "def strip_think(x: Any) -> str:\n",
        "    s = x[\"text\"] if isinstance(x, dict) and \"text\" in x else str(x)\n",
        "    s = THINK_RE.sub(\"\", s); s = FENCE_RE.sub(\"\", s)\n",
        "    return s.strip()\n",
        "\n",
        "def parse_json_value(s: str):\n",
        "    s = strip_think(s)\n",
        "    m = re.search(r\"(\\{.*\\}|\\[.*\\])\\s*$\", s, flags=re.S)\n",
        "    if not m: return None\n",
        "    blob = m.group(1)\n",
        "    try:\n",
        "        return json.loads(blob)\n",
        "    except Exception:\n",
        "        fix = blob.replace(\"â€œ\",\"\\\"\").replace(\"â€\",\"\\\"\").replace(\"â€™\",\"'\")\n",
        "        fix = re.sub(r\",\\s*}\", \"}\", fix); fix = re.sub(r\",\\s*]\", \"]\", fix)\n",
        "        try: return json.loads(fix)\n",
        "        except Exception: return None\n",
        "\n",
        "def parse_strict_json(s: str) -> dict:\n",
        "    obj = parse_json_value(s)\n",
        "    return obj if isinstance(obj, dict) else {}\n",
        "\n",
        "OBJ_RE = re.compile(r\"\\{(?:[^{}]|\\\"[^\\\"\\\\]*(?:\\\\.[^\\\"\\\\]*)*\\\")*\\}\")\n",
        "def extract_json_objects(text: str):\n",
        "    text = strip_think(text); objs = []\n",
        "    for m in OBJ_RE.finditer(text):\n",
        "        blob = m.group(0)\n",
        "        try:\n",
        "            obj = json.loads(blob)\n",
        "            if isinstance(obj, dict): objs.append(obj)\n",
        "        except Exception:\n",
        "            try:\n",
        "                fix = blob.replace(\"â€œ\",\"\\\"\").replace(\"â€\",\"\\\"\").replace(\"â€™\",\"'\")\n",
        "                fix = re.sub(r\",\\s*}\", \"}\", fix)\n",
        "                obj = json.loads(fix)\n",
        "                if isinstance(obj, dict): objs.append(obj)\n",
        "            except Exception: pass\n",
        "    return objs\n",
        "\n",
        "def jaccard(a: str, b: str) -> float:\n",
        "    A = set(re.findall(r\"[a-z0-9']+\", (a or \"\").lower()))\n",
        "    B = set(re.findall(r\"[a-z0-9']+\", (b or \"\").lower()))\n",
        "    if not A or not B: return 0.0\n",
        "    return len(A & B) / len(A | B)\n",
        "\n",
        "def too_similar_relaxed(ch1: Dict[str,str], ch2: Dict[str,str]) -> bool:\n",
        "    t_sim = jaccard(ch1[\"title\"], ch2[\"title\"])\n",
        "    d_sim = jaccard(ch1[\"description\"], ch2[\"description\"])\n",
        "    return (t_sim > 0.80) or (t_sim > 0.55 and d_sim > 0.62)\n",
        "\n",
        "def bigram_overlap(a: str, b: str) -> float:\n",
        "    def bigrams(s):\n",
        "        toks = re.findall(r\"[a-z0-9']+\", (s or \"\").lower())\n",
        "        return set(zip(toks, toks[1:])) if len(toks) > 1 else set()\n",
        "    A, B = bigrams(a), bigrams(b)\n",
        "    denom = len(A | B) if (A or B) else 1\n",
        "    return len(A & B) / denom\n",
        "\n",
        "def top_trigrams(text: str, k: int = 30) -> List[str]:\n",
        "    toks = re.findall(r\"[a-z0-9']+\", (text or \"\").lower())\n",
        "    tris = Counter(zip(toks, toks[1:], toks[2:]))\n",
        "    return [\" \".join(t) for t,_ in tris.most_common(k)]\n",
        "\n",
        "def approx_dialogue_ratio(text: str) -> float:\n",
        "    lines = [ln.strip() for ln in (text or \"\").splitlines() if ln.strip()]\n",
        "    if not lines: return 0.0\n",
        "    dial = sum(1 for ln in lines if re.search(r'[\"â€œâ€]|^â€”', ln))\n",
        "    return dial / max(1, len(lines))\n",
        "\n",
        "def word_count(text: str) -> int:\n",
        "    return len(re.findall(r\"[A-Za-z0-9']+\", text or \"\"))\n",
        "\n",
        "def _slug(s):\n",
        "    return re.sub(r\"[^a-z0-9]+\", \"-\", s.lower()).strip(\"-\")[:60]\n",
        "\n",
        "def _ck_paths(i, title):\n",
        "    base = f\"{i:03d}-{_slug(title)}\"\n",
        "    p = pathlib.Path(CHECKPOINT_DIR)\n",
        "    return p / (base + \".txt\"), p / (base + \".json\")\n",
        "\n",
        "def save_ckpt(i, title, text, notes):\n",
        "    p_txt, p_meta = _ck_paths(i, title)\n",
        "    p_txt.write_text(text or \"\", encoding=\"utf-8\")\n",
        "    meta = {\"chapter_index\": i, \"title\": title, \"notes\": notes}\n",
        "    p_meta.write_text(json.dumps(meta, ensure_ascii=False, indent=2), encoding=\"utf-8\")\n",
        "\n",
        "def load_ckpt_if_any(i, title):\n",
        "    p_txt, p_meta = _ck_paths(i, title)\n",
        "    if p_txt.exists():\n",
        "        text = p_txt.read_text(encoding=\"utf-8\")\n",
        "        notes = None\n",
        "        if p_meta.exists():\n",
        "            try: notes = json.loads(p_meta.read_text(encoding=\"utf-8\"))\n",
        "            except Exception: notes = None\n",
        "        return text, notes\n",
        "    return None, None\n",
        "\n",
        "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
        "# 5) Research Agent: duckduckgo + trafilatura â†’ History Brief JSON/MD\n",
        "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
        "from duckduckgo_search import DDGS\n",
        "import trafilatura\n",
        "\n",
        "def ddg_text(q: str, max_results=6):\n",
        "    with DDGS() as ddgs:\n",
        "        return list(ddgs.text(q, max_results=max_results, region=\"us-en\", safesearch=\"moderate\"))\n",
        "\n",
        "def ddg_news(q: str, max_results=6):\n",
        "    with DDGS() as ddgs:\n",
        "        return list(ddgs.news(q, max_results=max_results, region=\"us-en\", safesearch=\"moderate\"))\n",
        "\n",
        "def fetch_clean(url: str, timeout=20_000) -> str:\n",
        "    try:\n",
        "        downloaded = trafilatura.fetch_url(url, timeout=timeout)\n",
        "        if not downloaded: return \"\"\n",
        "        text = trafilatura.extract(downloaded, include_comments=False, include_tables=False, no_fallback=False)\n",
        "        return text or \"\"\n",
        "    except Exception:\n",
        "        return \"\"\n",
        "\n",
        "def research_pack(topic: str, seed_queries: List[str], per_query=5) -> Dict[str, Any]:\n",
        "    print(\"ğŸ” Research agent: collecting sourcesâ€¦\")\n",
        "    hits = []\n",
        "    for q in seed_queries:\n",
        "        try:\n",
        "            hits.extend(ddg_text(q, max_results=per_query))\n",
        "        except Exception:\n",
        "            continue\n",
        "    # Deduplicate by URL\n",
        "    seen = set(); hits2 = []\n",
        "    for h in hits:\n",
        "        url = h.get(\"href\") or h.get(\"url\")\n",
        "        if not url or url in seen: continue\n",
        "        seen.add(url); hits2.append({\"title\": h.get(\"title\",\"\"), \"url\": url})\n",
        "\n",
        "    docs = []\n",
        "    for h in tqdm(hits2[:25], desc=\"Fetching\"):\n",
        "        txt = fetch_clean(h[\"url\"])\n",
        "        if not txt: continue\n",
        "        docs.append({\"title\": h[\"title\"], \"url\": h[\"url\"], \"text\": txt[:120000]})\n",
        "\n",
        "    if not docs:\n",
        "        return {\"topic\": topic, \"facts\": [], \"timeline\": [], \"citations\": [], \"summary\": \"\"}\n",
        "\n",
        "    # Summarize with the planner (JSON)\n",
        "    SUMM_PROMPT = PromptTemplate(\n",
        "        input_variables=[\"topic\",\"docs\"],\n",
        "        template=(\n",
        "\"\"\"You are an impartial researcher. From these sources, produce STRICT JSON:\n",
        "{{\n",
        " \"facts\": [\"...\"],                       # 12â€“18 atomic, dated facts\n",
        " \"timeline\": [{{\"date\":\"YYYY-MM\",\"event\":\"...\",\"why_it_matters\":\"...\"}}, ...],  # 10â€“14 items\n",
        " \"policy_buckets\": {{\n",
        "   \"economy_tax\":\"...\", \"immigration\":\"...\", \"trade\":\"...\", \"foreign_policy\":\"...\", \"covid\":\"...\", \"justice_impeachments\":\"...\"\n",
        " }},\n",
        " \"summary\": \"(200â€“280 words, neutral)\",\n",
        " \"citations\": [{{\"title\":\"...\",\"url\":\"...\"}}, ...]  # 10â€“16 items\n",
        "}}\n",
        "Topic: {topic}\n",
        "Sources (title + excerpts): {docs}\n",
        "\"\"\"))\n",
        "    chain = SUMM_PROMPT | planner_llm_json\n",
        "    # compact sources text\n",
        "    doc_blurbs = [{\"title\": d[\"title\"], \"url\": d[\"url\"], \"snippet\": (d[\"text\"][:1000] + (\"â€¦\" if len(d[\"text\"])>1000 else \"\"))} for d in docs[:14]]\n",
        "    raw = chain.invoke({\"topic\": topic, \"docs\": json.dumps(doc_blurbs, ensure_ascii=False)})\n",
        "    data = parse_json_value(raw) or {}\n",
        "    data.setdefault(\"citations\", [])\n",
        "    # add any missing citations\n",
        "    for d in doc_blurbs:\n",
        "        if not any(c.get(\"url\")==d[\"url\"] for c in data[\"citations\"]):\n",
        "            data[\"citations\"].append({\"title\": d[\"title\"], \"url\": d[\"url\"]})\n",
        "    return data\n",
        "\n",
        "def brief_to_md(brief: Dict[str,Any]) -> str:\n",
        "    lines = [f\"# Research Brief: {brief.get('topic','')}\", \"\"]\n",
        "    if brief.get(\"summary\"):\n",
        "        lines += [\"## Summary\", brief[\"summary\"], \"\"]\n",
        "    if brief.get(\"timeline\"):\n",
        "        lines += [\"## Timeline\"]\n",
        "        for t in brief[\"timeline\"]:\n",
        "            lines.append(f\"- **{t.get('date','')}** â€” {t.get('event','')} â€” _{t.get('why_it_matters','')}_\")\n",
        "        lines.append(\"\")\n",
        "    if brief.get(\"policy_buckets\"):\n",
        "        lines += [\"## Policy Buckets\"]\n",
        "        for k,v in brief[\"policy_buckets\"].items():\n",
        "            lines.append(f\"- **{k}**: {v}\")\n",
        "        lines.append(\"\")\n",
        "    if brief.get(\"facts\"):\n",
        "        lines += [\"## Facts\"]\n",
        "        for f in brief[\"facts\"][:20]:\n",
        "            lines.append(f\"- {f}\")\n",
        "        lines.append(\"\")\n",
        "    if brief.get(\"citations\"):\n",
        "        lines += [\"## Sources\"]\n",
        "        for c in brief[\"citations\"][:20]:\n",
        "            lines.append(f\"- [{c.get('title','source')}]({c.get('url','')})\")\n",
        "    return \"\\n\".join(lines)\n",
        "\n",
        "# Default research queries for 2017â€“2021 baseline\n",
        "DEFAULT_TRUMP_QUERIES = [\n",
        "    \"Presidency of Donald Trump 2017 2021 summary\",\n",
        "    \"Tax Cuts and Jobs Act 2017 summary site:wikipedia.org\",\n",
        "    \"Executive Order 13769 travel ban summary\",\n",
        "    \"USMCA enters into force July 1 2020 site:ustr.gov\",\n",
        "    \"First impeachment of Donald Trump 2019 summary\",\n",
        "    \"Second impeachment of Donald Trump 2021 summary\",\n",
        "    \"COVID-19 response CARES Act March 2020 CRS summary site:crsreports.congress.gov\",\n",
        "    \"Operation Warp Speed overview site:gao.gov\"\n",
        "]\n",
        "\n",
        "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
        "# 6) Booster-grade OUTLINE generator (JSONâ†’NDJSON; plannerâ†’writer; avoid lists)\n",
        "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
        "def clean_outline_items(items):\n",
        "    out = []\n",
        "    for obj in items:\n",
        "        if not isinstance(obj, dict): continue\n",
        "        title = (obj.get(\"title\") or \"\").strip()\n",
        "        desc  = (obj.get(\"description\") or \"\").strip()\n",
        "        if title and desc: out.append({\"title\": title, \"description\": desc})\n",
        "    return out\n",
        "\n",
        "def robust_outline_batch(topic: str, ask: int, avoid_titles: List[str], avoid_phrases: List[str]):\n",
        "    payload = {\n",
        "        \"topic\": topic,\n",
        "        \"count\": ask,\n",
        "        \"avoid_titles\": \", \".join(sorted(set(avoid_titles))[:50]),\n",
        "        \"avoid_phrases\": \", \".join(sorted(set(avoid_phrases))[:50]),\n",
        "    }\n",
        "    # Planner JSON\n",
        "    try:\n",
        "        raw = outline_chain_json_planner.invoke(payload)\n",
        "        arr = parse_json_value(raw)\n",
        "        if isinstance(arr, list) and arr:\n",
        "            print(\"   âœ“ planner JSON\")\n",
        "            return clean_outline_items(arr)\n",
        "        objs = extract_json_objects(str(raw))\n",
        "        if objs:\n",
        "            print(\"   âœ“ planner JSON (rescued)\")\n",
        "            return clean_outline_items(objs)\n",
        "    except Exception as e:\n",
        "        print(f\"   Â· planner JSON failed: {e}\")\n",
        "    # Planner NDJSON\n",
        "    try:\n",
        "        raw = outline_chain_ndjson_plan.invoke(payload)\n",
        "        lines = [ln for ln in strip_think(raw).splitlines() if ln.strip()]\n",
        "        objs = []\n",
        "        for ln in lines:\n",
        "            try: objs.append(json.loads(ln))\n",
        "            except Exception:\n",
        "                fix = ln.replace(\"â€œ\",\"\\\"\").replace(\"â€\",\"\\\"\").replace(\"â€™\",\"'\")\n",
        "                fix = re.sub(r\",\\s*}\", \"}\", fix)\n",
        "                try: objs.append(json.loads(fix))\n",
        "                except Exception: pass\n",
        "        if objs:\n",
        "            print(\"   âœ“ planner NDJSON\")\n",
        "            return clean_outline_items(objs)\n",
        "    except Exception as e:\n",
        "        print(f\"   Â· planner NDJSON failed: {e}\")\n",
        "    # Writer NDJSON\n",
        "    try:\n",
        "        raw = outline_chain_ndjson_writer.invoke(payload)\n",
        "        lines = [ln for ln in strip_think(raw).splitlines() if ln.strip()]\n",
        "        objs = []\n",
        "        for ln in lines:\n",
        "            try: objs.append(json.loads(ln))\n",
        "            except Exception:\n",
        "                fix = ln.replace(\"â€œ\",\"\\\"\").replace(\"â€\",\"\\\"\").replace(\"â€™\",\"'\")\n",
        "                fix = re.sub(r\",\\s*}\", \"}\", fix)\n",
        "                try: objs.append(json.loads(fix))\n",
        "                except Exception: pass\n",
        "        if objs:\n",
        "            print(\"   âœ“ writer NDJSON\")\n",
        "            return clean_outline_items(objs)\n",
        "    except Exception as e:\n",
        "        print(f\"   Â· writer NDJSON failed: {e}\")\n",
        "    # Writer JSON last\n",
        "    try:\n",
        "        raw = (OUTLINE_JSON_PROMPT | writer_llm).invoke(payload)\n",
        "        arr = parse_json_value(raw)\n",
        "        if isinstance(arr, list) and arr:\n",
        "            print(\"   âœ“ writer JSON\")\n",
        "            return clean_outline_items(arr)\n",
        "        objs = extract_json_objects(str(raw))\n",
        "        if objs:\n",
        "            print(\"   âœ“ writer JSON (rescued)\")\n",
        "            return clean_outline_items(objs)\n",
        "    except Exception as e:\n",
        "        print(f\"   Â· writer JSON failed: {e}\")\n",
        "    # Stub fallback\n",
        "    print(\"   âš ï¸ stub fallback\")\n",
        "    TEMPLATES = [\n",
        "        (\"First 100 Days, Rewired\", \"A new administration rewrites norms; a misread memo sets up the seasonâ€™s first conflict.\"),\n",
        "        (\"The Unseen Docket\", \"A Supreme Court vacancy collides with backchannel promises and an ethics snag.\"),\n",
        "        (\"Trade Winds\", \"Tariffs, treaties, and a leak force an unlikely coalition to formâ€”or fracture.\"),\n",
        "        (\"Outbreak Narratives\", \"A public-health rehearsal becomes real; data, politics, and trust fall out of sync.\"),\n",
        "        (\"Backchannel Summit\", \"A surprise foreign breakthrough carries a personal cost that ricochets at home.\"),\n",
        "        (\"Platform Immunities\", \"A tech-policy skirmish pulls private lives into the open, with legal fallout.\"),\n",
        "        (\"Counting Rooms\", \"An election-year rule change triggers a chain of unintended consequences.\")\n",
        "    ]\n",
        "    random.shuffle(TEMPLATES)\n",
        "    return [{\"title\": t, \"description\": d} for t,d in TEMPLATES[:ask]]\n",
        "\n",
        "print(f\"â†’ Generating {NUM_CH}-chapter outline (booster mode) â€¦\")\n",
        "outline, seen_titles = [], set()\n",
        "needed = NUM_CH\n",
        "chunk = 3\n",
        "attempts, MAX_ATTEMPTS = 0, 60\n",
        "\n",
        "while len(outline) < needed and attempts < MAX_ATTEMPTS:\n",
        "    attempts += 1\n",
        "    ask = min(chunk, needed - len(outline))\n",
        "    avoid_titles = list(seen_titles)\n",
        "    recent_phrases = []\n",
        "    for it in outline[-12:]:\n",
        "        recent_phrases.extend(top_trigrams(it.get(\"description\",\"\"), k=6))\n",
        "    batch = robust_outline_batch(SEED_IDEA, ask, avoid_titles, recent_phrases)\n",
        "    added = 0\n",
        "    for ch in batch:\n",
        "        if not ch[\"title\"] or not ch[\"description\"]: continue\n",
        "        if ch[\"title\"] in seen_titles: continue\n",
        "        if any(too_similar_relaxed(ch, e) for e in outline): continue\n",
        "        outline.append(ch); seen_titles.add(ch[\"title\"]); added += 1\n",
        "        if len(outline) >= needed: break\n",
        "    print(f\"   â†’ accepted {added}; total now {len(outline)}/{needed}\")\n",
        "    if added == 0:\n",
        "        print(\"   Â· No unique chapters accepted from batch; retryingâ€¦\")\n",
        "\n",
        "print(f\"âœ” Final outline: {len(outline)} chapters\\n\")\n",
        "if len(outline) < needed:\n",
        "    print(\"âš ï¸ Could not reach target; proceeding with what we have.\")\n",
        "\n",
        "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
        "# 7) Characters + Theme/Motif Bible\n",
        "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
        "def robust_characters(outline_list, n_chars):\n",
        "    try:\n",
        "        raw = character_chain_json.invoke({\"outline\": json.dumps(outline_list, ensure_ascii=False),\n",
        "                                           \"num_chars\": n_chars})\n",
        "        arr = parse_json_value(raw)\n",
        "        if isinstance(arr, list) and len(arr) >= min(3, n_chars//2):\n",
        "            return [c for c in arr if isinstance(c, dict)][:n_chars]\n",
        "    except Exception: pass\n",
        "    try:\n",
        "        raw = (CHAR_JSON_PROMPT | writer_llm).invoke({\"outline\": json.dumps(outline_list, ensure_ascii=False),\n",
        "                                                      \"num_chars\": n_chars})\n",
        "        arr = parse_json_value(raw)\n",
        "        if isinstance(arr, list) and len(arr) >= min(3, n_chars//2):\n",
        "            return [c for c in arr if isinstance(c, dict)][:n_chars]\n",
        "    except Exception: pass\n",
        "    return [\n",
        "        {\"name\":\"Alex Vega\",\"role\":\"Chief of Staff\",\"development_arc\":\"From risk-averse gatekeeper to bold coalition-builder.\"},\n",
        "        {\"name\":\"Ruth Delgado\",\"role\":\"Solicitor General\",\"development_arc\":\"Learns to balance principle with political reality.\"},\n",
        "        {\"name\":\"Jonah Price\",\"role\":\"Data Journalist\",\"development_arc\":\"Truth-telling collides with personal loyalties.\"},\n",
        "    ][:n_chars]\n",
        "\n",
        "NUM_CHAR = max(3, min(10, len(outline)//8))\n",
        "print(f\"â†’ Generating {NUM_CHAR} charactersâ€¦\")\n",
        "characters = robust_characters(outline, NUM_CHAR)\n",
        "print(f\"âœ” Got {len(characters)} characters\\n\")\n",
        "\n",
        "print(\"â†’ Building theme/motif bibleâ€¦\")\n",
        "THEME_BIBLE = parse_strict_json(theme_chain.invoke({\n",
        "    \"topic\": SEED_IDEA,\n",
        "    \"outline\": json.dumps(outline, ensure_ascii=False)\n",
        "})) or {\"themes\":[],\"motifs\":[],\"promises\":[],\"logline\":\"\",\"genre_signals\":[]}\n",
        "MOTIF_LEDGER = list(THEME_BIBLE.get(\"motifs\", []))\n",
        "print(\"âœ” Theme bible ready.\\n\")\n",
        "\n",
        "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
        "# 8) Run Research Agent (if enabled) â†’ History Brief + Counterfactual seeds\n",
        "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
        "WORLD_BRIEF = \"\"\n",
        "COUNTERFACTUAL_POINTS = []\n",
        "if RESEARCH_AGENT_ENABLED:\n",
        "    brief = research_pack(\n",
        "        topic=\"U.S. Presidency 2017â€“2021 baseline for counterfactual (HRC wins 2016).\",\n",
        "        seed_queries=DEFAULT_TRUMP_QUERIES, per_query=5\n",
        "    )\n",
        "    # Save brief\n",
        "    pathlib.Path(\"research\").mkdir(exist_ok=True)\n",
        "    with open(\"research/history_brief.json\",\"w\",encoding=\"utf-8\") as f:\n",
        "        json.dump(brief, f, ensure_ascii=False, indent=2)\n",
        "    md = brief_to_md(brief)\n",
        "    pathlib.Path(\"research/history_brief.md\").write_text(md, encoding=\"utf-8\")\n",
        "    print(\"ğŸ§¾ Saved research/history_brief.{json,md}\")\n",
        "\n",
        "    # Compact bullets for prompts\n",
        "    bullets = []\n",
        "    for t in (brief.get(\"timeline\") or [])[:10]:\n",
        "        bullets.append(f\"{t.get('date','')}: {t.get('event','')}\")\n",
        "    if not bullets and brief.get(\"facts\"):\n",
        "        bullets = (brief[\"facts\"])[:10]\n",
        "    WORLD_BRIEF = \" | \".join(bullets)[:1200]\n",
        "\n",
        "    # Counterfactual divergence points\n",
        "    cf_raw = counterfactual_chain.invoke({\n",
        "        \"history_brief\": md[:6000],\n",
        "        \"premise\": \"Hillary Clinton wins 2016; explore plausible policy and geopolitical divergences 2017â€“2021.\"\n",
        "    })\n",
        "    COUNTERFACTUAL_POINTS = parse_json_value(cf_raw) or []\n",
        "else:\n",
        "    print(\"â„¹ï¸ Research agent disabled; continuing without WORLD_BRIEF.\")\n",
        "\n",
        "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
        "# 9) Chapter Generation (beats â†’ draft â†’ eval/polish) + checkpointing\n",
        "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
        "print(\"â†’ Generating chaptersâ€¦\")\n",
        "chap_texts = [None]*len(outline)\n",
        "editor_notes = [None]*len(outline)\n",
        "BIGRAM_THRESHOLD = 0.22\n",
        "\n",
        "def write_one(idx):\n",
        "    meta = outline[idx]\n",
        "    title = meta[\"title\"]\n",
        "\n",
        "    # Resume if cached\n",
        "    cached_txt, cached_notes = load_ckpt_if_any(idx, title)\n",
        "    if cached_txt:\n",
        "        return cached_txt, cached_notes\n",
        "\n",
        "    # Plan beats (with world brief if available)\n",
        "    plan = parse_strict_json(beats_chain.invoke({\n",
        "        \"title\": meta[\"title\"],\n",
        "        \"description\": meta[\"description\"],\n",
        "        \"theme_bible\": json.dumps(THEME_BIBLE, ensure_ascii=False),\n",
        "        \"motif_ledger\": json.dumps(MOTIF_LEDGER[-12:], ensure_ascii=False),\n",
        "        \"worldbrief\": WORLD_BRIEF or \"(none)\"\n",
        "    })) or {}\n",
        "    dialogue_target = float(plan.get(\"dialogue_target_pct\", 0.36))\n",
        "    sensory_palette = plan.get(\"sensory_palette\", [\"sight\",\"sound\"])\n",
        "    plan_json = json.dumps(plan.get(\"beats\", []), ensure_ascii=False)\n",
        "\n",
        "    # Draft\n",
        "    res = chapter_beats_llm.invoke({\n",
        "        \"title\": meta[\"title\"],\n",
        "        \"description\": meta[\"description\"],\n",
        "        \"idea\": SEED_IDEA,\n",
        "        \"plan\": plan_json,\n",
        "        \"themes\": \", \".join(THEME_BIBLE.get(\"themes\", [])),\n",
        "        \"sensory_palette\": \", \".join(sensory_palette),\n",
        "        \"dialogue_target\": dialogue_target,\n",
        "        \"worldbrief\": WORLD_BRIEF or \"(none)\"\n",
        "    })\n",
        "    chapter_txt = strip_think(res)\n",
        "\n",
        "    # Repetition guard\n",
        "    ledger = []\n",
        "    for j in range(idx):\n",
        "        prev = chap_texts[j]\n",
        "        if not prev: continue\n",
        "        if bigram_overlap(chapter_txt, prev) > BIGRAM_THRESHOLD:\n",
        "            ledger.extend(top_trigrams(prev, k=10))\n",
        "    ledger = list(dict.fromkeys(ledger))[:60]\n",
        "    if ledger:\n",
        "        chapter_txt = strip_think(revision_chain.invoke({\n",
        "            \"chapter\": chapter_txt,\n",
        "            \"title\": meta[\"title\"],\n",
        "            \"description\": meta[\"description\"],\n",
        "            \"ledger\": \"; \".join(ledger)\n",
        "        }))\n",
        "\n",
        "    # Evaluation + conditional polish\n",
        "    data = None\n",
        "    try:\n",
        "        report_txt = strip_think(eval_chain.invoke({\"chapter\": chapter_txt}))\n",
        "        m = re.search(r\"\\{[\\s\\S]*\\}\\s*$\", report_txt)\n",
        "        if m:\n",
        "            data = json.loads(m.group(0))\n",
        "        if data and \"scores\" in data:\n",
        "            scores = data[\"scores\"]\n",
        "            avg = sum(float(scores[k]) for k in scores)/len(scores)\n",
        "            dr = approx_dialogue_ratio(chapter_txt)\n",
        "            if abs(dr - dialogue_target) > 0.10:\n",
        "                chapter_txt = strip_think(dialogue_tuner.invoke({\"chapter\": chapter_txt, \"target\": dialogue_target}))\n",
        "            if (avg < 7.6) or (not FAST_MODE):\n",
        "                chapter_txt = strip_think(decliche_chain.invoke({\"chapter\": chapter_txt}))\n",
        "            if avg < 7.4:\n",
        "                edits = \" | \".join(data.get(\"three_micro_edits\", [])) or \"Sharpen hook; escalate midpoint; add concrete sensory beats.\"\n",
        "                chapter_txt = strip_think(punchup_chain.invoke({\"chapter\": chapter_txt, \"edits\": edits}))\n",
        "    except Exception:\n",
        "        data = None\n",
        "\n",
        "    # Mine motifs\n",
        "    try:\n",
        "        mined = parse_strict_json(motif_miner.invoke({\"chapter\": chapter_txt})) or {}\n",
        "        for m in (mined.get(\"motifs\") or []):\n",
        "            if m not in MOTIF_LEDGER: MOTIF_LEDGER.append(m)\n",
        "    except Exception: pass\n",
        "\n",
        "    save_ckpt(idx, title, chapter_txt, data)\n",
        "    return chapter_txt, data\n",
        "\n",
        "# Early calibration on first 3\n",
        "PREGEN = min(3, len(outline))\n",
        "for i in range(PREGEN):\n",
        "    ch_txt, notes = write_one(i); chap_texts[i] = ch_txt; editor_notes[i] = notes\n",
        "\n",
        "# Resize outline based on observed words/chapter to hit page target\n",
        "actual_avg = max(500, sum(word_count(chap_texts[i]) for i in range(PREGEN)) // PREGEN)\n",
        "recalc_num_ch = max(12, min(80, (TARGET_WORDS + actual_avg - 1) // actual_avg))\n",
        "if recalc_num_ch != len(outline):\n",
        "    delta = recalc_num_ch - len(outline)\n",
        "    if delta > 0:\n",
        "        print(f\"ğŸ” Resizing outline: need +{delta} chaptersâ€¦\")\n",
        "        extra = robust_outline_batch(SEED_IDEA, delta, list(seen_titles), [])\n",
        "        for obj in extra:\n",
        "            cand = {\"title\": (obj.get(\"title\") or \"\").strip(),\n",
        "                    \"description\": (obj.get(\"description\") or \"\").strip()}\n",
        "            if not cand[\"title\"] or not cand[\"description\"]: continue\n",
        "            if cand[\"title\"] in seen_titles: continue\n",
        "            if any(too_similar_relaxed(cand, e) for e in outline): continue\n",
        "            outline.append(cand); seen_titles.add(cand[\"title\"])\n",
        "            chap_texts.append(None); editor_notes.append(None)\n",
        "            if len(outline) >= recalc_num_ch: break\n",
        "        print(f\"   â†’ total {len(outline)} chapters after resize\")\n",
        "    elif delta < 0:\n",
        "        keep = max(PREGEN, recalc_num_ch)\n",
        "        outline = outline[:keep]; chap_texts = chap_texts[:keep]; editor_notes = editor_notes[:keep]\n",
        "        print(f\"âœ‚ï¸  Trimmed outline to {len(outline)} chapters\")\n",
        "\n",
        "# Finish remaining chapters\n",
        "remaining_idxs = [i for i, t in enumerate(chap_texts) if t is None]\n",
        "with ThreadPoolExecutor(max_workers=MAX_WORKERS) as ex:\n",
        "    futures = { ex.submit(write_one, i): i for i in remaining_idxs }\n",
        "    for fut in tqdm(as_completed(futures), total=len(futures), desc=\"Chapters\"):\n",
        "        idx = futures[fut]\n",
        "        try:\n",
        "            ch_txt, notes = fut.result()\n",
        "        except Exception as e:\n",
        "            ch_txt, notes = f\"[Generation failed: {e}]\", None\n",
        "        chap_texts[idx] = ch_txt; editor_notes[idx] = notes\n",
        "\n",
        "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
        "# 10) Build DOCX: Characters, Research Brief, Counterfactual Points, Chapters\n",
        "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
        "total_words = sum(word_count(t or \"\") for t in chap_texts)\n",
        "est_pages  = total_words / WORDS_PER_PAGE\n",
        "suggested_ch = max(12, min(80, round(total_words / CH_TARGET_WORDS)))\n",
        "print(f\"ğŸ§® Total words: {total_words:,}  â†’ est. pages â‰ˆ {est_pages:.0f}\")\n",
        "print(f\"ğŸ”§ If you rerun, suggested chapters for this style â‰ˆ {suggested_ch}\")\n",
        "\n",
        "doc = docx.Document()\n",
        "doc.add_heading(BOOK_TITLE, 0)\n",
        "doc.add_paragraph(f\"Seed idea: {SEED_IDEA}\")\n",
        "doc.add_paragraph(f\"Estimated pages: ~{est_pages:.0f}\")\n",
        "\n",
        "# Character Bible\n",
        "if characters:\n",
        "    doc.add_page_break()\n",
        "    doc.add_heading(\"Character Development\", level=1)\n",
        "    for c in characters:\n",
        "        name = c.get(\"name\",\"(Unnamed)\")\n",
        "        role = c.get(\"role\",\"\"); arc = c.get(\"development_arc\",\"\")\n",
        "        doc.add_heading(name, level=2)\n",
        "        if role: doc.add_paragraph(f\"Role: {role}\")\n",
        "        if arc:  doc.add_paragraph(arc)\n",
        "\n",
        "# Research Brief\n",
        "if RESEARCH_AGENT_ENABLED and pathlib.Path(\"research/history_brief.md\").exists():\n",
        "    doc.add_page_break()\n",
        "    doc.add_heading(\"Historical Brief (2017â€“2021 Baseline)\", level=1)\n",
        "    md_text = pathlib.Path(\"research/history_brief.md\").read_text(encoding=\"utf-8\")\n",
        "    # Keep it short in the docx (top sections only)\n",
        "    for para in md_text.splitlines()[:300]:\n",
        "        if para.startswith(\"#\"):\n",
        "            if para.startswith(\"## \"): doc.add_heading(para.replace(\"## \",\"\"), level=2)\n",
        "            elif para.startswith(\"# \"): doc.add_heading(para.replace(\"# \",\"\"), level=1)\n",
        "        elif para.strip():\n",
        "            doc.add_paragraph(para.strip())\n",
        "\n",
        "# Counterfactual Divergence Points\n",
        "if COUNTERFACTUAL_POINTS:\n",
        "    doc.add_page_break()\n",
        "    doc.add_heading(\"Counterfactual: 10 Divergence Points (HRC 2017â€“2021)\", level=1)\n",
        "    for i, d in enumerate(COUNTERFACTUAL_POINTS, 1):\n",
        "        doc.add_heading(f\"{i}. {d.get('title','')}\", level=2)\n",
        "        doc.add_paragraph(\"What changes: \" + d.get(\"what_changes\",\"\"))\n",
        "        doc.add_paragraph(\"Downstream ripples: \" + d.get(\"downstream_ripples\",\"\"))\n",
        "        for c in d.get(\"conflicts\",[])[:3]:\n",
        "            doc.add_paragraph(\"â€¢ \" + c)\n",
        "\n",
        "# Chapters\n",
        "for i, (meta, text) in enumerate(zip(outline, chap_texts), start=1):\n",
        "    doc.add_page_break()\n",
        "    doc.add_heading(f\"Chapter {i}: {meta['title']}\", level=1)\n",
        "    doc.add_paragraph(meta['description'], style=\"Intense Quote\")\n",
        "    doc.add_paragraph((text or \"\").strip())\n",
        "\n",
        "# Editorâ€™s Notes\n",
        "doc.add_page_break()\n",
        "doc.add_heading(\"Editorâ€™s Notes (Auto-Eval)\", level=1)\n",
        "for i, (meta, notes) in enumerate(zip(outline, editor_notes), start=1):\n",
        "    doc.add_heading(f\"Chapter {i}: {meta['title']}\", level=2)\n",
        "    if not notes or \"scores\" not in (notes or {}):\n",
        "        doc.add_paragraph(\"No evaluation available.\"); continue\n",
        "    scores = notes[\"scores\"]; one_liner = notes.get(\"one_sentence_note\",\"\")\n",
        "    edits = notes.get(\"three_micro_edits\", [])\n",
        "    try: avg_score = sum(float(scores[k]) for k in scores)/len(scores)\n",
        "    except Exception: avg_score = None\n",
        "    doc.add_paragraph(\"Scores: \" + \", \".join(f\"{k}: {scores[k]}\" for k in scores))\n",
        "    if avg_score is not None: doc.add_paragraph(f\"Average: {avg_score:.2f}\")\n",
        "    if one_liner: doc.add_paragraph(f\"Note: {one_liner}\")\n",
        "    for e in (edits or []): doc.add_paragraph(f\"â€¢ {e}\")\n",
        "\n",
        "# Back-cover copy\n",
        "blurb_data = {}\n",
        "try:\n",
        "    blurb_data = parse_strict_json(blurb_chain.invoke({\n",
        "        \"title\": BOOK_TITLE,\n",
        "        \"logline\": THEME_BIBLE.get(\"logline\",\"\"),\n",
        "        \"themes\": \", \".join(THEME_BIBLE.get(\"themes\", [])),\n",
        "        \"promises\": \", \".join(THEME_BIBLE.get(\"promises\", []))\n",
        "    })) or {}\n",
        "except Exception:\n",
        "    blurb_data = {}\n",
        "\n",
        "doc.add_page_break()\n",
        "doc.add_heading(\"Back-Cover Copy & Retailer Hook\", level=1)\n",
        "if blurb_data.get(\"blurb\"): doc.add_paragraph(blurb_data[\"blurb\"])\n",
        "if blurb_data.get(\"product_hook\"): doc.add_paragraph(f\"\\nRetailer Hook: {blurb_data['product_hook']}\")\n",
        "if blurb_data.get(\"snippets\"):\n",
        "    doc.add_heading(\"Short Social Snippets\", level=2)\n",
        "    for s in blurb_data[\"snippets\"]:\n",
        "        doc.add_paragraph(f\"â€¢ {s}\")\n",
        "\n",
        "# Save & download\n",
        "fn = BOOK_TITLE.replace(\" \", \"_\") + \".docx\"\n",
        "doc.save(fn)\n",
        "print(f\"ğŸ“˜ Saved {fn}\")\n",
        "files.download(fn)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "qSo8bjom_jQp",
        "outputId": "46ccb11f-b159-466d-a989-64106f6aba3f"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m132.6/132.6 kB\u001b[0m \u001b[31m2.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m837.9/837.9 kB\u001b[0m \u001b[31m8.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m3.3/3.3 MB\u001b[0m \u001b[31m8.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m315.5/315.5 kB\u001b[0m \u001b[31m9.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m274.7/274.7 kB\u001b[0m \u001b[31m7.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hâœ… Ollama health: 200\n",
            "ğŸ–¥ï¸ GPU: not detected\n",
            "âœ” Using model: llama3.2:3b\n",
            "âœ” Using model: llama3.2:3b\n",
            "ğŸ¯ Target pages: 320  â†’ target words â‰ˆ 88,000\n",
            "ğŸ“ Chapter target: ~3,000 words â†’ initial chapters: 30\n",
            "â†’ Generating 30-chapter outline (booster mode) â€¦\n",
            "   âœ“ planner JSON (rescued)\n",
            "   â†’ accepted 1; total now 1/30\n",
            "   âœ“ planner JSON (rescued)\n",
            "   â†’ accepted 1; total now 2/30\n",
            "   âœ“ planner JSON (rescued)\n",
            "   â†’ accepted 1; total now 3/30\n",
            "   âœ“ planner JSON (rescued)\n",
            "   â†’ accepted 1; total now 4/30\n",
            "   âœ“ planner JSON (rescued)\n",
            "   â†’ accepted 1; total now 5/30\n",
            "   âœ“ planner JSON (rescued)\n",
            "   â†’ accepted 1; total now 6/30\n",
            "   âœ“ planner JSON (rescued)\n",
            "   â†’ accepted 1; total now 7/30\n",
            "   âœ“ planner JSON (rescued)\n",
            "   â†’ accepted 0; total now 7/30\n",
            "   Â· No unique chapters accepted from batch; retryingâ€¦\n",
            "   âœ“ planner JSON (rescued)\n",
            "   â†’ accepted 1; total now 8/30\n",
            "   âœ“ planner JSON (rescued)\n",
            "   â†’ accepted 1; total now 9/30\n",
            "   âœ“ planner JSON (rescued)\n",
            "   â†’ accepted 1; total now 10/30\n",
            "   âœ“ planner JSON (rescued)\n",
            "   â†’ accepted 1; total now 11/30\n",
            "   âœ“ planner JSON (rescued)\n",
            "   â†’ accepted 1; total now 12/30\n",
            "   âœ“ planner JSON (rescued)\n",
            "   â†’ accepted 1; total now 13/30\n",
            "   âœ“ planner JSON (rescued)\n",
            "   â†’ accepted 0; total now 13/30\n",
            "   Â· No unique chapters accepted from batch; retryingâ€¦\n",
            "   âœ“ planner JSON (rescued)\n",
            "   â†’ accepted 0; total now 13/30\n",
            "   Â· No unique chapters accepted from batch; retryingâ€¦\n",
            "   âœ“ planner JSON (rescued)\n",
            "   â†’ accepted 0; total now 13/30\n",
            "   Â· No unique chapters accepted from batch; retryingâ€¦\n",
            "   âœ“ planner JSON (rescued)\n",
            "   â†’ accepted 0; total now 13/30\n",
            "   Â· No unique chapters accepted from batch; retryingâ€¦\n",
            "   âœ“ planner JSON (rescued)\n",
            "   â†’ accepted 0; total now 13/30\n",
            "   Â· No unique chapters accepted from batch; retryingâ€¦\n",
            "   âœ“ planner JSON (rescued)\n",
            "   â†’ accepted 0; total now 13/30\n",
            "   Â· No unique chapters accepted from batch; retryingâ€¦\n",
            "   âœ“ planner JSON (rescued)\n",
            "   â†’ accepted 0; total now 13/30\n",
            "   Â· No unique chapters accepted from batch; retryingâ€¦\n",
            "   âœ“ planner JSON (rescued)\n",
            "   â†’ accepted 0; total now 13/30\n",
            "   Â· No unique chapters accepted from batch; retryingâ€¦\n",
            "   âœ“ planner JSON (rescued)\n",
            "   â†’ accepted 0; total now 13/30\n",
            "   Â· No unique chapters accepted from batch; retryingâ€¦\n",
            "   âœ“ planner JSON (rescued)\n",
            "   â†’ accepted 0; total now 13/30\n",
            "   Â· No unique chapters accepted from batch; retryingâ€¦\n",
            "   âœ“ planner JSON (rescued)\n",
            "   â†’ accepted 0; total now 13/30\n",
            "   Â· No unique chapters accepted from batch; retryingâ€¦\n",
            "   âœ“ planner JSON (rescued)\n",
            "   â†’ accepted 0; total now 13/30\n",
            "   Â· No unique chapters accepted from batch; retryingâ€¦\n",
            "   âœ“ planner JSON (rescued)\n",
            "   â†’ accepted 0; total now 13/30\n",
            "   Â· No unique chapters accepted from batch; retryingâ€¦\n",
            "   âœ“ planner JSON (rescued)\n",
            "   â†’ accepted 1; total now 14/30\n",
            "   âœ“ planner JSON (rescued)\n",
            "   â†’ accepted 0; total now 14/30\n",
            "   Â· No unique chapters accepted from batch; retryingâ€¦\n",
            "   âœ“ planner JSON (rescued)\n",
            "   â†’ accepted 0; total now 14/30\n",
            "   Â· No unique chapters accepted from batch; retryingâ€¦\n",
            "   âœ“ planner JSON (rescued)\n",
            "   â†’ accepted 0; total now 14/30\n",
            "   Â· No unique chapters accepted from batch; retryingâ€¦\n",
            "   âœ“ planner JSON (rescued)\n",
            "   â†’ accepted 0; total now 14/30\n",
            "   Â· No unique chapters accepted from batch; retryingâ€¦\n",
            "   âœ“ planner JSON (rescued)\n",
            "   â†’ accepted 0; total now 14/30\n",
            "   Â· No unique chapters accepted from batch; retryingâ€¦\n",
            "   âœ“ planner JSON (rescued)\n",
            "   â†’ accepted 0; total now 14/30\n",
            "   Â· No unique chapters accepted from batch; retryingâ€¦\n",
            "   âœ“ planner JSON (rescued)\n",
            "   â†’ accepted 0; total now 14/30\n",
            "   Â· No unique chapters accepted from batch; retryingâ€¦\n",
            "   âœ“ planner JSON (rescued)\n",
            "   â†’ accepted 0; total now 14/30\n",
            "   Â· No unique chapters accepted from batch; retryingâ€¦\n",
            "   âœ“ planner JSON (rescued)\n",
            "   â†’ accepted 0; total now 14/30\n",
            "   Â· No unique chapters accepted from batch; retryingâ€¦\n",
            "   âœ“ planner JSON (rescued)\n",
            "   â†’ accepted 0; total now 14/30\n",
            "   Â· No unique chapters accepted from batch; retryingâ€¦\n",
            "   âœ“ planner JSON (rescued)\n",
            "   â†’ accepted 0; total now 14/30\n",
            "   Â· No unique chapters accepted from batch; retryingâ€¦\n",
            "   âœ“ planner JSON (rescued)\n",
            "   â†’ accepted 0; total now 14/30\n",
            "   Â· No unique chapters accepted from batch; retryingâ€¦\n",
            "   âœ“ planner JSON (rescued)\n",
            "   â†’ accepted 1; total now 15/30\n",
            "   âœ“ planner JSON (rescued)\n",
            "   â†’ accepted 0; total now 15/30\n",
            "   Â· No unique chapters accepted from batch; retryingâ€¦\n",
            "   âœ“ planner JSON (rescued)\n",
            "   â†’ accepted 0; total now 15/30\n",
            "   Â· No unique chapters accepted from batch; retryingâ€¦\n",
            "   âœ“ planner JSON (rescued)\n",
            "   â†’ accepted 1; total now 16/30\n",
            "   âœ“ planner JSON (rescued)\n",
            "   â†’ accepted 0; total now 16/30\n",
            "   Â· No unique chapters accepted from batch; retryingâ€¦\n",
            "   âœ“ planner JSON (rescued)\n",
            "   â†’ accepted 0; total now 16/30\n",
            "   Â· No unique chapters accepted from batch; retryingâ€¦\n",
            "   âœ“ planner JSON (rescued)\n",
            "   â†’ accepted 0; total now 16/30\n",
            "   Â· No unique chapters accepted from batch; retryingâ€¦\n",
            "   âœ“ planner JSON (rescued)\n",
            "   â†’ accepted 0; total now 16/30\n",
            "   Â· No unique chapters accepted from batch; retryingâ€¦\n",
            "   âœ“ planner JSON (rescued)\n",
            "   â†’ accepted 0; total now 16/30\n",
            "   Â· No unique chapters accepted from batch; retryingâ€¦\n",
            "   âœ“ planner JSON (rescued)\n",
            "   â†’ accepted 0; total now 16/30\n",
            "   Â· No unique chapters accepted from batch; retryingâ€¦\n",
            "   âœ“ planner JSON (rescued)\n",
            "   â†’ accepted 0; total now 16/30\n",
            "   Â· No unique chapters accepted from batch; retryingâ€¦\n",
            "   âœ“ planner JSON (rescued)\n",
            "   â†’ accepted 0; total now 16/30\n",
            "   Â· No unique chapters accepted from batch; retryingâ€¦\n",
            "   âœ“ planner JSON (rescued)\n",
            "   â†’ accepted 0; total now 16/30\n",
            "   Â· No unique chapters accepted from batch; retryingâ€¦\n",
            "   âœ“ planner JSON (rescued)\n",
            "   â†’ accepted 0; total now 16/30\n",
            "   Â· No unique chapters accepted from batch; retryingâ€¦\n",
            "   âœ“ planner JSON (rescued)\n",
            "   â†’ accepted 0; total now 16/30\n",
            "   Â· No unique chapters accepted from batch; retryingâ€¦\n",
            "   âœ“ planner JSON (rescued)\n",
            "   â†’ accepted 0; total now 16/30\n",
            "   Â· No unique chapters accepted from batch; retryingâ€¦\n",
            "   âœ“ planner JSON (rescued)\n",
            "   â†’ accepted 0; total now 16/30\n",
            "   Â· No unique chapters accepted from batch; retryingâ€¦\n",
            "   âœ“ planner JSON (rescued)\n",
            "   â†’ accepted 0; total now 16/30\n",
            "   Â· No unique chapters accepted from batch; retryingâ€¦\n",
            "   âœ“ planner JSON (rescued)\n",
            "   â†’ accepted 0; total now 16/30\n",
            "   Â· No unique chapters accepted from batch; retryingâ€¦\n",
            "   âœ“ planner JSON (rescued)\n",
            "   â†’ accepted 0; total now 16/30\n",
            "   Â· No unique chapters accepted from batch; retryingâ€¦\n",
            "âœ” Final outline: 16 chapters\n",
            "\n",
            "âš ï¸ Could not reach target; proceeding with what we have.\n",
            "â†’ Generating 3 charactersâ€¦\n",
            "âœ” Got 3 characters\n",
            "\n",
            "â†’ Building theme/motif bibleâ€¦\n",
            "âœ” Theme bible ready.\n",
            "\n",
            "ğŸ” Research agent: collecting sourcesâ€¦\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-2345448001.py:445: RuntimeWarning: This package (`duckduckgo_search`) has been renamed to `ddgs`! Use `pip install ddgs` instead.\n",
            "  with DDGS() as ddgs:\n",
            "/tmp/ipython-input-2345448001.py:445: RuntimeWarning: This package (`duckduckgo_search`) has been renamed to `ddgs`! Use `pip install ddgs` instead.\n",
            "  with DDGS() as ddgs:\n",
            "/tmp/ipython-input-2345448001.py:445: RuntimeWarning: This package (`duckduckgo_search`) has been renamed to `ddgs`! Use `pip install ddgs` instead.\n",
            "  with DDGS() as ddgs:\n",
            "/tmp/ipython-input-2345448001.py:445: RuntimeWarning: This package (`duckduckgo_search`) has been renamed to `ddgs`! Use `pip install ddgs` instead.\n",
            "  with DDGS() as ddgs:\n",
            "/tmp/ipython-input-2345448001.py:445: RuntimeWarning: This package (`duckduckgo_search`) has been renamed to `ddgs`! Use `pip install ddgs` instead.\n",
            "  with DDGS() as ddgs:\n",
            "/tmp/ipython-input-2345448001.py:445: RuntimeWarning: This package (`duckduckgo_search`) has been renamed to `ddgs`! Use `pip install ddgs` instead.\n",
            "  with DDGS() as ddgs:\n",
            "/tmp/ipython-input-2345448001.py:445: RuntimeWarning: This package (`duckduckgo_search`) has been renamed to `ddgs`! Use `pip install ddgs` instead.\n",
            "  with DDGS() as ddgs:\n",
            "/tmp/ipython-input-2345448001.py:445: RuntimeWarning: This package (`duckduckgo_search`) has been renamed to `ddgs`! Use `pip install ddgs` instead.\n",
            "  with DDGS() as ddgs:\n",
            "Fetching: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 25/25 [00:00<00:00, 126182.43it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ğŸ§¾ Saved research/history_brief.{json,md}\n",
            "â†’ Generating chaptersâ€¦\n",
            "ğŸ” Resizing outline: need +64 chaptersâ€¦\n",
            "   âœ“ planner JSON (rescued)\n",
            "   â†’ total 17 chapters after resize\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Chapters: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 14/14 [4:50:48<00:00, 1246.33s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ğŸ§® Total words: 13,786  â†’ est. pages â‰ˆ 50\n",
            "ğŸ”§ If you rerun, suggested chapters for this style â‰ˆ 12\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "AttributeError",
          "evalue": "'str' object has no attribute 'get'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-2345448001.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    915\u001b[0m     \u001b[0mdoc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_heading\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Counterfactual: 10 Divergence Points (HRC 2017â€“2021)\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlevel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    916\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0md\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mCOUNTERFACTUAL_POINTS\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 917\u001b[0;31m         \u001b[0mdoc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_heading\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"{i}. {d.get('title','')}\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlevel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    918\u001b[0m         \u001b[0mdoc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_paragraph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"What changes: \"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0md\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"what_changes\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\"\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    919\u001b[0m         \u001b[0mdoc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_paragraph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Downstream ripples: \"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0md\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"downstream_ripples\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\"\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAttributeError\u001b[0m: 'str' object has no attribute 'get'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "f4bVVRSbkrha"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "EM-tJ8IpkreX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "tu_eaMpQkrbU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ESh7jncekrYy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "en1h1yEMkrVJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
        "# 0) Colab Setup: install & launch Ollama (+ research agent, robust fallbacks)\n",
        "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
        "!pip install --quiet langchain-ollama python-docx tqdm ddgs trafilatura readability-lxml\n",
        "\n",
        "import os, threading, subprocess, time, requests, json, re, shutil, pathlib, sys, random, math\n",
        "from typing import List, Any, Dict, Tuple\n",
        "from concurrent.futures import ThreadPoolExecutor, as_completed\n",
        "from collections import Counter\n",
        "from tqdm import tqdm\n",
        "import docx\n",
        "from google.colab import files\n",
        "\n",
        "# Avoid LangChain provider hijacks\n",
        "for v in [\n",
        "    \"OPENAI_API_KEY\",\n",
        "    \"LITELLM_PROVIDER\", \"LITELLM_MODEL\", \"LITELLM_BASE_URL\",\n",
        "    \"LITELL M_PROVIDER\", \"LITELL M_MODEL\", \"LITELL M_BASE_URL\"\n",
        "]:\n",
        "    os.environ.pop(v, None)\n",
        "\n",
        "# â€”â€” Toggles / sizing knobs â€”â€”\n",
        "FAST_MODE = True                   # lighter sampling for speed on CPU\n",
        "RESEARCH_AGENT_ENABLED = True      # set False to disable web brief\n",
        "CPU_CHAPTER_CAP = 24               # soft cap for CPU-only runs; set to None to disable\n",
        "CHECKPOINT_DIR = \"book_ckpt\"       # per-chapter cache on disk\n",
        "os.makedirs(CHECKPOINT_DIR, exist_ok=True)\n",
        "\n",
        "# Conservative Ollama parallelism for Colab\n",
        "os.environ[\"OLLAMA_MAX_LOADED_MODELS\"] = \"1\"\n",
        "os.environ[\"OLLAMA_NUM_PARALLEL\"] = \"1\"\n",
        "\n",
        "# Launch Ollama\n",
        "os.environ[\"OLLAMA_HOST\"]    = \"127.0.0.1:11434\"\n",
        "os.environ[\"OLLAMA_ORIGINS\"] = \"*\"\n",
        "!curl -fsSL https://ollama.com/install.sh -o install.sh\n",
        "!bash install.sh >/dev/null 2>&1 || true\n",
        "\n",
        "def _serve_ollama():\n",
        "    subprocess.Popen([\"ollama\",\"serve\"], stderr=subprocess.DEVNULL, stdout=subprocess.DEVNULL)\n",
        "threading.Thread(target=_serve_ollama, daemon=True).start()\n",
        "time.sleep(8)\n",
        "print(\"âœ… Ollama health:\", requests.get(\"http://127.0.0.1:11434\").status_code)\n",
        "\n",
        "def _has_gpu():\n",
        "    try:\n",
        "        return shutil.which(\"nvidia-smi\") and (subprocess.run([\"nvidia-smi\"], capture_output=True).returncode==0)\n",
        "    except Exception:\n",
        "        return False\n",
        "HAS_GPU = bool(_has_gpu())\n",
        "print(\"ğŸ–¥ï¸ GPU:\", \"available\" if HAS_GPU else \"not detected\")\n",
        "\n",
        "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
        "# 1) Model resolver: pick the first available model from candidates\n",
        "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
        "def pick_first_available(candidates: List[str]) -> str:\n",
        "    for m in candidates:\n",
        "        try:\n",
        "            r = subprocess.run([\"ollama\", \"pull\", m], capture_output=True, text=True)\n",
        "            if r.returncode == 0:\n",
        "                print(f\"âœ” Using model: {m}\")\n",
        "                return m\n",
        "            else:\n",
        "                print(f\"âœ– Pull failed for {m} â†’ {r.stderr.strip() or r.stdout.strip()}\")\n",
        "        except Exception as e:\n",
        "            print(f\"âœ– Error pulling {m}: {e}\")\n",
        "    raise RuntimeError(f\"No candidate models could be pulled: {candidates}\")\n",
        "\n",
        "PLANNER_CANDIDATES = [\"llama3.2:3b\",\"qwen2.5:3b\",\"phi3:3.8b-mini\",\"gemma2:2b\",\"mistral:7b\",\"llama3.1:8b\"]\n",
        "WRITER_FAST_CANDIDATES = [\"llama3.2:3b\",\"qwen2.5:3b\",\"phi3:3.8b-mini\",\"gemma2:2b\",\"mistral:7b\",\"llama3.1:8b\"]\n",
        "WRITER_QUALITY_CANDIDATES = [\"llama3.1:8b\",\"mistral:7b\",\"qwen2.5:7b\"]\n",
        "\n",
        "PLANNER_MODEL = pick_first_available(PLANNER_CANDIDATES)\n",
        "WRITER_MODEL  = pick_first_available(WRITER_FAST_CANDIDATES if FAST_MODE else WRITER_QUALITY_CANDIDATES)\n",
        "\n",
        "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
        "# 2) User targets: auto pages â†’ words â†’ chapters\n",
        "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
        "BOOK_TITLE   = \"What Could Have Been: An Alternative History\"\n",
        "MODE         = \"fiction\"  # or \"nonfiction\"\n",
        "TARGET_PAGES = 320 if MODE == \"fiction\" else 280\n",
        "\n",
        "GENRE_PROFILE = {\n",
        "    \"fiction\":   {\"pages_min\": 280, \"pages_max\": 360, \"chapter_words_typical\": (2400, 3600)},\n",
        "    \"nonfiction\":{\"pages_min\": 220, \"pages_max\": 320, \"chapter_words_typical\": (3000, 4500)}\n",
        "}[MODE]\n",
        "\n",
        "if TARGET_PAGES is None:\n",
        "    TARGET_PAGES = (GENRE_PROFILE[\"pages_min\"] + GENRE_PROFILE[\"pages_max\"]) // 2\n",
        "\n",
        "WORDS_PER_PAGE = 275\n",
        "TARGET_WORDS   = int(TARGET_PAGES * WORDS_PER_PAGE)\n",
        "\n",
        "CH_MIN, CH_MAX = GENRE_PROFILE[\"chapter_words_typical\"]\n",
        "CH_TARGET_WORDS = int((CH_MIN + CH_MAX) / 2)\n",
        "\n",
        "# Base chapter count from pages goal\n",
        "NUM_CH = max(12, min(80, (TARGET_WORDS + CH_TARGET_WORDS - 1) // CH_TARGET_WORDS))\n",
        "# Optional CPU cap\n",
        "if CPU_CHAPTER_CAP and not HAS_GPU:\n",
        "    if NUM_CH > CPU_CHAPTER_CAP:\n",
        "        print(f\"âš™ï¸ CPU chapter cap active â†’ {CPU_CHAPTER_CAP} (was {NUM_CH})\")\n",
        "        NUM_CH = CPU_CHAPTER_CAP\n",
        "\n",
        "SEED_IDEA = (\"Counterfactual: Hillary Clinton wins the 2016 U.S. election. \"\n",
        "             \"Track real 2017â€“2021 events as baseline, then explore plausible divergences \"\n",
        "             \"in domestic policy, foreign affairs, courts, and tech/social media dynamics.\")\n",
        "\n",
        "print(f\"ğŸ¯ Target pages: {TARGET_PAGES}  â†’ target words â‰ˆ {TARGET_WORDS:,}\")\n",
        "print(f\"ğŸ“ Chapter target: ~{CH_TARGET_WORDS:,} words â†’ initial chapters: {NUM_CH}\")\n",
        "\n",
        "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
        "# 3) LLMs & prompts (incl. research-aware chapter prompt)\n",
        "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
        "from langchain_ollama import OllamaLLM\n",
        "from langchain_core.prompts import PromptTemplate\n",
        "\n",
        "PLANNER_NUM_PREDICT = 900 if FAST_MODE else 1400\n",
        "WRITER_NUM_PREDICT  = 1600 if FAST_MODE else 3000\n",
        "MAX_WORKERS = 1 if (FAST_MODE or not HAS_GPU) else 3\n",
        "\n",
        "planner_llm = OllamaLLM(model=PLANNER_MODEL, base_url=\"http://127.0.0.1:11434\",\n",
        "                        temperature=0.25, num_predict=PLANNER_NUM_PREDICT)\n",
        "planner_llm_json = OllamaLLM(model=PLANNER_MODEL, base_url=\"http://127.0.0.1:11434\",\n",
        "                             temperature=0.2, num_predict=PLANNER_NUM_PREDICT, format=\"json\")\n",
        "writer_llm  = OllamaLLM(model=WRITER_MODEL, base_url=\"http://127.0.0.1:11434\",\n",
        "                        temperature=0.8, num_ctx=4096, num_predict=WRITER_NUM_PREDICT)\n",
        "\n",
        "# Outline prompts with diversity/avoid lists (variety seed to shake outputs)\n",
        "OUTLINE_JSON_PROMPT = PromptTemplate(\n",
        "    input_variables=[\"topic\",\"count\",\"avoid_titles\",\"avoid_phrases\",\"vseed\"],\n",
        "    template=(\n",
        "\"\"\"Generate exactly {count} DIFFERENT chapter seeds for this novel as a JSON ARRAY.\n",
        "Each item: {{\"title\":\"...\", \"description\":\"...\"}}\n",
        "Rules:\n",
        "- Vary SETTING, MODE OF CONFLICT, and REVERSAL TYPE across items.\n",
        "- Avoid any titles in AVOID_TITLES and any phrases in AVOID_PHRASES.\n",
        "- Return JSON ONLY (no commentary).\n",
        "VARIETY_SEED: {vseed}\n",
        "Book idea: {topic}\n",
        "AVOID_TITLES: {avoid_titles}\n",
        "AVOID_PHRASES: {avoid_phrases}\n",
        "\"\"\"))\n",
        "\n",
        "OUTLINE_NDJSON_PROMPT = PromptTemplate(\n",
        "    input_variables=[\"topic\",\"count\",\"avoid_titles\",\"avoid_phrases\",\"vseed\"],\n",
        "    template=(\n",
        "\"\"\"Generate exactly {count} DIFFERENT chapter seeds as NDJSON (one JSON object per line).\n",
        "Each line: {{\"title\":\"...\", \"description\":\"...\"}}\n",
        "Rules:\n",
        "- Vary SETTING, MODE OF CONFLICT, and REVERSAL TYPE across items.\n",
        "- Avoid any titles in AVOID_TITLES and any phrases in AVOID_PHRASES.\n",
        "- No numbering, no code fences, no commentary.\n",
        "VARIETY_SEED: {vseed}\n",
        "Book idea: {topic}\n",
        "AVOID_TITLES: {avoid_titles}\n",
        "AVOID_PHRASES: {avoid_phrases}\n",
        "\"\"\"))\n",
        "\n",
        "CHAR_JSON_PROMPT = PromptTemplate(\n",
        "    input_variables=[\"outline\",\"num_chars\"],\n",
        "    template=(\n",
        "\"\"\"Given this chapter outline (JSON list): {outline}\n",
        "Create exactly {num_chars} MAIN CHARACTERS as a JSON ARRAY.\n",
        "Each item: {{\"name\":\"...\",\"role\":\"...\",\"development_arc\":\"...\"}}\n",
        "Return JSON ONLY.\"\"\"\n",
        "))\n",
        "\n",
        "# Research-aware chapter flow\n",
        "THEME_PROMPT = PromptTemplate(\n",
        "    input_variables=[\"topic\",\"outline\"],\n",
        "    template=(\n",
        "\"\"\"From the seed idea and outline, produce STRICT JSON:\n",
        "{{\n",
        "  \"themes\": [\"...\"], \"motifs\": [\"...\"], \"promises\": [\"...\"],\n",
        "  \"logline\": \"...\", \"genre_signals\": [\"...\"]\n",
        "}}\n",
        "Seed idea: {topic}\n",
        "Outline: {outline}\n",
        "\"\"\"))\n",
        "\n",
        "BEATS_PROMPT = PromptTemplate(\n",
        "    input_variables=[\"title\",\"description\",\"theme_bible\",\"motif_ledger\",\"worldbrief\"],\n",
        "    template=(\n",
        "\"\"\"Plan a beat sheet as STRICT JSON:\n",
        "{{\n",
        "  \"beats\": [\n",
        "    {{\"name\":\"Hook\",\"goal\":\"...\",\"conflict\":\"...\",\"setting\":\"...\",\"emotion\":\"...\"}}, ...\n",
        "  ],\n",
        "  \"dialogue_target_pct\": 0.36,\n",
        "  \"sensory_palette\": [\"sound\",\"smell\"],\n",
        "  \"foreshadow\":\"...\",\n",
        "  \"callback_motif\":\"...\"\n",
        "}}\n",
        "Requirements:\n",
        "- 8â€“12 beats with a midpoint reversal and a stinger.\n",
        "- Weave in WORLD BRIEF lightly (no info-dumps): {worldbrief}\n",
        "TITLE: {title}\n",
        "DESC: {description}\n",
        "THEME_BIBLE: {theme_bible}\n",
        "MOTIF_LEDGER: {motif_ledger}\n",
        "\"\"\"))\n",
        "\n",
        "CHAPTER_WITH_BEATS_PROMPT = PromptTemplate(\n",
        "    input_variables=[\"title\",\"description\",\"idea\",\"plan\",\"themes\",\"sensory_palette\",\"dialogue_target\",\"worldbrief\"],\n",
        "    template=(\n",
        "\"\"\"Write a ~2200â€“3200 word chapter titled \"{title}\".\n",
        "Seed idea: {idea}\n",
        "Mini-brief: {description}\n",
        "Plan (beats): {plan}\n",
        "Context to weave subtly (no info-dumps; show, don't tell): {worldbrief}\n",
        "\n",
        "Must do:\n",
        "- Open with a punchy 1â€“2 sentence hook.\n",
        "- Emphasize SENSORY PALETTE: {sensory_palette}\n",
        "- Aim for DIALOGUE DENSITY â‰ˆ {dialogue_target:.2f}.\n",
        "- Integrate 1 motif/prop from the plan naturally.\n",
        "- Midpoint reversal that reframes stakes.\n",
        "- End with a plausible cliffhanger/stinger.\n",
        "\n",
        "Style: concrete details, crisp verbs; avoid clichÃ©s; maintain POV & continuity.\n",
        "Themes to reinforce: {themes}\n",
        "Return TEXT ONLY.\n",
        "\"\"\"))\n",
        "\n",
        "chapter_prompt = PromptTemplate(\n",
        "    input_variables=[\"title\",\"description\",\"idea\"],\n",
        "    template=(\n",
        "\"\"\"Write a ~2200â€“3200 word chapter titled \"{title}\".\n",
        "Seed idea: {idea}\n",
        "Chapter description: \"{description}\"\n",
        "(If WORLD BRIEF is present in your system prompt, weave it subtly.)\n",
        "Return TEXT ONLY.\n",
        "\"\"\"))\n",
        "\n",
        "REVISION_PROMPT = PromptTemplate(\n",
        "    input_variables=[\"chapter\",\"title\",\"description\",\"ledger\"],\n",
        "    template=(\n",
        "\"\"\"Revise to reduce repetition with earlier chapters while improving novelty and tension.\n",
        "Keep continuity; change micro-beats and setting details.\n",
        "- Add one fresh obstacle, one specific sensory detail, one plausible surprise.\n",
        "Return TEXT ONLY.\n",
        "\n",
        "Title: {title}\n",
        "Description: {description}\n",
        "Do-not-repeat ledger: {ledger}\n",
        "Chapter draft:\n",
        "{chapter}\n",
        "\"\"\"))\n",
        "\n",
        "EVAL_PROMPT = PromptTemplate(\n",
        "    input_variables=[\"chapter\"],\n",
        "    template=(\n",
        "\"\"\"You are a tough fiction editor. Rate the chapter (1â€“10) on:\n",
        "pacing, tension, voice, imagery, dialogue, novelty.\n",
        "Return STRICT JSON only:\n",
        "{{\"scores\":{{\"pacing\":x,\"tension\":x,\"voice\":x,\"imagery\":x,\"dialogue\":x,\"novelty\":x}},\n",
        " \"one_sentence_note\":\"...\", \"three_micro_edits\":[\"...\",\"...\",\"...\"]}}\n",
        "Chapter:\n",
        "{chapter}\n",
        "\"\"\"))\n",
        "\n",
        "PUNCHUP_PROMPT = PromptTemplate(\n",
        "    input_variables=[\"chapter\",\"edits\"],\n",
        "    template=(\n",
        "\"\"\"Apply these micro-edits without changing plot:\n",
        "- {edits}\n",
        "Keep length Â±10%. Add concrete sensory details. Remove clichÃ©s.\n",
        "Return TEXT ONLY.\n",
        "\n",
        "Chapter:\n",
        "{chapter}\n",
        "\"\"\"))\n",
        "\n",
        "DIALOGUE_TUNER_PROMPT = PromptTemplate(\n",
        "    input_variables=[\"chapter\",\"target\"],\n",
        "    template=(\n",
        "\"\"\"Revise chapter to adjust dialogue density to â‰ˆ {target:.2f} (Â±0.08).\n",
        "Keep plot and beats intact. Length change â‰¤10%.\n",
        "Return TEXT ONLY.\n",
        "\n",
        "Chapter:\n",
        "{chapter}\n",
        "\"\"\"))\n",
        "\n",
        "DECLICHE_PROMPT = PromptTemplate(\n",
        "    input_variables=[\"chapter\"],\n",
        "    template=(\n",
        "\"\"\"Line-edit to remove clichÃ©s and filler. Replace with specific, concrete imagery.\n",
        "Preserve plot, POV, beats, and length (Â±5%). Return TEXT ONLY.\n",
        "\n",
        "Chapter:\n",
        "{chapter}\n",
        "\"\"\"))\n",
        "\n",
        "MOTIF_MINER_PROMPT = PromptTemplate(\n",
        "    input_variables=[\"chapter\"],\n",
        "    template=(\n",
        "\"\"\"Extract 1â€“3 recurring motifs/props/images (short noun phrases).\n",
        "Return STRICT JSON: {{\"motifs\":[\"...\"]}}\n",
        "Chapter:\n",
        "{chapter}\n",
        "\"\"\"))\n",
        "\n",
        "BLURB_PROMPT = PromptTemplate(\n",
        "    input_variables=[\"title\",\"logline\",\"themes\",\"promises\"],\n",
        "    template=(\n",
        "\"\"\"Write STRICT JSON:\n",
        "{{\"blurb\":\"(120â€“160 words)\",\"product_hook\":\"(1 sentence)\",\"snippets\":[\"...\",\"...\",\"...\"]}}\n",
        "Title: {title}\n",
        "Logline: {logline}\n",
        "Themes: {themes}\n",
        "Promises: {promises}\n",
        "\"\"\"))\n",
        "\n",
        "# Build chains\n",
        "outline_chain_json_planner  = OUTLINE_JSON_PROMPT   | planner_llm_json\n",
        "outline_chain_ndjson_plan   = OUTLINE_NDJSON_PROMPT | planner_llm\n",
        "outline_chain_ndjson_writer = OUTLINE_NDJSON_PROMPT | writer_llm\n",
        "character_chain_json        = CHAR_JSON_PROMPT      | planner_llm_json\n",
        "theme_chain                 = THEME_PROMPT          | planner_llm\n",
        "beats_chain                 = BEATS_PROMPT          | planner_llm\n",
        "chapter_beats_llm           = CHAPTER_WITH_BEATS_PROMPT | writer_llm\n",
        "chapter_chain               = chapter_prompt        | writer_llm\n",
        "revision_chain              = REVISION_PROMPT       | writer_llm\n",
        "eval_chain                  = EVAL_PROMPT           | planner_llm\n",
        "punchup_chain               = PUNCHUP_PROMPT        | writer_llm\n",
        "dialogue_tuner              = DIALOGUE_TUNER_PROMPT | writer_llm\n",
        "decliche_chain              = DECLICHE_PROMPT       | writer_llm\n",
        "motif_miner                 = MOTIF_MINER_PROMPT    | planner_llm\n",
        "blurb_chain                 = BLURB_PROMPT          | planner_llm\n",
        "\n",
        "# Counterfactual scaffolder (for HRC presidency)\n",
        "COUNTERFACTUAL_PROMPT = PromptTemplate(\n",
        "    input_variables=[\"history_brief\",\"premise\"],\n",
        "    template=(\n",
        "\"\"\"Based on this real history brief:\\n{history_brief}\\n\\n\n",
        "Propose 10 plausible DIVERGENCE POINTS if Hillary Clinton had won in 2016.\n",
        "For each: {{ \"title\": \"...\", \"what_changes\": \"...\", \"downstream_ripples\": \"...\", \"conflicts\": [\"...\",\"...\"] }}\n",
        "Return a STRICT JSON array of 10 items only.\n",
        "Premise: {premise}\n",
        "\"\"\"))\n",
        "counterfactual_chain = COUNTERFACTUAL_PROMPT | planner_llm_json\n",
        "\n",
        "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
        "# 4) Utilities: parsing, similarity, checkpoints, etc.\n",
        "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
        "THINK_RE = re.compile(r\"<think>.*?</think>\\s*\", flags=re.S|re.I)\n",
        "FENCE_RE = re.compile(r\"```(?:json)?|```\", flags=re.I)\n",
        "\n",
        "def strip_think(x: Any) -> str:\n",
        "    s = x[\"text\"] if isinstance(x, dict) and \"text\" in x else str(x)\n",
        "    s = THINK_RE.sub(\"\", s); s = FENCE_RE.sub(\"\", s)\n",
        "    return s.strip()\n",
        "\n",
        "def parse_json_value(s: str):\n",
        "    s = strip_think(s)\n",
        "    m = re.search(r\"(\\{.*\\}|\\[.*\\])\\s*$\", s, flags=re.S)\n",
        "    if not m: return None\n",
        "    blob = m.group(1)\n",
        "    try:\n",
        "        return json.loads(blob)\n",
        "    except Exception:\n",
        "        fix = blob.replace(\"â€œ\",\"\\\"\").replace(\"â€\",\"\\\"\").replace(\"â€™\",\"'\")\n",
        "        fix = re.sub(r\",\\s*}\", \"}\", fix); fix = re.sub(r\",\\s*]\", \"]\", fix)\n",
        "        try: return json.loads(fix)\n",
        "        except Exception: return None\n",
        "\n",
        "def parse_strict_json(s: str) -> dict:\n",
        "    obj = parse_json_value(s)\n",
        "    return obj if isinstance(obj, dict) else {}\n",
        "\n",
        "OBJ_RE = re.compile(r\"\\{(?:[^{}]|\\\"[^\\\"\\\\]*(?:\\\\.[^\\\"\\\\]*)*\\\")*\\}\")\n",
        "def extract_json_objects(text: str):\n",
        "    text = strip_think(text); objs = []\n",
        "    for m in OBJ_RE.finditer(text):\n",
        "        blob = m.group(0)\n",
        "        try:\n",
        "            obj = json.loads(blob)\n",
        "            if isinstance(obj, dict): objs.append(obj)\n",
        "        except Exception:\n",
        "            try:\n",
        "                fix = blob.replace(\"â€œ\",\"\\\"\").replace(\"â€\",\"\\\"\").replace(\"â€™\",\"'\")\n",
        "                fix = re.sub(r\",\\s*}\", \"}\", fix)\n",
        "                obj = json.loads(fix)\n",
        "                if isinstance(obj, dict): objs.append(obj)\n",
        "            except Exception: pass\n",
        "    return objs\n",
        "\n",
        "def jaccard(a: str, b: str) -> float:\n",
        "    A = set(re.findall(r\"[a-z0-9']+\", (a or \"\").lower()))\n",
        "    B = set(re.findall(r\"[a-z0-9']+\", (b or \"\").lower()))\n",
        "    if not A or not B: return 0.0\n",
        "    return len(A & B) / len(A | B)\n",
        "\n",
        "# Dedup thresholds â€” slightly relaxed to avoid over-filtering on small models\n",
        "def too_similar_relaxed(ch1: Dict[str,str], ch2: Dict[str,str]) -> bool:\n",
        "    t_sim = jaccard(ch1[\"title\"], ch2[\"title\"])\n",
        "    d_sim = jaccard(ch1[\"description\"], ch2[\"description\"])\n",
        "    return (t_sim > 0.80) or (t_sim > 0.55 and d_sim > 0.62)\n",
        "\n",
        "def bigram_overlap(a: str, b: str) -> float:\n",
        "    def bigrams(s):\n",
        "        toks = re.findall(r\"[a-z0-9']+\", (s or \"\").lower())\n",
        "        return set(zip(toks, toks[1:])) if len(toks) > 1 else set()\n",
        "    A, B = bigrams(a), bigrams(b)\n",
        "    denom = len(A | B) if (A or B) else 1\n",
        "    return len(A & B) / denom\n",
        "\n",
        "def top_trigrams(text: str, k: int = 30) -> List[str]:\n",
        "    toks = re.findall(r\"[a-z0-9']+\", (text or \"\").lower())\n",
        "    tris = Counter(zip(toks, toks[1:], toks[2:]))\n",
        "    return [\" \".join(t) for t,_ in tris.most_common(k)]\n",
        "\n",
        "def approx_dialogue_ratio(text: str) -> float:\n",
        "    lines = [ln.strip() for ln in (text or \"\").splitlines() if ln.strip()]\n",
        "    if not lines: return 0.0\n",
        "    dial = sum(1 for ln in lines if re.search(r'[\"â€œâ€]|^â€”', ln))\n",
        "    return dial / max(1, len(lines))\n",
        "\n",
        "def word_count(text: str) -> int:\n",
        "    return len(re.findall(r\"[A-Za-z0-9']+\", text or \"\"))\n",
        "\n",
        "def _slug(s):\n",
        "    return re.sub(r\"[^a-z0-9]+\", \"-\", s.lower()).strip(\"-\")[:60]\n",
        "\n",
        "def _ck_paths(i, title):\n",
        "    base = f\"{i:03d}-{_slug(title)}\"\n",
        "    p = pathlib.Path(CHECKPOINT_DIR)\n",
        "    return p / (base + \".txt\"), p / (base + \".json\")\n",
        "\n",
        "def save_ckpt(i, title, text, notes):\n",
        "    p_txt, p_meta = _ck_paths(i, title)\n",
        "    p_txt.write_text(text or \"\", encoding=\"utf-8\")\n",
        "    meta = {\"chapter_index\": i, \"title\": title, \"notes\": notes}\n",
        "    p_meta.write_text(json.dumps(meta, ensure_ascii=False, indent=2), encoding=\"utf-8\")\n",
        "\n",
        "def load_ckpt_if_any(i, title):\n",
        "    p_txt, p_meta = _ck_paths(i, title)\n",
        "    if p_txt.exists():\n",
        "        text = p_txt.read_text(encoding=\"utf-8\")\n",
        "        notes = None\n",
        "        if p_meta.exists():\n",
        "            try: notes = json.loads(p_meta.read_text(encoding=\"utf-8\"))\n",
        "            except Exception: notes = None\n",
        "        return text, notes\n",
        "    return None, None\n",
        "\n",
        "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
        "# 5) Research Agent: ddgs + trafilatura â†’ History Brief JSON/MD\n",
        "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
        "try:\n",
        "    from ddgs import DDGS   # new package name\n",
        "except Exception:\n",
        "    from duckduckgo_search import DDGS  # fallback\n",
        "\n",
        "import trafilatura\n",
        "\n",
        "def ddg_text(q: str, max_results=6):\n",
        "    with DDGS() as ddgs:\n",
        "        return list(ddgs.text(q, max_results=max_results, region=\"us-en\", safesearch=\"moderate\"))\n",
        "\n",
        "def ddg_news(q: str, max_results=6):\n",
        "    with DDGS() as ddgs:\n",
        "        return list(ddgs.news(q, max_results=max_results, region=\"us-en\", safesearch=\"moderate\"))\n",
        "\n",
        "def fetch_clean(url: str, timeout=20_000) -> str:\n",
        "    try:\n",
        "        downloaded = trafilatura.fetch_url(url, timeout=timeout)\n",
        "        if not downloaded: return \"\"\n",
        "        text = trafilatura.extract(downloaded, include_comments=False, include_tables=False, no_fallback=False)\n",
        "        return text or \"\"\n",
        "    except Exception:\n",
        "        return \"\"\n",
        "\n",
        "def research_pack(topic: str, seed_queries: List[str], per_query=4) -> Dict[str, Any]:\n",
        "    print(\"ğŸ” Research agent: collecting sourcesâ€¦\")\n",
        "    hits = []\n",
        "    for q in seed_queries:\n",
        "        try:\n",
        "            hits.extend(ddg_text(q, max_results=per_query))\n",
        "        except Exception:\n",
        "            continue\n",
        "    # Deduplicate by URL\n",
        "    seen = set(); hits2 = []\n",
        "    for h in hits:\n",
        "        url = h.get(\"href\") or h.get(\"url\")\n",
        "        if not url or url in seen: continue\n",
        "        seen.add(url); hits2.append({\"title\": h.get(\"title\",\"\"), \"url\": url})\n",
        "\n",
        "    docs = []\n",
        "    for h in tqdm(hits2[:22], desc=\"Fetching\"):\n",
        "        txt = fetch_clean(h[\"url\"])\n",
        "        if not txt: continue\n",
        "        docs.append({\"title\": h[\"title\"], \"url\": h[\"url\"], \"text\": txt[:120000]})\n",
        "\n",
        "    if not docs:\n",
        "        return {\"topic\": topic, \"facts\": [], \"timeline\": [], \"citations\": [], \"summary\": \"\"}\n",
        "\n",
        "    # Summarize with the planner (JSON)\n",
        "    SUMM_PROMPT = PromptTemplate(\n",
        "        input_variables=[\"topic\",\"docs\"],\n",
        "        template=(\n",
        "\"\"\"You are an impartial researcher. From these sources, produce STRICT JSON:\n",
        "{{\n",
        " \"facts\": [\"...\"],                       # 12â€“18 atomic, dated facts\n",
        " \"timeline\": [{{\"date\":\"YYYY-MM\",\"event\":\"...\",\"why_it_matters\":\"...\"}}, ...],  # 10â€“14 items\n",
        " \"policy_buckets\": {{\n",
        "   \"economy_tax\":\"...\", \"immigration\":\"...\", \"trade\":\"...\", \"foreign_policy\":\"...\", \"covid\":\"...\", \"justice_impeachments\":\"...\"\n",
        " }},\n",
        " \"summary\": \"(200â€“280 words, neutral)\",\n",
        " \"citations\": [{{\"title\":\"...\",\"url\":\"...\"}}, ...]  # 10â€“16 items\n",
        "}}\n",
        "Topic: {topic}\n",
        "Sources (title + excerpts): {docs}\n",
        "\"\"\"))\n",
        "    chain = SUMM_PROMPT | planner_llm_json\n",
        "    doc_blurbs = [{\"title\": d[\"title\"], \"url\": d[\"url\"], \"snippet\": (d[\"text\"][:1000] + (\"â€¦\" if len(d[\"text\"])>1000 else \"\"))} for d in docs[:14]]\n",
        "    raw = chain.invoke({\"topic\": topic, \"docs\": json.dumps(doc_blurbs, ensure_ascii=False)})\n",
        "    data = parse_json_value(raw) or {}\n",
        "    data.setdefault(\"citations\", [])\n",
        "    for d in doc_blurbs:\n",
        "        if not any(c.get(\"url\")==d[\"url\"] for c in data[\"citations\"]):\n",
        "            data[\"citations\"].append({\"title\": d[\"title\"], \"url\": d[\"url\"]})\n",
        "    return data\n",
        "\n",
        "def brief_to_md(brief: Dict[str,Any]) -> str:\n",
        "    lines = [f\"# Research Brief: {brief.get('topic','')}\", \"\"]\n",
        "    if brief.get(\"summary\"):\n",
        "        lines += [\"## Summary\", brief[\"summary\"], \"\"]\n",
        "    if brief.get(\"timeline\"):\n",
        "        lines += [\"## Timeline\"]\n",
        "        for t in brief[\"timeline\"]:\n",
        "            lines.append(f\"- **{t.get('date','')}** â€” {t.get('event','')} â€” _{t.get('why_it_matters','')}_\")\n",
        "        lines.append(\"\")\n",
        "    if brief.get(\"policy_buckets\"):\n",
        "        lines += [\"## Policy Buckets\"]\n",
        "        for k,v in brief[\"policy_buckets\"].items():\n",
        "            lines.append(f\"- **{k}**: {v}\")\n",
        "        lines.append(\"\")\n",
        "    if brief.get(\"facts\"):\n",
        "        lines += [\"## Facts\"]\n",
        "        for f in brief[\"facts\"][:20]:\n",
        "            lines.append(f\"- {f}\")\n",
        "        lines.append(\"\")\n",
        "    if brief.get(\"citations\"):\n",
        "        lines += [\"## Sources\"]\n",
        "        for c in brief[\"citations\"][:20]:\n",
        "            lines.append(f\"- [{c.get('title','source')}]({c.get('url','')})\")\n",
        "    return \"\\n\".join(lines)\n",
        "\n",
        "DEFAULT_TRUMP_QUERIES = [\n",
        "    \"Presidency of Donald Trump 2017 2021 summary\",\n",
        "    \"Tax Cuts and Jobs Act 2017 summary site:wikipedia.org\",\n",
        "    \"Executive Order 13769 travel ban summary\",\n",
        "    \"USMCA enters into force July 1 2020 site:ustr.gov\",\n",
        "    \"First impeachment of Donald Trump 2019 summary\",\n",
        "    \"Second impeachment of Donald Trump 2021 summary\",\n",
        "    \"COVID-19 response CARES Act March 2020 CRS summary site:crsreports.congress.gov\",\n",
        "    \"Operation Warp Speed overview site:gao.gov\"\n",
        "]\n",
        "\n",
        "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
        "# 6) Booster-grade OUTLINE generator (JSONâ†’NDJSON; plannerâ†’writer; avoid lists)\n",
        "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
        "def clean_outline_items(items):\n",
        "    out = []\n",
        "    for obj in items:\n",
        "        if not isinstance(obj, dict): continue\n",
        "        title = (obj.get(\"title\") or \"\").strip()\n",
        "        desc  = (obj.get(\"description\") or \"\").strip()\n",
        "        if title and desc: out.append({\"title\": title, \"description\": desc})\n",
        "    return out\n",
        "\n",
        "def robust_outline_batch(topic: str, ask: int, avoid_titles: List[str], avoid_phrases: List[str]):\n",
        "    vseed = random.randint(10_000, 999_999)\n",
        "    payload = {\n",
        "        \"topic\": topic,\n",
        "        \"count\": ask,\n",
        "        \"avoid_titles\": \", \".join(sorted(set(avoid_titles))[:50]),\n",
        "        \"avoid_phrases\": \", \".join(sorted(set(avoid_phrases))[:50]),\n",
        "        \"vseed\": vseed,\n",
        "    }\n",
        "    # Planner JSON\n",
        "    try:\n",
        "        raw = outline_chain_json_planner.invoke(payload)\n",
        "        arr = parse_json_value(raw)\n",
        "        if isinstance(arr, list) and arr:\n",
        "            print(\"   âœ“ planner JSON\")\n",
        "            return clean_outline_items(arr)\n",
        "        objs = extract_json_objects(str(raw))\n",
        "        if objs:\n",
        "            print(\"   âœ“ planner JSON (rescued)\")\n",
        "            return clean_outline_items(objs)\n",
        "    except Exception as e:\n",
        "        print(f\"   Â· planner JSON failed: {e}\")\n",
        "    # Planner NDJSON\n",
        "    try:\n",
        "        raw = outline_chain_ndjson_plan.invoke(payload)\n",
        "        lines = [ln for ln in strip_think(raw).splitlines() if ln.strip()]\n",
        "        objs = []\n",
        "        for ln in lines:\n",
        "            try: objs.append(json.loads(ln))\n",
        "            except Exception:\n",
        "                fix = ln.replace(\"â€œ\",\"\\\"\").replace(\"â€\",\"\\\"\").replace(\"â€™\",\"'\")\n",
        "                fix = re.sub(r\",\\s*}\", \"}\", fix)\n",
        "                try: objs.append(json.loads(fix))\n",
        "                except Exception: pass\n",
        "        if objs:\n",
        "            print(\"   âœ“ planner NDJSON\")\n",
        "            return clean_outline_items(objs)\n",
        "    except Exception as e:\n",
        "        print(f\"   Â· planner NDJSON failed: {e}\")\n",
        "    # Writer NDJSON\n",
        "    try:\n",
        "        raw = outline_chain_ndjson_writer.invoke(payload)\n",
        "        lines = [ln for ln in strip_think(raw).splitlines() if ln.strip()]\n",
        "        objs = []\n",
        "        for ln in lines:\n",
        "            try: objs.append(json.loads(ln))\n",
        "            except Exception:\n",
        "                fix = ln.replace(\"â€œ\",\"\\\"\").replace(\"â€\",\"\\\"\").replace(\"â€™\",\"'\")\n",
        "                fix = re.sub(r\",\\s*}\", \"}\", fix)\n",
        "                try: objs.append(json.loads(fix))\n",
        "                except Exception: pass\n",
        "        if objs:\n",
        "            print(\"   âœ“ writer NDJSON\")\n",
        "            return clean_outline_items(objs)\n",
        "    except Exception as e:\n",
        "        print(f\"   Â· writer NDJSON failed: {e}\")\n",
        "    # Writer JSON last\n",
        "    try:\n",
        "        raw = (OUTLINE_JSON_PROMPT | writer_llm).invoke(payload)\n",
        "        arr = parse_json_value(raw)\n",
        "        if isinstance(arr, list) and arr:\n",
        "            print(\"   âœ“ writer JSON\")\n",
        "            return clean_outline_items(arr)\n",
        "        objs = extract_json_objects(str(raw))\n",
        "        if objs:\n",
        "            print(\"   âœ“ writer JSON (rescued)\")\n",
        "            return clean_outline_items(objs)\n",
        "    except Exception as e:\n",
        "        print(f\"   Â· writer JSON failed: {e}\")\n",
        "    # Stub fallback\n",
        "    print(\"   âš ï¸ stub fallback\")\n",
        "    TEMPLATES = [\n",
        "        (\"First 100 Days, Rewired\", \"A new administration rewrites norms; a misread memo sets up the seasonâ€™s first conflict.\"),\n",
        "        (\"The Unseen Docket\", \"A Supreme Court vacancy collides with backchannel promises and an ethics snag.\"),\n",
        "        (\"Trade Winds\", \"Tariffs, treaties, and a leak force an unlikely coalition to formâ€”or fracture.\"),\n",
        "        (\"Outbreak Narratives\", \"A public-health rehearsal becomes real; data, politics, and trust fall out of sync.\"),\n",
        "        (\"Backchannel Summit\", \"A surprise foreign breakthrough carries a personal cost that ricochets at home.\"),\n",
        "        (\"Platform Immunities\", \"A tech-policy skirmish pulls private lives into the open, with legal fallout.\"),\n",
        "        (\"Counting Rooms\", \"An election-year rule change triggers a chain of unintended consequences.\")\n",
        "    ]\n",
        "    random.shuffle(TEMPLATES)\n",
        "    return [{\"title\": t, \"description\": d} for t,d in TEMPLATES[:ask]]\n",
        "\n",
        "print(f\"â†’ Generating {NUM_CH}-chapter outline (booster mode) â€¦\")\n",
        "outline, seen_titles = [], set()\n",
        "needed = NUM_CH\n",
        "chunk = 3\n",
        "attempts, MAX_ATTEMPTS = 0, 60\n",
        "stalled = 0\n",
        "\n",
        "while len(outline) < needed and attempts < MAX_ATTEMPTS:\n",
        "    attempts += 1\n",
        "    ask = min(chunk, needed - len(outline))\n",
        "    avoid_titles = list(seen_titles)\n",
        "    recent_phrases = []\n",
        "    for it in outline[-12:]:\n",
        "        recent_phrases.extend(top_trigrams(it.get(\"description\",\"\"), k=6))\n",
        "    batch = robust_outline_batch(SEED_IDEA, ask, avoid_titles, recent_phrases)\n",
        "    added = 0\n",
        "    for ch in batch:\n",
        "        if not ch[\"title\"] or not ch[\"description\"]:\n",
        "            continue\n",
        "        if ch[\"title\"] in seen_titles:\n",
        "            continue\n",
        "        if any(too_similar_relaxed(ch, e) for e in outline):\n",
        "            continue\n",
        "        outline.append(ch)\n",
        "        seen_titles.add(ch[\"title\"])\n",
        "        added += 1\n",
        "        if len(outline) >= needed:\n",
        "            break\n",
        "    print(f\"   â†’ accepted {added}; total now {len(outline)}/{needed}\")\n",
        "    if added == 0:\n",
        "        stalled += 1\n",
        "        if stalled >= 6:\n",
        "            # relax dedupe and push stubs\n",
        "            print(\"   Â· stalled; relaxing filter and adding stub seeds\")\n",
        "            while len(outline) < needed and len(batch) > 0:\n",
        "                ch = batch.pop()\n",
        "                title = (ch.get(\"title\") or f\"Thread {len(outline)+1}\").strip()\n",
        "                desc  = (ch.get(\"description\") or \"An escalated conflict reframes stakes.\").strip()\n",
        "                if title in seen_titles: title += f\" #{random.randint(10,99)}\"\n",
        "                outline.append({\"title\": title, \"description\": desc})\n",
        "                seen_titles.add(title)\n",
        "            stalled = 0\n",
        "    else:\n",
        "        stalled = 0\n",
        "\n",
        "print(f\"âœ” Final outline: {len(outline)} chapters\\n\")\n",
        "if len(outline) < needed:\n",
        "    print(\"âš ï¸ Could not reach target; proceeding with what we have.\")\n",
        "\n",
        "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
        "# 7) Characters + Theme/Motif Bible\n",
        "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
        "def robust_characters(outline_list, n_chars):\n",
        "    try:\n",
        "        raw = character_chain_json.invoke({\"outline\": json.dumps(outline_list, ensure_ascii=False),\n",
        "                                           \"num_chars\": n_chars})\n",
        "        arr = parse_json_value(raw)\n",
        "        if isinstance(arr, list) and len(arr) >= min(3, n_chars//2):\n",
        "            return [c for c in arr if isinstance(c, dict)][:n_chars]\n",
        "    except Exception: pass\n",
        "    try:\n",
        "        raw = (CHAR_JSON_PROMPT | writer_llm).invoke({\"outline\": json.dumps(outline_list, ensure_ascii=False),\n",
        "                                                      \"num_chars\": n_chars})\n",
        "        arr = parse_json_value(raw)\n",
        "        if isinstance(arr, list) and len(arr) >= min(3, n_chars//2):\n",
        "            return [c for c in arr if isinstance(c, dict)][:n_chars]\n",
        "    except Exception: pass\n",
        "    return [\n",
        "        {\"name\":\"Alex Vega\",\"role\":\"Chief of Staff\",\"development_arc\":\"From risk-averse gatekeeper to bold coalition-builder.\"},\n",
        "        {\"name\":\"Ruth Delgado\",\"role\":\"Solicitor General\",\"development_arc\":\"Learns to balance principle with political reality.\"},\n",
        "        {\"name\":\"Jonah Price\",\"role\":\"Data Journalist\",\"development_arc\":\"Truth-telling collides with personal loyalties.\"},\n",
        "    ][:n_chars]\n",
        "\n",
        "NUM_CHAR = max(3, min(10, len(outline)//8))\n",
        "print(f\"â†’ Generating {NUM_CHAR} charactersâ€¦\")\n",
        "characters = robust_characters(outline, NUM_CHAR)\n",
        "print(f\"âœ” Got {len(characters)} characters\\n\")\n",
        "\n",
        "print(\"â†’ Building theme/motif bibleâ€¦\")\n",
        "THEME_BIBLE = parse_strict_json(theme_chain.invoke({\n",
        "    \"topic\": SEED_IDEA,\n",
        "    \"outline\": json.dumps(outline, ensure_ascii=False)\n",
        "})) or {\"themes\":[],\"motifs\":[],\"promises\":[],\"logline\":\"\",\"genre_signals\":[]}\n",
        "MOTIF_LEDGER = list(THEME_BIBLE.get(\"motifs\", []))\n",
        "print(\"âœ” Theme bible ready.\\n\")\n",
        "\n",
        "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
        "# 8) Run Research Agent (if enabled) â†’ History Brief + Counterfactual seeds\n",
        "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
        "WORLD_BRIEF = \"\"\n",
        "COUNTERFACTUAL_POINTS = []\n",
        "if RESEARCH_AGENT_ENABLED:\n",
        "    brief = research_pack(\n",
        "        topic=\"U.S. Presidency 2017â€“2021 baseline for counterfactual (HRC wins 2016).\",\n",
        "        seed_queries=DEFAULT_TRUMP_QUERIES, per_query=4\n",
        "    )\n",
        "    # Save brief\n",
        "    pathlib.Path(\"research\").mkdir(exist_ok=True)\n",
        "    with open(\"research/history_brief.json\",\"w\",encoding=\"utf-8\") as f:\n",
        "        json.dump(brief, f, ensure_ascii=False, indent=2)\n",
        "    md = brief_to_md(brief)\n",
        "    pathlib.Path(\"research/history_brief.md\").write_text(md, encoding=\"utf-8\")\n",
        "    print(\"ğŸ§¾ Saved research/history_brief.{json,md}\")\n",
        "\n",
        "    # Compact bullets for prompts\n",
        "    bullets = []\n",
        "    for t in (brief.get(\"timeline\") or [])[:10]:\n",
        "        bullets.append(f\"{t.get('date','')}: {t.get('event','')}\")\n",
        "    if not bullets and brief.get(\"facts\"):\n",
        "        bullets = (brief[\"facts\"])[:10]\n",
        "    WORLD_BRIEF = \" | \".join(bullets)[:1200]\n",
        "\n",
        "    # Counterfactual divergence points (robustly normalized)\n",
        "    cf_raw = counterfactual_chain.invoke({\n",
        "        \"history_brief\": md[:6000],\n",
        "        \"premise\": \"Hillary Clinton wins 2016; explore plausible policy and geopolitical divergences 2017â€“2021.\"\n",
        "    })\n",
        "    parsed = parse_json_value(cf_raw)\n",
        "    # Normalizer: accept list of dicts or list of strings; coerce to dict skeletons\n",
        "    COUNTERFACTUAL_POINTS = []\n",
        "    if isinstance(parsed, list):\n",
        "        for item in parsed:\n",
        "            if isinstance(item, dict):\n",
        "                title = str(item.get(\"title\",\"\")).strip() or \"Divergence\"\n",
        "                what  = str(item.get(\"what_changes\",\"\")).strip() or \"A plausible shift in policy or personnel.\"\n",
        "                rip   = str(item.get(\"downstream_ripples\",\"\")).strip() or \"Cascading effects across agencies and geopolitics.\"\n",
        "                confs = item.get(\"conflicts\", [])\n",
        "                if not isinstance(confs, list): confs = [str(confs)]\n",
        "                COUNTERFACTUAL_POINTS.append({\n",
        "                    \"title\": title, \"what_changes\": what,\n",
        "                    \"downstream_ripples\": rip, \"conflicts\": [str(c) for c in confs][:3]\n",
        "                })\n",
        "            elif isinstance(item, str):\n",
        "                title = item.strip()\n",
        "                if title:\n",
        "                    COUNTERFACTUAL_POINTS.append({\n",
        "                        \"title\": title,\n",
        "                        \"what_changes\": \"Policy emphasis and staffing differ; agendas and committee priorities shift.\",\n",
        "                        \"downstream_ripples\": \"Budget allocations, diplomatic posture, and regulatory timelines diverge.\",\n",
        "                        \"conflicts\": [\"Institutional pushback\", \"Media battles\", \"Coalition fractures\"]\n",
        "                    })\n",
        "    # If still empty, fabricate 10 skeletons so DOCX never crashes\n",
        "    if not COUNTERFACTUAL_POINTS:\n",
        "        COUNTERFACTUAL_POINTS = [{\n",
        "            \"title\": f\"Divergence #{i+1}\",\n",
        "            \"what_changes\": \"Course correction on a key agenda item.\",\n",
        "            \"downstream_ripples\": \"Knock-on effects across agencies and allies.\",\n",
        "            \"conflicts\": [\"Stakeholder backlash\",\"Legal hurdles\",\"Messaging wars\"]\n",
        "        } for i in range(10)]\n",
        "else:\n",
        "    print(\"â„¹ï¸ Research agent disabled; continuing without WORLD_BRIEF.\")\n",
        "\n",
        "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
        "# 9) Chapter Generation (beats â†’ draft â†’ eval/polish) + checkpointing\n",
        "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
        "print(\"â†’ Generating chaptersâ€¦\")\n",
        "chap_texts = [None]*len(outline)\n",
        "editor_notes = [None]*len(outline)\n",
        "BIGRAM_THRESHOLD = 0.22\n",
        "\n",
        "def write_one(idx):\n",
        "    meta = outline[idx]\n",
        "    title = meta[\"title\"]\n",
        "\n",
        "    # Resume if cached\n",
        "    cached_txt, cached_notes = load_ckpt_if_any(idx, title)\n",
        "    if cached_txt:\n",
        "        return cached_txt, cached_notes\n",
        "\n",
        "    # Plan beats (with world brief if available)\n",
        "    plan = parse_strict_json(beats_chain.invoke({\n",
        "        \"title\": meta[\"title\"],\n",
        "        \"description\": meta[\"description\"],\n",
        "        \"theme_bible\": json.dumps(THEME_BIBLE, ensure_ascii=False),\n",
        "        \"motif_ledger\": json.dumps(MOTIF_LEDGER[-12:], ensure_ascii=False),\n",
        "        \"worldbrief\": WORLD_BRIEF or \"(none)\"\n",
        "    })) or {}\n",
        "    dialogue_target = float(plan.get(\"dialogue_target_pct\", 0.36))\n",
        "    sensory_palette = plan.get(\"sensory_palette\", [\"sight\",\"sound\"])\n",
        "    plan_json = json.dumps(plan.get(\"beats\", []), ensure_ascii=False)\n",
        "\n",
        "    # Draft\n",
        "    res = chapter_beats_llm.invoke({\n",
        "        \"title\": meta[\"title\"],\n",
        "        \"description\": meta[\"description\"],\n",
        "        \"idea\": SEED_IDEA,\n",
        "        \"plan\": plan_json,\n",
        "        \"themes\": \", \".join(THEME_BIBLE.get(\"themes\", [])),\n",
        "        \"sensory_palette\": \", \".join(sensory_palette),\n",
        "        \"dialogue_target\": dialogue_target,\n",
        "        \"worldbrief\": WORLD_BRIEF or \"(none)\"\n",
        "    })\n",
        "    chapter_txt = strip_think(res)\n",
        "\n",
        "    # Repetition guard\n",
        "    ledger = []\n",
        "    for j in range(idx):\n",
        "        prev = chap_texts[j]\n",
        "        if not prev: continue\n",
        "        if bigram_overlap(chapter_txt, prev) > BIGRAM_THRESHOLD:\n",
        "            ledger.extend(top_trigrams(prev, k=10))\n",
        "    ledger = list(dict.fromkeys(ledger))[:60]\n",
        "    if ledger:\n",
        "        chapter_txt = strip_think(revision_chain.invoke({\n",
        "            \"chapter\": chapter_txt,\n",
        "            \"title\": meta[\"title\"],\n",
        "            \"description\": meta[\"description\"],\n",
        "            \"ledger\": \"; \".join(ledger)\n",
        "        }))\n",
        "\n",
        "    # Evaluation + conditional polish\n",
        "    data = None\n",
        "    try:\n",
        "        report_txt = strip_think(eval_chain.invoke({\"chapter\": chapter_txt}))\n",
        "        m = re.search(r\"\\{[\\s\\S]*\\}\\s*$\", report_txt)\n",
        "        if m:\n",
        "            data = json.loads(m.group(0))\n",
        "        if data and \"scores\" in data:\n",
        "            scores = data[\"scores\"]\n",
        "            avg = sum(float(scores[k]) for k in scores)/len(scores)\n",
        "            dr = approx_dialogue_ratio(chapter_txt)\n",
        "            if abs(dr - dialogue_target) > 0.10:\n",
        "                chapter_txt = strip_think(dialogue_tuner.invoke({\"chapter\": chapter_txt, \"target\": dialogue_target}))\n",
        "            if (avg < 7.6) or (not FAST_MODE):\n",
        "                chapter_txt = strip_think(decliche_chain.invoke({\"chapter\": chapter_txt}))\n",
        "            if avg < 7.4:\n",
        "                edits = \" | \".join(data.get(\"three_micro_edits\", [])) or \"Sharpen hook; escalate midpoint; add concrete sensory beats.\"\n",
        "                chapter_txt = strip_think(punchup_chain.invoke({\"chapter\": chapter_txt, \"edits\": edits}))\n",
        "    except Exception:\n",
        "        data = None\n",
        "\n",
        "    # Mine motifs\n",
        "    try:\n",
        "        mined = parse_strict_json(motif_miner.invoke({\"chapter\": chapter_txt})) or {}\n",
        "        for m in (mined.get(\"motifs\") or []):\n",
        "            if m not in MOTIF_LEDGER: MOTIF_LEDGER.append(m)\n",
        "    except Exception: pass\n",
        "\n",
        "    save_ckpt(idx, title, chapter_txt, data)\n",
        "    return chapter_txt, data\n",
        "\n",
        "# Early calibration on first 3 (serial)\n",
        "PREGEN = min(3, len(outline))\n",
        "for i in range(PREGEN):\n",
        "    ch_txt, notes = write_one(i); chap_texts[i] = ch_txt; editor_notes[i] = notes\n",
        "\n",
        "# Resize outline based on observed words/chapter to hit page target\n",
        "actual_avg = max(500, sum(word_count(chap_texts[i]) for i in range(PREGEN)) // PREGEN)\n",
        "recalc_num_ch = max(12, min(80, (TARGET_WORDS + actual_avg - 1) // actual_avg))\n",
        "# Respect CPU cap\n",
        "if CPU_CHAPTER_CAP and not HAS_GPU:\n",
        "    recalc_num_ch = min(recalc_num_ch, CPU_CHAPTER_CAP)\n",
        "\n",
        "if recalc_num_ch != len(outline):\n",
        "    delta = recalc_num_ch - len(outline)\n",
        "    if delta > 0:\n",
        "        print(f\"ğŸ” Resizing outline: need +{delta} chaptersâ€¦\")\n",
        "        extra = robust_outline_batch(SEED_IDEA, delta, list(seen_titles), [])\n",
        "        for obj in extra:\n",
        "            cand = {\"title\": (obj.get(\"title\") or \"\").strip(),\n",
        "                    \"description\": (obj.get(\"description\") or \"\").strip()}\n",
        "            if not cand[\"title\"] or not cand[\"description\"]: continue\n",
        "            if cand[\"title\"] in seen_titles: continue\n",
        "            if any(too_similar_relaxed(cand, e) for e in outline): continue\n",
        "            outline.append(cand); seen_titles.add(cand[\"title\"])\n",
        "            chap_texts.append(None); editor_notes.append(None)\n",
        "            if len(outline) >= recalc_num_ch: break\n",
        "        print(f\"   â†’ total {len(outline)} chapters after resize\")\n",
        "    elif delta < 0:\n",
        "        keep = max(PREGEN, recalc_num_ch)\n",
        "        outline = outline[:keep]; chap_texts = chap_texts[:keep]; editor_notes = editor_notes[:keep]\n",
        "        print(f\"âœ‚ï¸  Trimmed outline to {len(outline)} chapters\")\n",
        "\n",
        "# Finish remaining chapters\n",
        "remaining_idxs = [i for i, t in enumerate(chap_texts) if t is None]\n",
        "with ThreadPoolExecutor(max_workers=MAX_WORKERS) as ex:\n",
        "    futures = { ex.submit(write_one, i): i for i in remaining_idxs }\n",
        "    for fut in tqdm(as_completed(futures), total=len(futures), desc=\"Chapters\"):\n",
        "        idx = futures[fut]\n",
        "        try:\n",
        "            ch_txt, notes = fut.result()\n",
        "        except Exception as e:\n",
        "            ch_txt, notes = f\"[Generation failed: {e}]\", None\n",
        "        chap_texts[idx] = ch_txt; editor_notes[idx] = notes\n",
        "\n",
        "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
        "# 10) Build DOCX (robust against mixed counterfactual output) + Download\n",
        "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
        "total_words = sum(word_count(t or \"\") for t in chap_texts)\n",
        "est_pages  = total_words / WORDS_PER_PAGE\n",
        "suggested_ch = max(12, min(80, round(total_words / CH_TARGET_WORDS)))\n",
        "print(f\"ğŸ§® Total words: {total_words:,}  â†’ est. pages â‰ˆ {est_pages:.0f}\")\n",
        "print(f\"ğŸ”§ If you rerun, suggested chapters for this style â‰ˆ {suggested_ch}\")\n",
        "\n",
        "doc = docx.Document()\n",
        "doc.add_heading(BOOK_TITLE, 0)\n",
        "doc.add_paragraph(f\"Seed idea: {SEED_IDEA}\")\n",
        "doc.add_paragraph(f\"Estimated pages: ~{est_pages:.0f}\")\n",
        "\n",
        "# Character Bible\n",
        "if characters:\n",
        "    doc.add_page_break()\n",
        "    doc.add_heading(\"Character Development\", level=1)\n",
        "    for c in characters:\n",
        "        name = c.get(\"name\",\"(Unnamed)\")\n",
        "        role = c.get(\"role\",\"\"); arc = c.get(\"development_arc\",\"\")\n",
        "        doc.add_heading(name, level=2)\n",
        "        if role: doc.add_paragraph(f\"Role: {role}\")\n",
        "        if arc:  doc.add_paragraph(arc)\n",
        "\n",
        "# Research Brief\n",
        "if RESEARCH_AGENT_ENABLED and pathlib.Path(\"research/history_brief.md\").exists():\n",
        "    doc.add_page_break()\n",
        "    doc.add_heading(\"Historical Brief (2017â€“2021 Baseline)\", level=1)\n",
        "    md_text = pathlib.Path(\"research/history_brief.md\").read_text(encoding=\"utf-8\")\n",
        "    for para in md_text.splitlines()[:300]:\n",
        "        if para.startswith(\"#\"):\n",
        "            if para.startswith(\"## \"): doc.add_heading(para.replace(\"## \",\"\"), level=2)\n",
        "            elif para.startswith(\"# \"): doc.add_heading(para.replace(\"# \",\"\"), level=1)\n",
        "        elif para.strip():\n",
        "            doc.add_paragraph(para.strip())\n",
        "\n",
        "# Counterfactual Divergence Points (robust loop)\n",
        "if COUNTERFACTUAL_POINTS:\n",
        "    doc.add_page_break()\n",
        "    doc.add_heading(\"Counterfactual: 10 Divergence Points (HRC 2017â€“2021)\", level=1)\n",
        "    for i, d in enumerate(COUNTERFACTUAL_POINTS[:10], 1):\n",
        "        try:\n",
        "            title = d.get(\"title\",\"Divergence\")\n",
        "            what  = d.get(\"what_changes\",\"A plausible shift in policy or personnel.\")\n",
        "            rip   = d.get(\"downstream_ripples\",\"Knock-on effects across agencies and allies.\")\n",
        "            confs = d.get(\"conflicts\", [])\n",
        "        except AttributeError:\n",
        "            # If d is a string, wrap it\n",
        "            title = str(d)\n",
        "            what  = \"Policy emphasis and staffing differ; agendas and committee priorities shift.\"\n",
        "            rip   = \"Budget allocations, diplomatic posture, and regulatory timelines diverge.\"\n",
        "            confs = [\"Institutional pushback\", \"Media battles\", \"Coalition fractures\"]\n",
        "        doc.add_heading(f\"{i}. {title}\", level=2)\n",
        "        doc.add_paragraph(\"What changes: \" + what)\n",
        "        doc.add_paragraph(\"Downstream ripples: \" + rip)\n",
        "        for c in (confs or [])[:3]:\n",
        "            doc.add_paragraph(\"â€¢ \" + str(c))\n",
        "\n",
        "# Chapters\n",
        "for i, (meta, text) in enumerate(zip(outline, chap_texts), start=1):\n",
        "    doc.add_page_break()\n",
        "    doc.add_heading(f\"Chapter {i}: {meta['title']}\", level=1)\n",
        "    doc.add_paragraph(meta['description'], style=\"Intense Quote\")\n",
        "    doc.add_paragraph((text or \"\").strip())\n",
        "\n",
        "# Editorâ€™s Notes\n",
        "doc.add_page_break()\n",
        "doc.add_heading(\"Editorâ€™s Notes (Auto-Eval)\", level=1)\n",
        "for i, (meta, notes) in enumerate(zip(outline, editor_notes), start=1):\n",
        "    doc.add_heading(f\"Chapter {i}: {meta['title']}\", level=2)\n",
        "    if not notes or \"scores\" not in (notes or {}):\n",
        "        doc.add_paragraph(\"No evaluation available.\"); continue\n",
        "    scores = notes[\"scores\"]; one_liner = notes.get(\"one_sentence_note\",\"\")\n",
        "    edits = notes.get(\"three_micro_edits\", [])\n",
        "    try: avg_score = sum(float(scores[k]) for k in scores)/len(scores)\n",
        "    except Exception: avg_score = None\n",
        "    doc.add_paragraph(\"Scores: \" + \", \".join(f\"{k}: {scores[k]}\" for k in scores))\n",
        "    if avg_score is not None: doc.add_paragraph(f\"Average: {avg_score:.2f}\")\n",
        "    if one_liner: doc.add_paragraph(f\"Note: {one_liner}\")\n",
        "    for e in (edits or []): doc.add_paragraph(f\"â€¢ {e}\")\n",
        "\n",
        "# Back-cover copy\n",
        "blurb_data = {}\n",
        "try:\n",
        "    blurb_data = parse_strict_json(blurb_chain.invoke({\n",
        "        \"title\": BOOK_TITLE,\n",
        "        \"logline\": THEME_BIBLE.get(\"logline\",\"\"),\n",
        "        \"themes\": \", \".join(THEME_BIBLE.get(\"themes\", [])),\n",
        "        \"promises\": \", \".join(THEME_BIBLE.get(\"promises\", []))\n",
        "    })) or {}\n",
        "except Exception:\n",
        "    blurb_data = {}\n",
        "\n",
        "doc.add_page_break()\n",
        "doc.add_heading(\"Back-Cover Copy & Retailer Hook\", level=1)\n",
        "if blurb_data.get(\"blurb\"): doc.add_paragraph(blurb_data[\"blurb\"])\n",
        "if blurb_data.get(\"product_hook\"): doc.add_paragraph(f\"\\nRetailer Hook: {blurb_data['product_hook']}\")\n",
        "if blurb_data.get(\"snippets\"):\n",
        "    doc.add_heading(\"Short Social Snippets\", level=2)\n",
        "    for s in blurb_data[\"snippets\"]:\n",
        "        doc.add_paragraph(f\"â€¢ {s}\")\n",
        "\n",
        "# Save & download\n",
        "fn = BOOK_TITLE.replace(\" \", \"_\") + \".docx\"\n",
        "doc.save(fn)\n",
        "print(f\"ğŸ“˜ Saved {fn}\")\n",
        "files.download(fn)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "55Qob5ApkrQo",
        "outputId": "9e67ff9b-124b-4872-ee70-e3cd9aa621f3"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m253.0/253.0 kB\u001b[0m \u001b[31m5.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m22.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m40.7/40.7 kB\u001b[0m \u001b[31m1.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m5.3/5.3 MB\u001b[0m \u001b[31m16.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m837.9/837.9 kB\u001b[0m \u001b[31m24.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m3.3/3.3 MB\u001b[0m \u001b[31m71.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m315.5/315.5 kB\u001b[0m \u001b[31m19.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m274.7/274.7 kB\u001b[0m \u001b[31m17.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hâœ… Ollama health: 200\n",
            "ğŸ–¥ï¸ GPU: not detected\n",
            "âœ” Using model: llama3.2:3b\n",
            "âœ” Using model: llama3.2:3b\n",
            "âš™ï¸ CPU chapter cap active â†’ 24 (was 30)\n",
            "ğŸ¯ Target pages: 320  â†’ target words â‰ˆ 88,000\n",
            "ğŸ“ Chapter target: ~3,000 words â†’ initial chapters: 24\n",
            "â†’ Generating 24-chapter outline (booster mode) â€¦\n",
            "   âœ“ planner JSON (rescued)\n",
            "   â†’ accepted 1; total now 1/24\n",
            "   âœ“ planner JSON (rescued)\n",
            "   â†’ accepted 1; total now 2/24\n",
            "   âœ“ planner JSON (rescued)\n",
            "   â†’ accepted 1; total now 3/24\n",
            "   âœ“ planner JSON (rescued)\n",
            "   â†’ accepted 1; total now 4/24\n",
            "   âœ“ planner JSON (rescued)\n",
            "   â†’ accepted 1; total now 5/24\n",
            "   âœ“ planner JSON (rescued)\n",
            "   â†’ accepted 1; total now 6/24\n",
            "   âœ“ planner JSON (rescued)\n",
            "   â†’ accepted 1; total now 7/24\n",
            "   âœ“ planner JSON (rescued)\n",
            "   â†’ accepted 1; total now 8/24\n",
            "   âœ“ planner JSON (rescued)\n",
            "   â†’ accepted 0; total now 8/24\n",
            "   âœ“ planner JSON (rescued)\n",
            "   â†’ accepted 0; total now 8/24\n",
            "   âœ“ planner JSON (rescued)\n",
            "   â†’ accepted 1; total now 9/24\n",
            "   âœ“ planner JSON (rescued)\n",
            "   â†’ accepted 0; total now 9/24\n",
            "   âœ“ planner JSON (rescued)\n",
            "   â†’ accepted 1; total now 10/24\n",
            "   âœ“ planner JSON (rescued)\n",
            "   â†’ accepted 0; total now 10/24\n",
            "   âœ“ planner JSON (rescued)\n",
            "   â†’ accepted 0; total now 10/24\n",
            "   âœ“ planner JSON (rescued)\n",
            "   â†’ accepted 0; total now 10/24\n",
            "   âœ“ planner JSON (rescued)\n",
            "   â†’ accepted 0; total now 10/24\n",
            "   âœ“ planner JSON (rescued)\n",
            "   â†’ accepted 1; total now 11/24\n",
            "   âœ“ planner JSON (rescued)\n",
            "   â†’ accepted 1; total now 12/24\n",
            "   âœ“ planner JSON (rescued)\n",
            "   â†’ accepted 0; total now 12/24\n",
            "   âœ“ planner JSON (rescued)\n",
            "   â†’ accepted 0; total now 12/24\n",
            "   âœ“ planner JSON (rescued)\n",
            "   â†’ accepted 0; total now 12/24\n",
            "   âœ“ planner JSON (rescued)\n",
            "   â†’ accepted 0; total now 12/24\n",
            "   âœ“ planner JSON (rescued)\n",
            "   â†’ accepted 0; total now 12/24\n",
            "   âœ“ planner JSON (rescued)\n",
            "   â†’ accepted 0; total now 12/24\n",
            "   Â· stalled; relaxing filter and adding stub seeds\n",
            "   âœ“ planner JSON (rescued)\n",
            "   â†’ accepted 1; total now 14/24\n",
            "   âœ“ planner JSON (rescued)\n",
            "   â†’ accepted 1; total now 15/24\n",
            "   âœ“ planner JSON (rescued)\n",
            "   â†’ accepted 1; total now 16/24\n",
            "   âœ“ planner JSON (rescued)\n",
            "   â†’ accepted 1; total now 17/24\n",
            "   âœ“ planner JSON (rescued)\n",
            "   â†’ accepted 1; total now 18/24\n",
            "   âœ“ planner JSON (rescued)\n",
            "   â†’ accepted 0; total now 18/24\n",
            "   âœ“ planner JSON (rescued)\n",
            "   â†’ accepted 0; total now 18/24\n",
            "   âœ“ planner JSON (rescued)\n",
            "   â†’ accepted 0; total now 18/24\n",
            "   âœ“ planner JSON (rescued)\n",
            "   â†’ accepted 0; total now 18/24\n",
            "   âœ“ planner JSON (rescued)\n",
            "   â†’ accepted 0; total now 18/24\n",
            "   âœ“ planner JSON (rescued)\n",
            "   â†’ accepted 0; total now 18/24\n",
            "   Â· stalled; relaxing filter and adding stub seeds\n",
            "   âœ“ planner JSON (rescued)\n",
            "   â†’ accepted 0; total now 19/24\n",
            "   âœ“ planner JSON (rescued)\n",
            "   â†’ accepted 0; total now 19/24\n",
            "   âœ“ planner JSON (rescued)\n",
            "   â†’ accepted 0; total now 19/24\n",
            "   âœ“ planner JSON (rescued)\n",
            "   â†’ accepted 0; total now 19/24\n",
            "   âœ“ planner JSON (rescued)\n",
            "   â†’ accepted 0; total now 19/24\n",
            "   âœ“ planner JSON (rescued)\n",
            "   â†’ accepted 0; total now 19/24\n",
            "   Â· stalled; relaxing filter and adding stub seeds\n",
            "   âœ“ planner JSON (rescued)\n",
            "   â†’ accepted 0; total now 20/24\n",
            "   âœ“ planner JSON (rescued)\n",
            "   â†’ accepted 0; total now 20/24\n",
            "   âœ“ planner JSON (rescued)\n",
            "   â†’ accepted 0; total now 20/24\n",
            "   âœ“ planner JSON (rescued)\n",
            "   â†’ accepted 0; total now 20/24\n",
            "   âœ“ planner JSON (rescued)\n",
            "   â†’ accepted 0; total now 20/24\n",
            "   âœ“ planner JSON (rescued)\n",
            "   â†’ accepted 0; total now 20/24\n",
            "   Â· stalled; relaxing filter and adding stub seeds\n",
            "   âœ“ planner JSON (rescued)\n",
            "   â†’ accepted 0; total now 21/24\n",
            "   âœ“ planner JSON (rescued)\n",
            "   â†’ accepted 0; total now 21/24\n",
            "   âœ“ planner JSON (rescued)\n",
            "   â†’ accepted 0; total now 21/24\n",
            "   âœ“ planner JSON (rescued)\n",
            "   â†’ accepted 0; total now 21/24\n",
            "   âœ“ planner JSON (rescued)\n",
            "   â†’ accepted 0; total now 21/24\n",
            "   âœ“ planner JSON (rescued)\n",
            "   â†’ accepted 0; total now 21/24\n",
            "   Â· stalled; relaxing filter and adding stub seeds\n",
            "   âœ“ planner JSON (rescued)\n",
            "   â†’ accepted 0; total now 22/24\n",
            "   âœ“ planner JSON (rescued)\n",
            "   â†’ accepted 0; total now 22/24\n",
            "   âœ“ planner JSON (rescued)\n",
            "   â†’ accepted 0; total now 22/24\n",
            "   âœ“ planner JSON (rescued)\n",
            "   â†’ accepted 0; total now 22/24\n",
            "   âœ“ planner JSON (rescued)\n",
            "   â†’ accepted 0; total now 22/24\n",
            "   âœ“ planner JSON (rescued)\n",
            "   â†’ accepted 0; total now 22/24\n",
            "   Â· stalled; relaxing filter and adding stub seeds\n",
            "âœ” Final outline: 23 chapters\n",
            "\n",
            "âš ï¸ Could not reach target; proceeding with what we have.\n",
            "â†’ Generating 3 charactersâ€¦\n",
            "âœ” Got 3 characters\n",
            "\n",
            "â†’ Building theme/motif bibleâ€¦\n",
            "âœ” Theme bible ready.\n",
            "\n",
            "ğŸ” Research agent: collecting sourcesâ€¦\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Fetching: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 22/22 [00:00<00:00, 89068.23it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ğŸ§¾ Saved research/history_brief.{json,md}\n",
            "â†’ Generating chaptersâ€¦\n",
            "ğŸ” Resizing outline: need +1 chaptersâ€¦\n",
            "   âœ“ planner JSON (rescued)\n",
            "   â†’ total 24 chapters after resize\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Chapters: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 21/21 [8:03:47<00:00, 1382.28s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ğŸ§® Total words: 18,233  â†’ est. pages â‰ˆ 66\n",
            "ğŸ”§ If you rerun, suggested chapters for this style â‰ˆ 12\n",
            "ğŸ“˜ Saved What_Could_Have_Been:_An_Alternative_History.docx\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_c18f7194-57c1-412c-9c22-ed4ed6e5b1ed\", \"What_Could_Have_Been:_An_Alternative_History.docx\", 77766)"
            ]
          },
          "metadata": {}
        }
      ]
    }
  ]
}